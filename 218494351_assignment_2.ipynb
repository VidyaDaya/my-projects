{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "218494351_assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjif_5FsdOFz",
        "colab_type": "text"
      },
      "source": [
        "# SIT744 Assignment 2: Efficient Training of Convolutional Neural Network \n",
        "\n",
        "<div class=\"alert-info\">\n",
        "    <p>Due: <strong>9:00am 18 May 2020</strong>  (Monday)</p>\n",
        "\n",
        "This is an <strong>individual</strong> assignment. It contributes <strong>40%</strong> to your final mark. Read the assignment instruction carefully.\n",
        "\n",
        "<h2> What to submit </h2>\n",
        "\n",
        "<p>\n",
        "This assignment is to be completed individually and submitted to CloudDeakin. <strong>By the due date, you are required to submit the following files to the corresponding Assignment (Dropbox) in CloudDeakin</strong>:\n",
        "\n",
        "<ol>\n",
        "<li>\t<strong>[YourID]_assignment2_solution.ipynp</strong>:  This is your Python notebook solution source file. </li>\n",
        "<li>\t<strong>[YourID]_assingment2_output.html</strong>: This is the output of your Python notebook solution <emph>exported</emph> in HTML format.</li>\n",
        "<li>\tExtra files needed to complete your assignment, if any (e.g., images used in your answers).</li>\n",
        "</ol>\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "For example, if your student ID is: 123456, you will then need to submit the following files:\n",
        "<ul>\n",
        "<li> 123456_assignment2_solution.ipynp </li>\n",
        "<li> 123456_assignment2_output.html</li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<h2> Warning </h2>\n",
        "\n",
        "Some components of this assignment may involve heavy computation that runs for a long duration. Please start early to avoid missing the assignment due date.\n",
        "\n",
        "<h2> Marking criteria </h2>\n",
        "\n",
        "<p>\n",
        "Your submission will be marked using the following criteria.\n",
        "\n",
        "<ul>\n",
        "<li> Showing good effort through completed tasks.</li>\n",
        "<li> Applying deep learning theory to design suitable deep learning solutions for the tasks.</li>\n",
        "<li> Critically evaluating and reflecting on the pros and cons of various design decisions.</li>\n",
        "<li> Demonstrating creativity and resourcefulness in providing unique individual solutions.</li>\n",
        "<li> Showing attention to details through a good quality assignment report.</li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "Indicative weights of various tasks are provided, but the assignment will be marked by the overall quality per the above criteria.\n",
        "</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4mK_yswYepF",
        "colab_type": "code",
        "outputId": "2c019c8c-67d6-4281-d67c-4df968659474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twFQbltnm8da",
        "colab_type": "text"
      },
      "source": [
        "## Assignment objective\n",
        "\n",
        "This assignment is to feedback on your learning in deep learning theory and its application to  data analytics or artificial intelligence problems.  \n",
        "\n",
        "It builds on Assignment 1 but requires a higher level of mastery of deep learning theory and programming/engineering skills. In particular, you will experience training a much deeper network on a large-scale dataset. You will encounter  practical issues that help you consolidate textbook learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ITc1hw_o7qV",
        "colab_type": "text"
      },
      "source": [
        "## Task 1 Solving Fashion-MNIST with Convolutional Neural Networks\n",
        "\n",
        "*(weight ~20%)*\n",
        "\n",
        "In Assignment 1, you tackled the image classification problem in Fashion-MNIST. There, you used a Densely Connected Neural Network. You should now know that is not an optimal model architecture for the problem. In Assignment 2, you will apply the best practices of deep-learning computer vision to improve the image classification performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gQxeGYNZIGY",
        "colab_type": "code",
        "outputId": "b09506ac-cd34-4b15-915f-cef8474e9bf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "2.3.0-tf\n",
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdHwmgwOpEfx",
        "colab_type": "text"
      },
      "source": [
        "### Task 1.1 Revisit Fashion-MNIST classification with DNN\n",
        "\n",
        "*(weight ~3%)*\n",
        "\n",
        "Review your Assignment 1 solution, and reproduce the experiment here. Try to improve the model without changing the model architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmCsKN89YwMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfds.disable_progress_bar()\n",
        "\n",
        "TRAIN_DS_SIZE = 48000\n",
        "VALID_DS_SIZE = 6000\n",
        "TEST_DS_SIZE = 6000\n",
        "\n",
        "(fashion_mnist_train, fashion_mnist_valid, fashion_mnist_test), info = tfds.load('fashion_mnist', \n",
        "                                                               split=[f'train[:{TRAIN_DS_SIZE}]', \n",
        "                                                                      f'train[{TRAIN_DS_SIZE}:{TRAIN_DS_SIZE + VALID_DS_SIZE}]', \n",
        "                                                                      f'train[{TRAIN_DS_SIZE + VALID_DS_SIZE}:{TRAIN_DS_SIZE + VALID_DS_SIZE + TEST_DS_SIZE}]'],\n",
        "                                                               with_info=True,\n",
        "                                                               as_supervised=True)\n",
        "\n",
        "def preprocess(image,label):\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = image / 255\n",
        "  return image, label\n",
        "\n",
        "train_dataset = (fashion_mnist_train.map(preprocess).shuffle(buffer_size=50000).batch(128,drop_remainder=True).cache().repeat())\n",
        "test_dataset=(fashion_mnist_test.map(preprocess).batch(128,drop_remainder=True).cache().repeat())\n",
        "validation_dataset=(fashion_mnist_valid.map(preprocess).batch(128,drop_remainder=True).cache().repeat())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQEi35PZ09V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))\n",
        "model.compile(optimizer = Adam(learning_rate=0.01),loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOkfEdxlaNQF",
        "colab_type": "code",
        "outputId": "7b45b492-7f41-4f7e-bce4-d1f5884801dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "BATCH_SIZE=128\n",
        "EPOCHS=250\n",
        "STEPS_PER_EPOCH=100\n",
        "history=model.fit(train_dataset,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=validation_dataset,steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,verbose=1,shuffle=True)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 1.2226 - accuracy: 0.5253 - val_loss: 0.7600 - val_accuracy: 0.7222\n",
            "Epoch 2/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.7393 - val_loss: 0.6087 - val_accuracy: 0.7770\n",
            "Epoch 3/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.7795 - val_loss: 0.5589 - val_accuracy: 0.8066\n",
            "Epoch 4/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.7932 - val_loss: 0.5452 - val_accuracy: 0.8023\n",
            "Epoch 5/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.8075 - val_loss: 0.4944 - val_accuracy: 0.8200\n",
            "Epoch 6/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.8175 - val_loss: 0.5029 - val_accuracy: 0.8213\n",
            "Epoch 7/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.8217 - val_loss: 0.4938 - val_accuracy: 0.8231\n",
            "Epoch 8/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.8304 - val_loss: 0.4351 - val_accuracy: 0.8462\n",
            "Epoch 9/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.8395 - val_loss: 0.4330 - val_accuracy: 0.8417\n",
            "Epoch 10/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8380 - val_loss: 0.4208 - val_accuracy: 0.8452\n",
            "Epoch 11/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8444 - val_loss: 0.4165 - val_accuracy: 0.8472\n",
            "Epoch 12/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8499 - val_loss: 0.4318 - val_accuracy: 0.8445\n",
            "Epoch 13/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8484 - val_loss: 0.3955 - val_accuracy: 0.8575\n",
            "Epoch 14/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8507 - val_loss: 0.4137 - val_accuracy: 0.8494\n",
            "Epoch 15/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8576 - val_loss: 0.3856 - val_accuracy: 0.8606\n",
            "Epoch 16/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8555 - val_loss: 0.3909 - val_accuracy: 0.8589\n",
            "Epoch 17/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8562 - val_loss: 0.3890 - val_accuracy: 0.8528\n",
            "Epoch 18/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8571 - val_loss: 0.3806 - val_accuracy: 0.8637\n",
            "Epoch 19/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8657 - val_loss: 0.3882 - val_accuracy: 0.8567\n",
            "Epoch 20/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8597 - val_loss: 0.3621 - val_accuracy: 0.8664\n",
            "Epoch 21/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8655 - val_loss: 0.3794 - val_accuracy: 0.8633\n",
            "Epoch 22/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8667 - val_loss: 0.3648 - val_accuracy: 0.8661\n",
            "Epoch 23/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3566 - accuracy: 0.8700 - val_loss: 0.3815 - val_accuracy: 0.8597\n",
            "Epoch 24/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8679 - val_loss: 0.3512 - val_accuracy: 0.8711\n",
            "Epoch 25/250\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8699 - val_loss: 0.3418 - val_accuracy: 0.8720\n",
            "Epoch 26/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3535 - accuracy: 0.8752 - val_loss: 0.3561 - val_accuracy: 0.8708\n",
            "Epoch 27/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8735 - val_loss: 0.3690 - val_accuracy: 0.8666\n",
            "Epoch 28/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8707 - val_loss: 0.3385 - val_accuracy: 0.8783\n",
            "Epoch 29/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8737 - val_loss: 0.3447 - val_accuracy: 0.8748\n",
            "Epoch 30/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8813 - val_loss: 0.3397 - val_accuracy: 0.8761\n",
            "Epoch 31/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8755 - val_loss: 0.3558 - val_accuracy: 0.8730\n",
            "Epoch 32/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3266 - accuracy: 0.8780 - val_loss: 0.3541 - val_accuracy: 0.8678\n",
            "Epoch 33/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8766 - val_loss: 0.3482 - val_accuracy: 0.8741\n",
            "Epoch 34/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8844 - val_loss: 0.3581 - val_accuracy: 0.8683\n",
            "Epoch 35/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.8791 - val_loss: 0.3345 - val_accuracy: 0.8769\n",
            "Epoch 36/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.8809 - val_loss: 0.3378 - val_accuracy: 0.8767\n",
            "Epoch 37/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.8826 - val_loss: 0.3478 - val_accuracy: 0.8691\n",
            "Epoch 38/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.8861 - val_loss: 0.3447 - val_accuracy: 0.8750\n",
            "Epoch 39/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3069 - accuracy: 0.8848 - val_loss: 0.3246 - val_accuracy: 0.8791\n",
            "Epoch 40/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3130 - accuracy: 0.8815 - val_loss: 0.3196 - val_accuracy: 0.8806\n",
            "Epoch 41/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.8885 - val_loss: 0.3508 - val_accuracy: 0.8712\n",
            "Epoch 42/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.8880 - val_loss: 0.3375 - val_accuracy: 0.8778\n",
            "Epoch 43/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8866 - val_loss: 0.3133 - val_accuracy: 0.8831\n",
            "Epoch 44/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8839 - val_loss: 0.3344 - val_accuracy: 0.8739\n",
            "Epoch 45/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8899 - val_loss: 0.3201 - val_accuracy: 0.8830\n",
            "Epoch 46/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.8905 - val_loss: 0.3341 - val_accuracy: 0.8781\n",
            "Epoch 47/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.8875 - val_loss: 0.3607 - val_accuracy: 0.8644\n",
            "Epoch 48/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8872 - val_loss: 0.3292 - val_accuracy: 0.8833\n",
            "Epoch 49/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2938 - accuracy: 0.8921 - val_loss: 0.3433 - val_accuracy: 0.8744\n",
            "Epoch 50/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2866 - accuracy: 0.8916 - val_loss: 0.3244 - val_accuracy: 0.8827\n",
            "Epoch 51/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.8901 - val_loss: 0.3309 - val_accuracy: 0.8784\n",
            "Epoch 52/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.8919 - val_loss: 0.3459 - val_accuracy: 0.8730\n",
            "Epoch 53/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8923 - val_loss: 0.3247 - val_accuracy: 0.8858\n",
            "Epoch 54/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2838 - accuracy: 0.8933 - val_loss: 0.3363 - val_accuracy: 0.8786\n",
            "Epoch 55/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8903 - val_loss: 0.3271 - val_accuracy: 0.8763\n",
            "Epoch 56/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2902 - accuracy: 0.8938 - val_loss: 0.3480 - val_accuracy: 0.8791\n",
            "Epoch 57/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8959 - val_loss: 0.3377 - val_accuracy: 0.8813\n",
            "Epoch 58/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2820 - accuracy: 0.8937 - val_loss: 0.3086 - val_accuracy: 0.8867\n",
            "Epoch 59/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2798 - accuracy: 0.8963 - val_loss: 0.3224 - val_accuracy: 0.8789\n",
            "Epoch 60/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2833 - accuracy: 0.8967 - val_loss: 0.3113 - val_accuracy: 0.8888\n",
            "Epoch 61/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2726 - accuracy: 0.8980 - val_loss: 0.3389 - val_accuracy: 0.8783\n",
            "Epoch 62/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2702 - accuracy: 0.8969 - val_loss: 0.3556 - val_accuracy: 0.8689\n",
            "Epoch 63/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2761 - accuracy: 0.8958 - val_loss: 0.3479 - val_accuracy: 0.8781\n",
            "Epoch 64/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2757 - accuracy: 0.8978 - val_loss: 0.3277 - val_accuracy: 0.8827\n",
            "Epoch 65/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2654 - accuracy: 0.8993 - val_loss: 0.3365 - val_accuracy: 0.8809\n",
            "Epoch 66/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8969 - val_loss: 0.3415 - val_accuracy: 0.8820\n",
            "Epoch 67/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2691 - accuracy: 0.9012 - val_loss: 0.3417 - val_accuracy: 0.8770\n",
            "Epoch 68/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.8991 - val_loss: 0.3234 - val_accuracy: 0.8883\n",
            "Epoch 69/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.9017 - val_loss: 0.3378 - val_accuracy: 0.8784\n",
            "Epoch 70/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2640 - accuracy: 0.9009 - val_loss: 0.3235 - val_accuracy: 0.8842\n",
            "Epoch 71/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.9041 - val_loss: 0.3551 - val_accuracy: 0.8748\n",
            "Epoch 72/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.9031 - val_loss: 0.3260 - val_accuracy: 0.8852\n",
            "Epoch 73/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2584 - accuracy: 0.8998 - val_loss: 0.3304 - val_accuracy: 0.8806\n",
            "Epoch 74/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2639 - accuracy: 0.9013 - val_loss: 0.3228 - val_accuracy: 0.8806\n",
            "Epoch 75/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.9019 - val_loss: 0.3146 - val_accuracy: 0.8864\n",
            "Epoch 76/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.9066 - val_loss: 0.3339 - val_accuracy: 0.8795\n",
            "Epoch 77/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.9045 - val_loss: 0.3690 - val_accuracy: 0.8644\n",
            "Epoch 78/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.9011 - val_loss: 0.3583 - val_accuracy: 0.8795\n",
            "Epoch 79/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.9052 - val_loss: 0.3222 - val_accuracy: 0.8878\n",
            "Epoch 80/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2454 - accuracy: 0.9046 - val_loss: 0.3407 - val_accuracy: 0.8816\n",
            "Epoch 81/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.9059 - val_loss: 0.3595 - val_accuracy: 0.8792\n",
            "Epoch 82/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2518 - accuracy: 0.9104 - val_loss: 0.3452 - val_accuracy: 0.8786\n",
            "Epoch 83/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.9061 - val_loss: 0.3297 - val_accuracy: 0.8883\n",
            "Epoch 84/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2417 - accuracy: 0.9087 - val_loss: 0.3433 - val_accuracy: 0.8822\n",
            "Epoch 85/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.9049 - val_loss: 0.3344 - val_accuracy: 0.8798\n",
            "Epoch 86/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.9103 - val_loss: 0.3672 - val_accuracy: 0.8759\n",
            "Epoch 87/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2431 - accuracy: 0.9074 - val_loss: 0.3455 - val_accuracy: 0.8827\n",
            "Epoch 88/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.9068 - val_loss: 0.3579 - val_accuracy: 0.8794\n",
            "Epoch 89/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2530 - accuracy: 0.9059 - val_loss: 0.3414 - val_accuracy: 0.8733\n",
            "Epoch 90/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2513 - accuracy: 0.9091 - val_loss: 0.3156 - val_accuracy: 0.8881\n",
            "Epoch 91/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.9095 - val_loss: 0.3301 - val_accuracy: 0.8825\n",
            "Epoch 92/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2423 - accuracy: 0.9080 - val_loss: 0.3575 - val_accuracy: 0.8714\n",
            "Epoch 93/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.9065 - val_loss: 0.3536 - val_accuracy: 0.8819\n",
            "Epoch 94/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2459 - accuracy: 0.9098 - val_loss: 0.3241 - val_accuracy: 0.8877\n",
            "Epoch 95/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2242 - accuracy: 0.9156 - val_loss: 0.3551 - val_accuracy: 0.8767\n",
            "Epoch 96/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2459 - accuracy: 0.9077 - val_loss: 0.3441 - val_accuracy: 0.8875\n",
            "Epoch 97/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2444 - accuracy: 0.9115 - val_loss: 0.3736 - val_accuracy: 0.8753\n",
            "Epoch 98/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2343 - accuracy: 0.9102 - val_loss: 0.3351 - val_accuracy: 0.8867\n",
            "Epoch 99/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2251 - accuracy: 0.9162 - val_loss: 0.3408 - val_accuracy: 0.8856\n",
            "Epoch 100/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2402 - accuracy: 0.9083 - val_loss: 0.3475 - val_accuracy: 0.8794\n",
            "Epoch 101/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2400 - accuracy: 0.9126 - val_loss: 0.3503 - val_accuracy: 0.8852\n",
            "Epoch 102/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2233 - accuracy: 0.9139 - val_loss: 0.3547 - val_accuracy: 0.8784\n",
            "Epoch 103/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2289 - accuracy: 0.9129 - val_loss: 0.3582 - val_accuracy: 0.8791\n",
            "Epoch 104/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2344 - accuracy: 0.9120 - val_loss: 0.3428 - val_accuracy: 0.8781\n",
            "Epoch 105/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2336 - accuracy: 0.9161 - val_loss: 0.3211 - val_accuracy: 0.8934\n",
            "Epoch 106/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2182 - accuracy: 0.9166 - val_loss: 0.3491 - val_accuracy: 0.8808\n",
            "Epoch 107/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2233 - accuracy: 0.9148 - val_loss: 0.3691 - val_accuracy: 0.8733\n",
            "Epoch 108/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2346 - accuracy: 0.9143 - val_loss: 0.3427 - val_accuracy: 0.8852\n",
            "Epoch 109/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9153 - val_loss: 0.3381 - val_accuracy: 0.8866\n",
            "Epoch 110/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2128 - accuracy: 0.9178 - val_loss: 0.3673 - val_accuracy: 0.8753\n",
            "Epoch 111/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2266 - accuracy: 0.9156 - val_loss: 0.3351 - val_accuracy: 0.8856\n",
            "Epoch 112/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2269 - accuracy: 0.9166 - val_loss: 0.3962 - val_accuracy: 0.8723\n",
            "Epoch 113/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9177 - val_loss: 0.3405 - val_accuracy: 0.8873\n",
            "Epoch 114/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2110 - accuracy: 0.9203 - val_loss: 0.3396 - val_accuracy: 0.8863\n",
            "Epoch 115/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2245 - accuracy: 0.9155 - val_loss: 0.3776 - val_accuracy: 0.8711\n",
            "Epoch 116/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.9174 - val_loss: 0.3681 - val_accuracy: 0.8838\n",
            "Epoch 117/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.9198 - val_loss: 0.3483 - val_accuracy: 0.8869\n",
            "Epoch 118/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2094 - accuracy: 0.9203 - val_loss: 0.3692 - val_accuracy: 0.8811\n",
            "Epoch 119/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2221 - accuracy: 0.9163 - val_loss: 0.3543 - val_accuracy: 0.8780\n",
            "Epoch 120/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2208 - accuracy: 0.9179 - val_loss: 0.3427 - val_accuracy: 0.8859\n",
            "Epoch 121/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9228 - val_loss: 0.3664 - val_accuracy: 0.8783\n",
            "Epoch 122/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2053 - accuracy: 0.9225 - val_loss: 0.3514 - val_accuracy: 0.8830\n",
            "Epoch 123/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2213 - accuracy: 0.9179 - val_loss: 0.3508 - val_accuracy: 0.8834\n",
            "Epoch 124/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2115 - accuracy: 0.9201 - val_loss: 0.3370 - val_accuracy: 0.8886\n",
            "Epoch 125/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2031 - accuracy: 0.9220 - val_loss: 0.3713 - val_accuracy: 0.8823\n",
            "Epoch 126/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2081 - accuracy: 0.9213 - val_loss: 0.3340 - val_accuracy: 0.8836\n",
            "Epoch 127/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2170 - accuracy: 0.9200 - val_loss: 0.3951 - val_accuracy: 0.8802\n",
            "Epoch 128/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2094 - accuracy: 0.9197 - val_loss: 0.3413 - val_accuracy: 0.8859\n",
            "Epoch 129/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2037 - accuracy: 0.9216 - val_loss: 0.3341 - val_accuracy: 0.8916\n",
            "Epoch 130/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2161 - accuracy: 0.9165 - val_loss: 0.3815 - val_accuracy: 0.8767\n",
            "Epoch 131/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2145 - accuracy: 0.9227 - val_loss: 0.3892 - val_accuracy: 0.8781\n",
            "Epoch 132/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2004 - accuracy: 0.9216 - val_loss: 0.3451 - val_accuracy: 0.8902\n",
            "Epoch 133/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1976 - accuracy: 0.9219 - val_loss: 0.4269 - val_accuracy: 0.8662\n",
            "Epoch 134/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2120 - accuracy: 0.9212 - val_loss: 0.3628 - val_accuracy: 0.8783\n",
            "Epoch 135/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2121 - accuracy: 0.9238 - val_loss: 0.3540 - val_accuracy: 0.8864\n",
            "Epoch 136/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1941 - accuracy: 0.9241 - val_loss: 0.3791 - val_accuracy: 0.8816\n",
            "Epoch 137/250\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9251 - val_loss: 0.3550 - val_accuracy: 0.8834\n",
            "Epoch 138/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2104 - accuracy: 0.9220 - val_loss: 0.3503 - val_accuracy: 0.8938\n",
            "Epoch 139/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2032 - accuracy: 0.9242 - val_loss: 0.3582 - val_accuracy: 0.8845\n",
            "Epoch 140/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1953 - accuracy: 0.9246 - val_loss: 0.3572 - val_accuracy: 0.8863\n",
            "Epoch 141/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1945 - accuracy: 0.9255 - val_loss: 0.3479 - val_accuracy: 0.8845\n",
            "Epoch 142/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1996 - accuracy: 0.9255 - val_loss: 0.3889 - val_accuracy: 0.8863\n",
            "Epoch 143/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1918 - accuracy: 0.9279 - val_loss: 0.3584 - val_accuracy: 0.8861\n",
            "Epoch 144/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1898 - accuracy: 0.9269 - val_loss: 0.3659 - val_accuracy: 0.8898\n",
            "Epoch 145/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2023 - accuracy: 0.9248 - val_loss: 0.3544 - val_accuracy: 0.8870\n",
            "Epoch 146/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1982 - accuracy: 0.9265 - val_loss: 0.3941 - val_accuracy: 0.8848\n",
            "Epoch 147/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9258 - val_loss: 0.3946 - val_accuracy: 0.8769\n",
            "Epoch 148/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1918 - accuracy: 0.9237 - val_loss: 0.4385 - val_accuracy: 0.8748\n",
            "Epoch 149/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2012 - accuracy: 0.9248 - val_loss: 0.3750 - val_accuracy: 0.8808\n",
            "Epoch 150/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.9274 - val_loss: 0.3751 - val_accuracy: 0.8827\n",
            "Epoch 151/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1816 - accuracy: 0.9290 - val_loss: 0.3915 - val_accuracy: 0.8777\n",
            "Epoch 152/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1850 - accuracy: 0.9284 - val_loss: 0.3692 - val_accuracy: 0.8889\n",
            "Epoch 153/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2013 - accuracy: 0.9250 - val_loss: 0.3523 - val_accuracy: 0.8909\n",
            "Epoch 154/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1857 - accuracy: 0.9309 - val_loss: 0.3778 - val_accuracy: 0.8813\n",
            "Epoch 155/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9288 - val_loss: 0.3991 - val_accuracy: 0.8798\n",
            "Epoch 156/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1939 - accuracy: 0.9251 - val_loss: 0.3842 - val_accuracy: 0.8753\n",
            "Epoch 157/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1903 - accuracy: 0.9295 - val_loss: 0.3919 - val_accuracy: 0.8886\n",
            "Epoch 158/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1916 - accuracy: 0.9284 - val_loss: 0.3868 - val_accuracy: 0.8847\n",
            "Epoch 159/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1900 - accuracy: 0.9277 - val_loss: 0.4116 - val_accuracy: 0.8783\n",
            "Epoch 160/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1968 - accuracy: 0.9264 - val_loss: 0.3690 - val_accuracy: 0.8873\n",
            "Epoch 161/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1826 - accuracy: 0.9317 - val_loss: 0.4231 - val_accuracy: 0.8805\n",
            "Epoch 162/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1876 - accuracy: 0.9279 - val_loss: 0.3789 - val_accuracy: 0.8855\n",
            "Epoch 163/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1814 - accuracy: 0.9298 - val_loss: 0.4490 - val_accuracy: 0.8745\n",
            "Epoch 164/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9250 - val_loss: 0.3583 - val_accuracy: 0.8894\n",
            "Epoch 165/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1868 - accuracy: 0.9312 - val_loss: 0.4051 - val_accuracy: 0.8767\n",
            "Epoch 166/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1821 - accuracy: 0.9322 - val_loss: 0.3847 - val_accuracy: 0.8838\n",
            "Epoch 167/250\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1803 - accuracy: 0.9310 - val_loss: 0.3863 - val_accuracy: 0.8777\n",
            "Epoch 168/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9266 - val_loss: 0.3882 - val_accuracy: 0.8905\n",
            "Epoch 169/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1888 - accuracy: 0.9288 - val_loss: 0.4010 - val_accuracy: 0.8788\n",
            "Epoch 170/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1809 - accuracy: 0.9304 - val_loss: 0.4406 - val_accuracy: 0.8786\n",
            "Epoch 171/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1866 - accuracy: 0.9283 - val_loss: 0.3914 - val_accuracy: 0.8848\n",
            "Epoch 172/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1821 - accuracy: 0.9320 - val_loss: 0.4084 - val_accuracy: 0.8897\n",
            "Epoch 173/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1813 - accuracy: 0.9296 - val_loss: 0.3827 - val_accuracy: 0.8833\n",
            "Epoch 174/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1745 - accuracy: 0.9332 - val_loss: 0.4196 - val_accuracy: 0.8830\n",
            "Epoch 175/250\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1867 - accuracy: 0.9304 - val_loss: 0.4160 - val_accuracy: 0.8786\n",
            "Epoch 176/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1746 - accuracy: 0.9350 - val_loss: 0.4636 - val_accuracy: 0.8761\n",
            "Epoch 177/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1765 - accuracy: 0.9327 - val_loss: 0.4165 - val_accuracy: 0.8773\n",
            "Epoch 178/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1768 - accuracy: 0.9323 - val_loss: 0.4603 - val_accuracy: 0.8731\n",
            "Epoch 179/250\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1906 - accuracy: 0.9290 - val_loss: 0.3768 - val_accuracy: 0.8869\n",
            "Epoch 180/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9311 - val_loss: 0.4201 - val_accuracy: 0.8778\n",
            "Epoch 181/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1752 - accuracy: 0.9348 - val_loss: 0.4044 - val_accuracy: 0.8803\n",
            "Epoch 182/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1785 - accuracy: 0.9309 - val_loss: 0.3781 - val_accuracy: 0.8830\n",
            "Epoch 183/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1804 - accuracy: 0.9320 - val_loss: 0.4187 - val_accuracy: 0.8819\n",
            "Epoch 184/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1802 - accuracy: 0.9333 - val_loss: 0.4161 - val_accuracy: 0.8761\n",
            "Epoch 185/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1733 - accuracy: 0.9337 - val_loss: 0.4451 - val_accuracy: 0.8816\n",
            "Epoch 186/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1769 - accuracy: 0.9336 - val_loss: 0.3820 - val_accuracy: 0.8859\n",
            "Epoch 187/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9367 - val_loss: 0.4270 - val_accuracy: 0.8830\n",
            "Epoch 188/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1798 - accuracy: 0.9308 - val_loss: 0.3896 - val_accuracy: 0.8841\n",
            "Epoch 189/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9358 - val_loss: 0.3976 - val_accuracy: 0.8884\n",
            "Epoch 190/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1804 - accuracy: 0.9300 - val_loss: 0.4100 - val_accuracy: 0.8847\n",
            "Epoch 191/250\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1656 - accuracy: 0.9400 - val_loss: 0.4719 - val_accuracy: 0.8744\n",
            "Epoch 192/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9362 - val_loss: 0.4121 - val_accuracy: 0.8825\n",
            "Epoch 193/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1744 - accuracy: 0.9348 - val_loss: 0.4465 - val_accuracy: 0.8761\n",
            "Epoch 194/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1798 - accuracy: 0.9320 - val_loss: 0.3850 - val_accuracy: 0.8802\n",
            "Epoch 195/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.9375 - val_loss: 0.4396 - val_accuracy: 0.8719\n",
            "Epoch 196/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.9388 - val_loss: 0.4314 - val_accuracy: 0.8763\n",
            "Epoch 197/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.9359 - val_loss: 0.4008 - val_accuracy: 0.8859\n",
            "Epoch 198/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1765 - accuracy: 0.9330 - val_loss: 0.4397 - val_accuracy: 0.8791\n",
            "Epoch 199/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.9337 - val_loss: 0.4354 - val_accuracy: 0.8798\n",
            "Epoch 200/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1633 - accuracy: 0.9413 - val_loss: 0.4293 - val_accuracy: 0.8788\n",
            "Epoch 201/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1774 - accuracy: 0.9315 - val_loss: 0.4035 - val_accuracy: 0.8852\n",
            "Epoch 202/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1646 - accuracy: 0.9391 - val_loss: 0.4462 - val_accuracy: 0.8795\n",
            "Epoch 203/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9317 - val_loss: 0.3936 - val_accuracy: 0.8873\n",
            "Epoch 204/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.9366 - val_loss: 0.4169 - val_accuracy: 0.8875\n",
            "Epoch 205/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1727 - accuracy: 0.9332 - val_loss: 0.3878 - val_accuracy: 0.8850\n",
            "Epoch 206/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1559 - accuracy: 0.9418 - val_loss: 0.4569 - val_accuracy: 0.8800\n",
            "Epoch 207/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9365 - val_loss: 0.4324 - val_accuracy: 0.8861\n",
            "Epoch 208/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.9401 - val_loss: 0.4568 - val_accuracy: 0.8819\n",
            "Epoch 209/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1627 - accuracy: 0.9403 - val_loss: 0.4220 - val_accuracy: 0.8795\n",
            "Epoch 210/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1583 - accuracy: 0.9416 - val_loss: 0.4247 - val_accuracy: 0.8809\n",
            "Epoch 211/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.9395 - val_loss: 0.4449 - val_accuracy: 0.8786\n",
            "Epoch 212/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.9388 - val_loss: 0.4208 - val_accuracy: 0.8859\n",
            "Epoch 213/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.9415 - val_loss: 0.4552 - val_accuracy: 0.8833\n",
            "Epoch 214/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 0.9402 - val_loss: 0.4236 - val_accuracy: 0.8808\n",
            "Epoch 215/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9420 - val_loss: 0.4433 - val_accuracy: 0.8834\n",
            "Epoch 216/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1599 - accuracy: 0.9420 - val_loss: 0.4144 - val_accuracy: 0.8816\n",
            "Epoch 217/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1513 - accuracy: 0.9436 - val_loss: 0.4304 - val_accuracy: 0.8848\n",
            "Epoch 218/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1597 - accuracy: 0.9390 - val_loss: 0.4323 - val_accuracy: 0.8813\n",
            "Epoch 219/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1525 - accuracy: 0.9415 - val_loss: 0.4554 - val_accuracy: 0.8842\n",
            "Epoch 220/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1584 - accuracy: 0.9410 - val_loss: 0.4038 - val_accuracy: 0.8863\n",
            "Epoch 221/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1434 - accuracy: 0.9475 - val_loss: 0.4792 - val_accuracy: 0.8792\n",
            "Epoch 222/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1579 - accuracy: 0.9423 - val_loss: 0.4267 - val_accuracy: 0.8841\n",
            "Epoch 223/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1543 - accuracy: 0.9413 - val_loss: 0.4986 - val_accuracy: 0.8739\n",
            "Epoch 224/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1572 - accuracy: 0.9428 - val_loss: 0.4185 - val_accuracy: 0.8795\n",
            "Epoch 225/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9439 - val_loss: 0.4418 - val_accuracy: 0.8780\n",
            "Epoch 226/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1559 - accuracy: 0.9398 - val_loss: 0.4830 - val_accuracy: 0.8756\n",
            "Epoch 227/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1526 - accuracy: 0.9423 - val_loss: 0.4660 - val_accuracy: 0.8791\n",
            "Epoch 228/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.9457 - val_loss: 0.4969 - val_accuracy: 0.8803\n",
            "Epoch 229/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9420 - val_loss: 0.4535 - val_accuracy: 0.8839\n",
            "Epoch 230/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9467 - val_loss: 0.4470 - val_accuracy: 0.8792\n",
            "Epoch 231/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1513 - accuracy: 0.9445 - val_loss: 0.4210 - val_accuracy: 0.8836\n",
            "Epoch 232/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1386 - accuracy: 0.9479 - val_loss: 0.4571 - val_accuracy: 0.8839\n",
            "Epoch 233/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1516 - accuracy: 0.9425 - val_loss: 0.4759 - val_accuracy: 0.8794\n",
            "Epoch 234/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1525 - accuracy: 0.9424 - val_loss: 0.4888 - val_accuracy: 0.8802\n",
            "Epoch 235/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1547 - accuracy: 0.9424 - val_loss: 0.4307 - val_accuracy: 0.8848\n",
            "Epoch 236/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9456 - val_loss: 0.5062 - val_accuracy: 0.8783\n",
            "Epoch 237/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9455 - val_loss: 0.4582 - val_accuracy: 0.8853\n",
            "Epoch 238/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9446 - val_loss: 0.5190 - val_accuracy: 0.8748\n",
            "Epoch 239/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9425 - val_loss: 0.4351 - val_accuracy: 0.8819\n",
            "Epoch 240/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9477 - val_loss: 0.4449 - val_accuracy: 0.8848\n",
            "Epoch 241/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9479 - val_loss: 0.5212 - val_accuracy: 0.8770\n",
            "Epoch 242/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9439 - val_loss: 0.4917 - val_accuracy: 0.8761\n",
            "Epoch 243/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 0.9481 - val_loss: 0.5126 - val_accuracy: 0.8808\n",
            "Epoch 244/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9454 - val_loss: 0.4716 - val_accuracy: 0.8794\n",
            "Epoch 245/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9478 - val_loss: 0.4708 - val_accuracy: 0.8833\n",
            "Epoch 246/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1494 - accuracy: 0.9427 - val_loss: 0.4561 - val_accuracy: 0.8844\n",
            "Epoch 247/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1381 - accuracy: 0.9469 - val_loss: 0.4977 - val_accuracy: 0.8814\n",
            "Epoch 248/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9448 - val_loss: 0.4544 - val_accuracy: 0.8878\n",
            "Epoch 249/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.9490 - val_loss: 0.4674 - val_accuracy: 0.8892\n",
            "Epoch 250/250\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9427 - val_loss: 0.4653 - val_accuracy: 0.8781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO7FdQwJcGhq",
        "colab_type": "code",
        "outputId": "6e738d7d-236b-49dd-f10d-ab8f82e266fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss_value,acc_value=model.evaluate(test_dataset,steps=50,verbose=0)\n",
        "print(\"Accuracy of our model is \", acc_value*100)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of our model is  88.37500214576721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrNxTWQPJ01a",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of our dense neural network is 88.3% as we can see from the output above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfTL_5kPsl4j",
        "colab_type": "text"
      },
      "source": [
        "### Task 1.2 Train a ConvNet from scratch\n",
        "\n",
        "*(weight ~5%)*\n",
        "\n",
        "Build a ConvNet to replace the densely connected network in Task 1.1. Report the classification accuracy on the test set. Aim to achieve higher accuracy. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0A94PhHdWw_",
        "colab_type": "code",
        "outputId": "15f0f2cd-67ca-4dcf-a93a-f22d3cd393ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(28, 28, 1),padding='same'),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(28, 28, 1),padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Dropout((0.25)),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  #tf.keras.layers.Dropout((0.5)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(train_dataset,validation_data=(validation_dataset),steps_per_epoch=100,validation_steps=100, epochs=10,batch_size=BATCH_SIZE)\n",
        "test_loss = model.evaluate(test_dataset,verbose=0,steps=100)\n",
        "print(\"The accuracy of our ConvNet model is\", test_loss[1]*100)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 28, 28, 128)       1280      \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 28, 28, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,248,266\n",
            "Trainable params: 1,248,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 1.4956 - accuracy: 0.4404 - val_loss: 0.8027 - val_accuracy: 0.6904\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.7462 - accuracy: 0.7234 - val_loss: 0.6968 - val_accuracy: 0.7216\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.6403 - accuracy: 0.7620 - val_loss: 0.5299 - val_accuracy: 0.8150\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.5523 - accuracy: 0.7921 - val_loss: 0.4937 - val_accuracy: 0.8209\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.4855 - accuracy: 0.8207 - val_loss: 0.4489 - val_accuracy: 0.8371\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.4555 - accuracy: 0.8323 - val_loss: 0.4280 - val_accuracy: 0.8431\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.4387 - accuracy: 0.8439 - val_loss: 0.4011 - val_accuracy: 0.8549\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.4227 - accuracy: 0.8456 - val_loss: 0.3917 - val_accuracy: 0.8566\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.4006 - accuracy: 0.8534 - val_loss: 0.3880 - val_accuracy: 0.8584\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.3944 - accuracy: 0.8549 - val_loss: 0.3635 - val_accuracy: 0.8657\n",
            "The accuracy of our ConvNet model is 86.1328125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGn6Cd5dJqbX",
        "colab_type": "text"
      },
      "source": [
        "The classification accuracy after adding convolution layers has become 86.13%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbhr44DnMbKZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Task 1.3 Build an input pipeline for data augmentation\n",
        "\n",
        "*(weight ~5%)*\n",
        "\n",
        "Build a data preprocessing pipeline to perform data augmentation. (You may use Keras ImageDataGenerator or write your own transformations.)\n",
        "\n",
        "- Report the new classification accuracy. Make sure that you use the same number of training epochs as in Task 1.2.\n",
        "\n",
        "- (Optional) Profile your input pipeline to identify the most time-consuming operation. What actions have you taken to address that slow operation? (*Hint: You may use the [TensorFlow Profiler](https://github.com/tensorflow/profiler).*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpucFRAAKFV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=10,\n",
        "                             zoom_range = 0.1,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1,\n",
        "                             horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxvypGdHKjFs",
        "colab_type": "text"
      },
      "source": [
        "Trying to get the Same train,validation,test split as used for both DNN and ConvNet for Data Augmentation too as datagen.flow() only accepts numpy arrays and not datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apq1W5orCgk_",
        "colab_type": "code",
        "outputId": "26ab24b1-fa54-4983-e9c7-ef66d226a98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#FOR AUGMENTATION-SAME SPLIT\n",
        "train_data, info = tfds.load('fashion_mnist', split=tfds.Split.TRAIN, with_info=True, as_supervised=True)\n",
        "\n",
        "train_x = []\n",
        "train_y = []\n",
        "for sample in train_data:\n",
        "    train_x.append(sample[0].numpy())\n",
        "    train_y.append(tf.keras.utils.to_categorical(sample[1].numpy(), num_classes=10))\n",
        "\n",
        "#train_x=tf.image.grayscale_to_rgb(train_x)\n",
        "\n",
        "train_x = np.asarray(train_x)\n",
        "train_y = np.asarray(train_y)\n",
        "\n",
        "train_x=train_x/255.0\n",
        "\n",
        "x_train, x_remaining = np.split(train_x,[int(0.8 * train_x.shape[0])])\n",
        "x_validation, x_test = np.split(x_remaining,[int(0.5 * x_remaining.shape[0])])\n",
        "\n",
        "y_train, y_remaining = np.split(train_y,[int(0.8 * train_y.shape[0])])\n",
        "y_validation, y_test = np.split(y_remaining,[int(0.5 * y_remaining.shape[0])])\n",
        "\n",
        "print(x_train.shape,x_test.shape,x_validation.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 28, 28, 1) (6000, 28, 28, 1) (6000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYXvm_jUwgFc",
        "colab_type": "code",
        "outputId": "15eaaf3b-9b4b-4b0a-8512-569fdbcfbf05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_aug = model.fit(datagen.flow(x_train, y_train, batch_size=128),shuffle=True,steps_per_epoch=x_train.shape[0] / 128, epochs=10,\n",
        "                    validation_data=datagen.flow(x_validation,y_validation,batch_size=128),validation_steps=x_validation.shape[0]/128)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 17s 47ms/step - loss: 0.6858 - accuracy: 0.7423 - val_loss: 0.5475 - val_accuracy: 0.7870\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 17s 46ms/step - loss: 0.4380 - accuracy: 0.8357 - val_loss: 0.3635 - val_accuracy: 0.8622\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 18s 47ms/step - loss: 0.3695 - accuracy: 0.8618 - val_loss: 0.3705 - val_accuracy: 0.8578\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 17s 46ms/step - loss: 0.3367 - accuracy: 0.8768 - val_loss: 0.3057 - val_accuracy: 0.8853\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 17s 47ms/step - loss: 0.3183 - accuracy: 0.8801 - val_loss: 0.2935 - val_accuracy: 0.8888\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 17s 47ms/step - loss: 0.2987 - accuracy: 0.8898 - val_loss: 0.2835 - val_accuracy: 0.8958\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 17s 47ms/step - loss: 0.2851 - accuracy: 0.8940 - val_loss: 0.2880 - val_accuracy: 0.8923\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 18s 48ms/step - loss: 0.2744 - accuracy: 0.8985 - val_loss: 0.2830 - val_accuracy: 0.8942\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 17s 46ms/step - loss: 0.2683 - accuracy: 0.9004 - val_loss: 0.2454 - val_accuracy: 0.9108\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 18s 47ms/step - loss: 0.2617 - accuracy: 0.9025 - val_loss: 0.2508 - val_accuracy: 0.9098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCt6yP4W_9JQ",
        "colab_type": "code",
        "outputId": "b7dc24a3-1081-4e96-c9b2-91129407d775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "aug=model.evaluate(x_test,y_test,steps=100,verbose=0)\n",
        "print(\"Accuracy of model after data augmentation is \",aug[1]*100 )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model after data augmentation is  92.88333058357239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fdwy2AJdzaq",
        "colab_type": "text"
      },
      "source": [
        "The model shows an accuracy of 92.8% over the test dataset after data augmentation using the ImageDataGenerator.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prctXU4BswKK",
        "colab_type": "text"
      },
      "source": [
        "### Task 1.3 Fashion-MNIST with transfer learning\n",
        "\n",
        "*(weight ~5%)*\n",
        "\n",
        "Use a pretrained model as the convolutional base to improve the classification performance. (Hint: You may use models in Keras Applications or those in the TensorFlow Hub.)\n",
        "\n",
        "- Try both with fine-tuning and without fine-tuning.\n",
        "- Report the model performance as before.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CewH-8YGUtq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "\n",
        "TRAIN_DS_SIZE = 48000\n",
        "VALID_DS_SIZE = 6000\n",
        "TEST_DS_SIZE = 6000\n",
        "\n",
        "(fashion_mnist_train, fashion_mnist_valid, fashion_mnist_test), info = tfds.load('fashion_mnist', \n",
        "                                                               split=[f'train[:{TRAIN_DS_SIZE}]', \n",
        "                                                                      f'train[{TRAIN_DS_SIZE}:{TRAIN_DS_SIZE + VALID_DS_SIZE}]', \n",
        "                                                                      f'train[{TRAIN_DS_SIZE + VALID_DS_SIZE}:{TRAIN_DS_SIZE + VALID_DS_SIZE + TEST_DS_SIZE}]'],\n",
        "                                                               with_info=True,\n",
        "                                                               as_supervised=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEOMM1mS2yI9",
        "colab_type": "code",
        "outputId": "2feae9d3-0ddf-4c41-a0a9-bce31ff87fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        }
      },
      "source": [
        "vgg16 = VGG16(weights='imagenet',\n",
        "                  include_top=False, \n",
        "                  input_shape=(32,32,3),\n",
        "                  classes=10)\n",
        "vgg16.trainable = False\n",
        "vgg16.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPWmZZ8lL7qR",
        "colab_type": "code",
        "outputId": "104ffa2c-3df2-4bfa-9f20-94d09b7717ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "IMAGE_SIZE = 32\n",
        "def pre_process_image(image, label):\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = image/255\n",
        "  image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "  image = tf.image.grayscale_to_rgb(image, name=None)\n",
        "  print(image.shape)\n",
        "  return image, label\n",
        "\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "train_batches = fashion_mnist_train.map(pre_process_image).batch(TRAIN_BATCH_SIZE,drop_remainder=True).cache().repeat()\n",
        "validation_batches = fashion_mnist_valid.map(pre_process_image).batch(TRAIN_BATCH_SIZE,drop_remainder=True).cache().repeat()\n",
        "test_batches=fashion_mnist_test.map(pre_process_image).batch(TRAIN_BATCH_SIZE,drop_remainder=True).cache().repeat()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 3)\n",
            "(32, 32, 3)\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o0X1nyAM2t-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(vgg16)\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFJ5jBfdNQIS",
        "colab_type": "code",
        "outputId": "00265a90-65f8-4e17-e844-dc937bacb027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "history_transfer = model.fit(\n",
        "    train_batches,\n",
        "    epochs=15,\n",
        "    steps_per_epoch=100,\n",
        "    validation_data=(validation_batches),\n",
        "    validation_steps=100\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 2.3256 - accuracy: 0.0996 - val_loss: 2.3028 - val_accuracy: 0.1037\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 2.3029 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.0965\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 2.3028 - accuracy: 0.0952 - val_loss: 2.3026 - val_accuracy: 0.1001\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 2.3027 - accuracy: 0.0967 - val_loss: 2.3027 - val_accuracy: 0.0965\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 2.3027 - accuracy: 0.0969 - val_loss: 2.3027 - val_accuracy: 0.1001\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 2.3026 - accuracy: 0.1039 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 2.3027 - accuracy: 0.0975 - val_loss: 2.3028 - val_accuracy: 0.0965\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 2.3027 - accuracy: 0.0968 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 2.3026 - accuracy: 0.1051 - val_loss: 2.3028 - val_accuracy: 0.0952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P7cFXX7Ot2t",
        "colab_type": "code",
        "outputId": "ffc1d03a-8b55-493c-82b0-24a6c1188916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "transfer_loss=model.evaluate(test_batches,steps=100,verbose=0)\n",
        "print(\"Accuracy of the model with transfer learning is \",transfer_loss[1]*100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model with transfer learning is  9.562499821186066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EYPFOvmt6FY",
        "colab_type": "code",
        "outputId": "315dabc9-1716-4bb9-c3fa-6ecbaaa4e3cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "#With fine-tuning\n",
        "vgg16.trainable=True\n",
        "set_trainable = False\n",
        "for layer in vgg16.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "for layer in vgg16.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f7c2c1df1d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c2c1e2240> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c700cd908> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7c700c68d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c700c6780> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c700cfe48> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7c700d1f28> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c7017d080> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c700d40f0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c700d7160> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7c700d6470> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c700d6630> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c700d5c88> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c2c131e80> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7c2c0eb320> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c2c0ebd30> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c2c0f0f28> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7c2c0f54e0> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7c2c0fc400> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc0MWNaURFjr",
        "colab_type": "code",
        "outputId": "4943de2e-7ce0-4e2c-9915-1f93c0233510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(vgg16)\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 14,781,642\n",
            "Trainable params: 7,146,378\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqIiVuPGVto_",
        "colab_type": "code",
        "outputId": "4eb4bcc2-8c94-4b54-c2da-b13175b1f723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_batches,\n",
        "    epochs=15,\n",
        "    steps_per_epoch=100,\n",
        "    validation_data=(validation_batches),\n",
        "    validation_steps=100\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 2.3188 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3027 - accuracy: 0.0943 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3028 - accuracy: 0.0970 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3027 - accuracy: 0.1029 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3028 - accuracy: 0.0971 - val_loss: 2.3027 - val_accuracy: 0.0965\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3027 - accuracy: 0.0962 - val_loss: 2.3027 - val_accuracy: 0.1001\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3026 - accuracy: 0.1041 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3027 - accuracy: 0.0975 - val_loss: 2.3027 - val_accuracy: 0.0965\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3027 - accuracy: 0.0963 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 2.3026 - accuracy: 0.1048 - val_loss: 2.3028 - val_accuracy: 0.0952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQPjl6r6ct5u",
        "colab_type": "code",
        "outputId": "ff6669c6-4c40-4787-a83c-112f76b4f3da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "finetune_vgg=model.evaluate(test_batches,steps=100,verbose=0)\n",
        "print(\"Accuracy of model after fine-tuning our transfer learning model is \",finetune_vgg[1]*100 )"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model after fine-tuning our transfer learning model is  9.562499821186066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaHLKDLas_dF",
        "colab_type": "text"
      },
      "source": [
        "### Task 1.4 Performance comparison\n",
        "\n",
        "*(weight ~2%)*\n",
        "\n",
        "Record the test accuracy achieved at different training configurations above. Which method achieved the highest accuracy? Why did it work better for this problem?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBTL8EazrIrB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        ">Configuration | Accuracy Score\n",
        ">--- | ---\n",
        ">DNN | 88.3\n",
        ">CNN | 86.13\n",
        ">Data Augmentation | 92.8\n",
        ">VGG16 | 9.56\n",
        ">VGG16 with Fine-tuning | 9.56"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7nXz5UgcaXc",
        "colab_type": "text"
      },
      "source": [
        "The model with data augmentation has shown the highest accuracy. This has worked best because the model is now trained to several augmented versions of the training image and results in better accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouK5NY-_pLDK",
        "colab_type": "text"
      },
      "source": [
        "## Task 2 Fast training of deep networks\n",
        "\n",
        "*(weight ~20%)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgoOE2W1pdfN",
        "colab_type": "text"
      },
      "source": [
        "### Task 2.1 Train a highly accurate network for CIFAR10\n",
        "\n",
        "*(weight ~7%)*\n",
        "\n",
        "In this task, you will train deep neural networks on the [CIFAR10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). Compared with the datasets that you have worked on so far, CIFAR10 represents a relatively larger multi-class classification problem and presents a great opportunity for you to solve a \"harder\" problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaD5oqj3lhuI",
        "colab_type": "text"
      },
      "source": [
        "#### Task 2.1.1 Document the hardware used\n",
        "\n",
        "Before you start, write down your hardware specifications, including \n",
        "\n",
        "- the GPU model, the number of GPUs, and the GPU memory\n",
        "- the CPU model, the number of CPUs, and the CPU clock speed\n",
        "\n",
        "(Hint: you may find commands like `nvidia-smi`, `lscpu` or `psutil` useful.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpCS7q7-WO8D",
        "colab_type": "text"
      },
      "source": [
        "CPU Model:'Intel64 Family 6 Model 142 Stepping 9, GenuineIntel'\n",
        "\n",
        "CPU Physical Cores: 4\n",
        "\n",
        "CPU Clock Speed:cpufreq(current=2600.0, min=0.0, max=2701.0) in MHz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9PCCWVlXbO9",
        "colab_type": "text"
      },
      "source": [
        "Number of GPU : 1\n",
        "\n",
        "GPU Memory: 2048 MiB\n",
        "\n",
        "GPU Model:GeForce 940MX "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5597dJCHIYS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Commands used for 2.1.1 (RUN in COMMAND PROMPT)\n",
        "# import nvidia_smi\n",
        "# nvidia-smi --query-gpu=name,temperature.gpu,utilization.gpu,utilization.memory,memory.total,memory.free,memory.used --format=csv\n",
        "# import psutil\n",
        "# psutil.cpu_count()\n",
        "# psutil.cpu_freq()\n",
        "# import platform\n",
        "# platform.processor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adN9Tq-6lyG-",
        "colab_type": "text"
      },
      "source": [
        "#### Task 2.1.2 Train a \"shallow\" ConvNet\n",
        "\n",
        "Build a ConvNet with fewer than 10 layers. Train the network until it converges. You will use this network as a baseline for the later experiments. \n",
        "\n",
        "- Plot the training and validation history. \n",
        "- Report the testing accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5R8aYv3Iv4q",
        "colab_type": "code",
        "outputId": "bcadca82-30cd-4c22-8e53-79cc1984f014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train=x_train/255.0\n",
        "x_test=x_test/255.0\n",
        "\n",
        "y_train=to_categorical(y_train)\n",
        "y_test=to_categorical(y_test)\n",
        "\n",
        "\n",
        "x_validation, x_test = np.split(x_test,[int(0.8 * x_test.shape[0])])\n",
        "y_validation, y_test = np.split(y_test,[int(0.8 * y_test.shape[0])])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjPKXSf5v9zp",
        "colab_type": "code",
        "outputId": "93a13151-6648-4a81-cb99-3017f9c32b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train.shape,x_test.shape,y_train.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (2000, 32, 32, 3) (50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhPNdFP5luSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32,32,3),padding='same'),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32,32,3),padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D((2, 2),padding='valid'),\n",
        "  tf.keras.layers.Dropout(0.25),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D((2,2),padding='valid'),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv7cu2oLw95K",
        "colab_type": "code",
        "outputId": "15097c84-f645-4431-bff6-b7f5f0656204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "cifar10_history=model.fit(x_train,y_train,epochs=15,validation_data=(x_validation,y_validation))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3513 - accuracy: 0.5113 - val_loss: 1.0273 - val_accuracy: 0.6388\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9032 - accuracy: 0.6821 - val_loss: 0.8613 - val_accuracy: 0.7016\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7448 - accuracy: 0.7368 - val_loss: 0.7692 - val_accuracy: 0.7337\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6399 - accuracy: 0.7747 - val_loss: 0.7447 - val_accuracy: 0.7552\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5615 - accuracy: 0.8010 - val_loss: 0.7431 - val_accuracy: 0.7524\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4856 - accuracy: 0.8277 - val_loss: 0.7951 - val_accuracy: 0.7470\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4190 - accuracy: 0.8511 - val_loss: 0.7695 - val_accuracy: 0.7589\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3661 - accuracy: 0.8691 - val_loss: 0.8468 - val_accuracy: 0.7510\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3159 - accuracy: 0.8870 - val_loss: 0.9003 - val_accuracy: 0.7466\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2770 - accuracy: 0.9022 - val_loss: 1.0249 - val_accuracy: 0.7464\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2499 - accuracy: 0.9095 - val_loss: 1.0051 - val_accuracy: 0.7484\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2141 - accuracy: 0.9233 - val_loss: 1.0737 - val_accuracy: 0.7495\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2007 - accuracy: 0.9298 - val_loss: 1.1633 - val_accuracy: 0.7455\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1861 - accuracy: 0.9343 - val_loss: 1.1858 - val_accuracy: 0.7393\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1732 - accuracy: 0.9385 - val_loss: 1.3141 - val_accuracy: 0.7477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEpLw7VHcz5h",
        "colab_type": "code",
        "outputId": "4c0047d2-257d-40d0-eeb9-9250b69673a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(cifar10_history.history['accuracy'])\n",
        "plt.plot(cifar10_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW8KmkfNx812",
        "colab_type": "code",
        "outputId": "dbe2542d-2e58-425f-da8d-21dd0ccb4831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "cifar10_acc=model.evaluate(x_test,y_test)\n",
        "print(\"The accuracy of building a shallow Convnet over CIFAR10 is \",cifar10_acc[1]*100)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 4ms/step - loss: 1.2030 - accuracy: 0.7580\n",
            "The accuracy of building a shallow Convnet over CIFAR10 is  75.80000162124634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NTjVIUkmv7S",
        "colab_type": "text"
      },
      "source": [
        "#### Task 2.1.3 Train a ResNet\n",
        "\n",
        "Train a residual neural network (ResNet) on the CIFAR10 training data and report the test accuracy and the training time.\n",
        "\n",
        "The ResNet is a popular network architecture for image classification. You may find more information about how ResNet works by reading this [paper](https://arxiv.org/abs/1512.03385).\n",
        "\n",
        "\n",
        "*(You may implement a resnet model or use an existing implementation. In either case, you should not use pretrained network weights.)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCkgkX2c-fVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "resnet_base=ResNet50(weights=None,include_top=False,input_shape=(32,32,3),classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7J90kBxusyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet_base.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDN6iiOBfnAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_resmodel():\n",
        "  model = tf.keras.models.Sequential([\n",
        "                                      tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32,32,3),padding='same'),\n",
        "                                      tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32,32,3),padding='same'),\n",
        "                                      tf.keras.layers.MaxPooling2D((2, 2),padding='valid'),\n",
        "                                      tf.keras.layers.Dropout(0.25),\n",
        "                                      tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n",
        "                                      tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n",
        "                                      tf.keras.layers.MaxPooling2D((2,2),padding='valid'),\n",
        "                                      tf.keras.layers.Flatten(),\n",
        "                                      tf.keras.layers.Dense(128, activation='relu'),\n",
        "                                      tf.keras.layers.Dense(10, activation='softmax')\n",
        "                                      ])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JmUK75hoVCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                    rotation_range=3,\n",
        "                                    horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6BoZTTCjoSO",
        "colab_type": "code",
        "outputId": "a9294df4-ee56-4412-de63-fd8713ce40ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "model = make_resmodel()\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(data_generator.flow(x_train, y_train,batch_size=128),\n",
        "                    steps_per_epoch=x_train.shape[0]/128,\n",
        "                    epochs=3,\n",
        "                    validation_data=data_generator.flow(x_validation, y_validation,batch_size=128),\n",
        "                    validation_steps=x_validation.shape[0]/128\n",
        "                    )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "391/390 [==============================] - 31s 79ms/step - loss: 3.0168 - accuracy: 0.1005 - val_loss: 2.3028 - val_accuracy: 0.0970\n",
            "Epoch 2/3\n",
            "391/390 [==============================] - 30s 77ms/step - loss: 2.3038 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1001\n",
            "Epoch 3/3\n",
            "391/390 [==============================] - 30s 76ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84YG4IjVfMPq",
        "colab_type": "code",
        "outputId": "99aa8b4e-cc23-4226-f733-0a2002c72d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "resnet_loss=model.evaluate(x_test,y_test,steps=100,verbose=0)\n",
        "print(\"Accuracy of the Resnet is \",resnet_loss[1]*100)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the Resnet is  9.200000017881393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH6ZBiECzS75",
        "colab_type": "text"
      },
      "source": [
        "### Task 2.2 Fast training of ResNet\n",
        "\n",
        "*(weight ~10%)*\n",
        "\n",
        "In this task, you will experiment with different ways to reduce the time for training your ResNet on CIFAR10. There are different ways to speed up neural network training; below are two ideas. Please select at least one idea to implement. Explain the experiment steps and report the final performance and training time.\n",
        "\n",
        "#### Option 1. Learning rate schedule\n",
        "\n",
        "Use a learning rate schedule for the training. Some popular learning rate schedules include \n",
        "\n",
        "- the Step Decay learning rate (e.g., see [here](https://github.com/kuangliu/pytorch-cifar))\n",
        "- [Cyclical learning rates](https://arxiv.org/abs/1506.01186)\n",
        "- [The exponential learning rate](https://openreview.net/forum?id=rJg8TeSFDH) \n",
        "\n",
        "Also Keras provides [some convenient functions](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules) that you can use.\n",
        "\n",
        "\n",
        "#### Option 2. Look ahead optimiser\n",
        "\n",
        "Read [this paper](https://arxiv.org/abs/1907.08610) and implement the Lookahead optimiser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isQCmUzEhqLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_learning_rate = 0.1\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERlpih2jh8Nw",
        "colab_type": "code",
        "outputId": "237d122d-b927-4a14-af0f-02c5ceec78d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "model=make_resmodel()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(data_generator.flow(x_train, y_train,batch_size=128),\n",
        "                    steps_per_epoch=x_train.shape[0]/128,\n",
        "                    epochs=3,\n",
        "                    validation_data=data_generator.flow(x_validation, y_validation,batch_size=128),\n",
        "                    validation_steps=x_validation.shape[0]/128\n",
        "                    )"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "391/390 [==============================] - 29s 75ms/step - loss: 44924288.0000 - accuracy: 0.0998 - val_loss: 2.3178 - val_accuracy: 0.1016\n",
            "Epoch 2/3\n",
            "391/390 [==============================] - 30s 75ms/step - loss: 2.3100 - accuracy: 0.0990 - val_loss: 2.3082 - val_accuracy: 0.1001\n",
            "Epoch 3/3\n",
            "391/390 [==============================] - 29s 75ms/step - loss: 2.3103 - accuracy: 0.0977 - val_loss: 2.3068 - val_accuracy: 0.1014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3vw0-whti4F",
        "colab_type": "code",
        "outputId": "38d80f4d-ca08-4f9e-b3a6-68e52ee68567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "resnet_loss=model.evaluate(x_test,y_test,steps=100,verbose=0)\n",
        "print(\"Accuracy of the Resnet is \",resnet_loss[1]*100)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the Resnet is  8.699999749660492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8cKfAOjpn7c",
        "colab_type": "text"
      },
      "source": [
        "### Task 2.3 Performance comparison\n",
        "\n",
        "*(weight ~3%)*\n",
        "\n",
        "Based on the above experiments, which method or which combination of methods result in the best accuracy with the same training time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmw0VlCUovvS",
        "colab_type": "text"
      },
      "source": [
        "Training the CIFAR10 dataset with a shallow CNN shows better accuracy when compared to training a Resnet50."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUV0wuZ01DNA",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**END OF ASSIGNMENT TWO**"
      ]
    }
  ]
}