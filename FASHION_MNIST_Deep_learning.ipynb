{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FASHION-MNIST Deep learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VidyaDaya/my-projects/blob/master/FASHION_MNIST_Deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOr2bP8kAzKE"
      },
      "source": [
        "## Objective\n",
        "\n",
        "Demonstrate the knowledge in deep learning that you have acquired from the lectures and practical lab materials.\n",
        "We work with Fashion-MNIST dataset for image recognition. The dataset contains 10 classes of 28x28 grayscale images. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oySOPK4saPD0",
        "outputId": "859d2ea5-c49b-4a0d-ebe1-ccd5b32a2c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n",
            "2.3.0-tf\n",
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDqvFgbRAzKG"
      },
      "source": [
        "## Task 1 Load the data\n",
        "\n",
        "\n",
        "\n",
        "Load the Fashion MNIST dataset (https://github.com/zalandoresearch/fashion-mnist). You may get the data via Keras (keras.datasets) or Tensorflow Datasets (tfds). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUim3j-LaPD5",
        "outputId": "cb470c85-51b6-42c6-e96f-877df5d53044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHHg8sj0C0nn",
        "outputId": "ed5b9e16-5cd9-40e2-fdbb-3862a2359aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFbty6i5AzKm"
      },
      "source": [
        "## Task 2 Understand the data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLYAtx-ZAzKo"
      },
      "source": [
        "Display 100 images from the train set in the form of 10x10 matrix.\n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "1. What are the unique labels in this dataset?\n",
        "2. How many training images and how many test images?\n",
        "3. What is the size of each image?\n",
        "4. Find out the numeric range of the input. Do we need to rescale the input?\n",
        "5. In our problem, what are the shapes of input tensors and target tensors? Do you need to reshape the input?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25DG4K0LaPD9",
        "outputId": "d58146a5-cc1b-4b92-e3ae-f30dda71623f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "image_index = 0 \n",
        "f, axarr = plt.subplots(10,10)\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        axarr[i,j].imshow(x_train[image_index])\n",
        "        image_index+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 100 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LchfEi36aPEA",
        "outputId": "069962a4-fd4d-42bd-a7d6-13aefd03f096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('Unique labels in dataset')\n",
        "u = np.unique(y_train)\n",
        "print(u)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique labels in dataset\n",
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmc0zH8eaPED",
        "outputId": "53620c18-df49-48bb-821b-e5c23fea71b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"Number of training images\")\n",
        "print(x_train.shape[0])\n",
        "print(\"Number of testing images\")\n",
        "print(x_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training images\n",
            "60000\n",
            "Number of testing images\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLUPr4bSaPEG",
        "outputId": "19693250-08f6-45de-e3e2-a7cceebbc813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Size of each image\")\n",
        "print(x_train.shape[1]*x_train.shape[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of each image\n",
            "784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y4p7p-NplRg",
        "outputId": "b0d399ac-229b-4b57-9fd2-6a8897506976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "val_range= x_train.ptp()\n",
        "print(\"Numeric range of the input is till \", val_range)\n",
        "print(\"We need to normalize the input and bring down its value between 0 and 1\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numeric range of the input is till  255\n",
            "We need to normalize the input and bring down its value between 0 and 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv9CmpsraPEJ",
        "outputId": "5f16c4d3-63a5-41d8-d147-57649b5e0d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Input tensor shape is \",x_train.shape)\n",
        "print(\"Taget tensor shape is  \",y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input tensor shape is  (60000, 28, 28)\n",
            "Taget tensor shape is   (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkVa_VjriCJi"
      },
      "source": [
        "We don't need to reshape the input and target tensors.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdfHpBGgC1Zz"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tkl-PwsrXip"
      },
      "source": [
        "## Task 3 Construct an input pipeline\n",
        "\n",
        "\n",
        "\n",
        "Creat train/validate/test data splits and construct tf.data pipelines. Make sure that the training data is batched.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTyhqX0QPmWt"
      },
      "source": [
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk_GWhw_KFyo",
        "outputId": "1da0b62b-19a7-4f1b-98db-4f47c4ea9094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dataset=tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "for image,label in train_dataset.take(1):\n",
        "  print(image.shape,label.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28) (10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa25Lj1lQSF6"
      },
      "source": [
        "def preprocess(image,label):\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = image / 255\n",
        "  return image, label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--WhjZvR3OaA"
      },
      "source": [
        "train_dataset = (train_dataset.map(preprocess).shuffle(buffer_size=50000).batch(128,drop_remainder=True).cache().repeat())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYe7PHtcoAPj"
      },
      "source": [
        "test_dataset=(test_dataset.map(preprocess).batch(128,drop_remainder=True).cache().repeat())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnE7ZFS_AzLg"
      },
      "source": [
        "## Task 4 Construct a deep forward neural network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChlhkwhkAzLi"
      },
      "source": [
        "### Task 4.1 Setting up a model for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuxhQM6jAzLl"
      },
      "source": [
        "Construct a deep feedforward neural network. You need to decide and report the following configurations:\n",
        "\n",
        "- Output layer: \n",
        "    - How many output nodes?\n",
        "    - Which activation function?\n",
        "- Hidden layers:\n",
        "    - How many hidden layers?\n",
        "    - How many nodes in each layer?\n",
        "    - Which activation function for each layer?\n",
        "- Input layer\n",
        "    - What is the input size?\n",
        "- The loss function\n",
        "- The metrics for model evaluation (which may be different from the loss function)\n",
        "- The optimiser\n",
        "\n",
        "Justify your model design decisions.\n",
        "\n",
        "Plot the model structure `using keras.utils.plot_model` or similar tools."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXlJ0nx5kB0e"
      },
      "source": [
        "Output layer:\n",
        "We are having 10 output nodes and we are using softmax activation function for the output layer.\n",
        "Hidden layers:\n",
        "We have 2 hidden layers for our model and each layer has 128 nodes. For both the hidden layers, we have relu as the activation function.\n",
        "Input layer:\n",
        "The input size is (28,28) as mentioned in the model.\n",
        "For the model, we also use categorical crossentropy as the loss function, accuracy as the metric and adam as the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZkNHB78ogvS"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))\n",
        "model.compile(optimizer = Adam(learning_rate=0.01),loss='categorical_crossentropy',metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKwVVFbbJaXJ",
        "outputId": "e84ef864-98fc-4743-c5a1-d8850b8c2759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "tf.keras.utils.plot_model(model, to_file='model.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s2RlHBS9YQY",
        "outputId": "4be25595-5182-4ef7-8102-fba2e0def718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ2BVK5tAzMM"
      },
      "source": [
        "### Task 4.2 Fitting the model\n",
        "\n",
        "Now fit the model. Decide and report the following training setting:\n",
        "\n",
        "1. The training batch size\n",
        "2. The number of training epochs (at least 1,000 epochs recommended)\n",
        "3. The learning rate. If you used momentum or a learning rate schedule, please report the configuration as well.\n",
        "\n",
        "Plot the training and validation loss and accuracy. Answer the following questions:\n",
        "\n",
        "1. Do you see overfitting or underfitting? Why?\n",
        "2. If you see overfitting, at which epoch did it happen?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVq2Qj4Stq-7"
      },
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "root_logdir=\"logs\"\n",
        "run_id=datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir=os.path.join(root_logdir,run_id)\n",
        "tf.compat.v1.reset_default_graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw8GP0vjtsOm"
      },
      "source": [
        "!rm -rf ./logs/\n",
        "file_writer=tf.summary.create_file_writer(logdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjUruKlqtlhO",
        "outputId": "5cf1d3a0-ddf3-48e4-c6f9-b6c980da1359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "keras.callbacks.TensorBoard(\n",
        "  log_dir=logdir,\n",
        "  histogram_freq=1,  # How often to log histogram visualizations\n",
        "  embeddings_freq=0,  # How often to log embedding visualizations\n",
        "  update_freq='batch')  # How often to write logs (default: once per epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.TensorBoard at 0x7f00f538e470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgb1fpYmaBQT"
      },
      "source": [
        "The batch size we are using is 128. We are going to fit the model over 1000 epochs. For the optimizer- Adam we use a learning rate of 0.01."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzXBBjqBODiz",
        "outputId": "fdf02b88-f1c1-4a2b-84fe-7c3bc87a7350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "BATCH_SIZE=128\n",
        "EPOCHS=1000\n",
        "STEPS_PER_EPOCH=100\n",
        "tensorboard_cbk = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "history=model.fit(train_dataset,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=test_dataset,steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,verbose=1,shuffle=True,callbacks=[tensorboard_cbk])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 1.1581 - accuracy: 0.5583 - val_loss: 0.7754 - val_accuracy: 0.7059\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6701 - accuracy: 0.7479 - val_loss: 0.6446 - val_accuracy: 0.7623\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5761 - accuracy: 0.7889 - val_loss: 0.5692 - val_accuracy: 0.7970\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5477 - accuracy: 0.8005 - val_loss: 0.5536 - val_accuracy: 0.8031\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4996 - accuracy: 0.8184 - val_loss: 0.5264 - val_accuracy: 0.8127\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4935 - accuracy: 0.8219 - val_loss: 0.5298 - val_accuracy: 0.8091\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4538 - accuracy: 0.8322 - val_loss: 0.4875 - val_accuracy: 0.8277\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4394 - accuracy: 0.8406 - val_loss: 0.4812 - val_accuracy: 0.8255\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4388 - accuracy: 0.8377 - val_loss: 0.4469 - val_accuracy: 0.8411\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4373 - accuracy: 0.8417 - val_loss: 0.4560 - val_accuracy: 0.8377\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4159 - accuracy: 0.8481 - val_loss: 0.4467 - val_accuracy: 0.8394\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3972 - accuracy: 0.8546 - val_loss: 0.4248 - val_accuracy: 0.8478\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3942 - accuracy: 0.8575 - val_loss: 0.4527 - val_accuracy: 0.8388\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3837 - accuracy: 0.8562 - val_loss: 0.4654 - val_accuracy: 0.8378\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4025 - accuracy: 0.8539 - val_loss: 0.4364 - val_accuracy: 0.8452\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3795 - accuracy: 0.8592 - val_loss: 0.4082 - val_accuracy: 0.8573\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3628 - accuracy: 0.8698 - val_loss: 0.4022 - val_accuracy: 0.8591\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3707 - accuracy: 0.8651 - val_loss: 0.3926 - val_accuracy: 0.8612\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3631 - accuracy: 0.8659 - val_loss: 0.4110 - val_accuracy: 0.8534\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3740 - accuracy: 0.8645 - val_loss: 0.4078 - val_accuracy: 0.8539\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3431 - accuracy: 0.8746 - val_loss: 0.3968 - val_accuracy: 0.8541\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3443 - accuracy: 0.8745 - val_loss: 0.4053 - val_accuracy: 0.8545\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3513 - accuracy: 0.8709 - val_loss: 0.4188 - val_accuracy: 0.8480\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3555 - accuracy: 0.8705 - val_loss: 0.3845 - val_accuracy: 0.8628\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3372 - accuracy: 0.8783 - val_loss: 0.3853 - val_accuracy: 0.8612\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3289 - accuracy: 0.8799 - val_loss: 0.3971 - val_accuracy: 0.8564\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3320 - accuracy: 0.8791 - val_loss: 0.4107 - val_accuracy: 0.8505\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3293 - accuracy: 0.8779 - val_loss: 0.4061 - val_accuracy: 0.8523\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3366 - accuracy: 0.8754 - val_loss: 0.4093 - val_accuracy: 0.8556\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3205 - accuracy: 0.8827 - val_loss: 0.3985 - val_accuracy: 0.8578\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3161 - accuracy: 0.8844 - val_loss: 0.3843 - val_accuracy: 0.8656\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3205 - accuracy: 0.8820 - val_loss: 0.3801 - val_accuracy: 0.8631\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3145 - accuracy: 0.8874 - val_loss: 0.3767 - val_accuracy: 0.8644\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3220 - accuracy: 0.8809 - val_loss: 0.3702 - val_accuracy: 0.8652\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2989 - accuracy: 0.8914 - val_loss: 0.3687 - val_accuracy: 0.8702\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3080 - accuracy: 0.8855 - val_loss: 0.3793 - val_accuracy: 0.8661\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3106 - accuracy: 0.8856 - val_loss: 0.3788 - val_accuracy: 0.8609\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3116 - accuracy: 0.8849 - val_loss: 0.3705 - val_accuracy: 0.8678\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2993 - accuracy: 0.8892 - val_loss: 0.3825 - val_accuracy: 0.8587\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2989 - accuracy: 0.8898 - val_loss: 0.3739 - val_accuracy: 0.8666\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2995 - accuracy: 0.8910 - val_loss: 0.4182 - val_accuracy: 0.8525\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2996 - accuracy: 0.8889 - val_loss: 0.3539 - val_accuracy: 0.8734\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3003 - accuracy: 0.8878 - val_loss: 0.3947 - val_accuracy: 0.8606\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2924 - accuracy: 0.8915 - val_loss: 0.3736 - val_accuracy: 0.8691\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2868 - accuracy: 0.8943 - val_loss: 0.4203 - val_accuracy: 0.8545\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2969 - accuracy: 0.8895 - val_loss: 0.3674 - val_accuracy: 0.8662\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2841 - accuracy: 0.8951 - val_loss: 0.3775 - val_accuracy: 0.8652\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2898 - accuracy: 0.8892 - val_loss: 0.3773 - val_accuracy: 0.8627\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2812 - accuracy: 0.8980 - val_loss: 0.3632 - val_accuracy: 0.8684\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2833 - accuracy: 0.8946 - val_loss: 0.3720 - val_accuracy: 0.8662\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2846 - accuracy: 0.8937 - val_loss: 0.3666 - val_accuracy: 0.8719\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2804 - accuracy: 0.8945 - val_loss: 0.3581 - val_accuracy: 0.8734\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2784 - accuracy: 0.8966 - val_loss: 0.3577 - val_accuracy: 0.8711\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2718 - accuracy: 0.9002 - val_loss: 0.3812 - val_accuracy: 0.8667\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2757 - accuracy: 0.8978 - val_loss: 0.3864 - val_accuracy: 0.8659\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2765 - accuracy: 0.8963 - val_loss: 0.3619 - val_accuracy: 0.8691\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2744 - accuracy: 0.8957 - val_loss: 0.3803 - val_accuracy: 0.8670\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2690 - accuracy: 0.9009 - val_loss: 0.3694 - val_accuracy: 0.8683\n",
            "Epoch 59/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2683 - accuracy: 0.8995 - val_loss: 0.3608 - val_accuracy: 0.8714\n",
            "Epoch 60/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2687 - accuracy: 0.8997 - val_loss: 0.3752 - val_accuracy: 0.8681\n",
            "Epoch 61/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2654 - accuracy: 0.8995 - val_loss: 0.3737 - val_accuracy: 0.8675\n",
            "Epoch 62/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2699 - accuracy: 0.8991 - val_loss: 0.3663 - val_accuracy: 0.8675\n",
            "Epoch 63/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2584 - accuracy: 0.9056 - val_loss: 0.3531 - val_accuracy: 0.8775\n",
            "Epoch 64/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2675 - accuracy: 0.9006 - val_loss: 0.3637 - val_accuracy: 0.8711\n",
            "Epoch 65/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2638 - accuracy: 0.8995 - val_loss: 0.3659 - val_accuracy: 0.8722\n",
            "Epoch 66/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2612 - accuracy: 0.9008 - val_loss: 0.3765 - val_accuracy: 0.8694\n",
            "Epoch 67/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2622 - accuracy: 0.9035 - val_loss: 0.3766 - val_accuracy: 0.8656\n",
            "Epoch 68/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2526 - accuracy: 0.9058 - val_loss: 0.3926 - val_accuracy: 0.8695\n",
            "Epoch 69/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2587 - accuracy: 0.9028 - val_loss: 0.3873 - val_accuracy: 0.8636\n",
            "Epoch 70/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2576 - accuracy: 0.9009 - val_loss: 0.3690 - val_accuracy: 0.8695\n",
            "Epoch 71/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2551 - accuracy: 0.9054 - val_loss: 0.3597 - val_accuracy: 0.8730\n",
            "Epoch 72/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2506 - accuracy: 0.9073 - val_loss: 0.3822 - val_accuracy: 0.8672\n",
            "Epoch 73/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2552 - accuracy: 0.9036 - val_loss: 0.3664 - val_accuracy: 0.8695\n",
            "Epoch 74/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2493 - accuracy: 0.9056 - val_loss: 0.3625 - val_accuracy: 0.8734\n",
            "Epoch 75/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2473 - accuracy: 0.9077 - val_loss: 0.3671 - val_accuracy: 0.8697\n",
            "Epoch 76/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2494 - accuracy: 0.9054 - val_loss: 0.3754 - val_accuracy: 0.8714\n",
            "Epoch 77/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2471 - accuracy: 0.9080 - val_loss: 0.3556 - val_accuracy: 0.8792\n",
            "Epoch 78/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2449 - accuracy: 0.9089 - val_loss: 0.3670 - val_accuracy: 0.8680\n",
            "Epoch 79/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2488 - accuracy: 0.9059 - val_loss: 0.3642 - val_accuracy: 0.8750\n",
            "Epoch 80/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2414 - accuracy: 0.9098 - val_loss: 0.3809 - val_accuracy: 0.8756\n",
            "Epoch 81/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2476 - accuracy: 0.9043 - val_loss: 0.3665 - val_accuracy: 0.8727\n",
            "Epoch 82/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2411 - accuracy: 0.9112 - val_loss: 0.3729 - val_accuracy: 0.8748\n",
            "Epoch 83/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2382 - accuracy: 0.9112 - val_loss: 0.3678 - val_accuracy: 0.8717\n",
            "Epoch 84/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2406 - accuracy: 0.9095 - val_loss: 0.3789 - val_accuracy: 0.8670\n",
            "Epoch 85/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2405 - accuracy: 0.9079 - val_loss: 0.3534 - val_accuracy: 0.8759\n",
            "Epoch 86/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2369 - accuracy: 0.9115 - val_loss: 0.3708 - val_accuracy: 0.8752\n",
            "Epoch 87/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2404 - accuracy: 0.9099 - val_loss: 0.3739 - val_accuracy: 0.8683\n",
            "Epoch 88/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2329 - accuracy: 0.9114 - val_loss: 0.3848 - val_accuracy: 0.8692\n",
            "Epoch 89/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2402 - accuracy: 0.9112 - val_loss: 0.3619 - val_accuracy: 0.8792\n",
            "Epoch 90/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2271 - accuracy: 0.9111 - val_loss: 0.3736 - val_accuracy: 0.8697\n",
            "Epoch 91/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2411 - accuracy: 0.9105 - val_loss: 0.3748 - val_accuracy: 0.8783\n",
            "Epoch 92/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2380 - accuracy: 0.9090 - val_loss: 0.4132 - val_accuracy: 0.8628\n",
            "Epoch 93/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2317 - accuracy: 0.9123 - val_loss: 0.3661 - val_accuracy: 0.8730\n",
            "Epoch 94/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2332 - accuracy: 0.9114 - val_loss: 0.3852 - val_accuracy: 0.8742\n",
            "Epoch 95/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2341 - accuracy: 0.9116 - val_loss: 0.4426 - val_accuracy: 0.8555\n",
            "Epoch 96/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2326 - accuracy: 0.9134 - val_loss: 0.4309 - val_accuracy: 0.8547\n",
            "Epoch 97/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2317 - accuracy: 0.9132 - val_loss: 0.4055 - val_accuracy: 0.8700\n",
            "Epoch 98/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2276 - accuracy: 0.9140 - val_loss: 0.4064 - val_accuracy: 0.8589\n",
            "Epoch 99/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2285 - accuracy: 0.9112 - val_loss: 0.3938 - val_accuracy: 0.8639\n",
            "Epoch 100/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2286 - accuracy: 0.9147 - val_loss: 0.3758 - val_accuracy: 0.8758\n",
            "Epoch 101/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2284 - accuracy: 0.9144 - val_loss: 0.4013 - val_accuracy: 0.8670\n",
            "Epoch 102/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2275 - accuracy: 0.9142 - val_loss: 0.3938 - val_accuracy: 0.8687\n",
            "Epoch 103/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2247 - accuracy: 0.9165 - val_loss: 0.3842 - val_accuracy: 0.8694\n",
            "Epoch 104/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2181 - accuracy: 0.9166 - val_loss: 0.4239 - val_accuracy: 0.8577\n",
            "Epoch 105/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2270 - accuracy: 0.9144 - val_loss: 0.3864 - val_accuracy: 0.8747\n",
            "Epoch 106/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2222 - accuracy: 0.9173 - val_loss: 0.3952 - val_accuracy: 0.8733\n",
            "Epoch 107/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2238 - accuracy: 0.9152 - val_loss: 0.3706 - val_accuracy: 0.8773\n",
            "Epoch 108/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2220 - accuracy: 0.9162 - val_loss: 0.3769 - val_accuracy: 0.8761\n",
            "Epoch 109/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2260 - accuracy: 0.9127 - val_loss: 0.3922 - val_accuracy: 0.8742\n",
            "Epoch 110/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2181 - accuracy: 0.9162 - val_loss: 0.3801 - val_accuracy: 0.8736\n",
            "Epoch 111/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2193 - accuracy: 0.9171 - val_loss: 0.3933 - val_accuracy: 0.8769\n",
            "Epoch 112/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2175 - accuracy: 0.9164 - val_loss: 0.3943 - val_accuracy: 0.8709\n",
            "Epoch 113/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2170 - accuracy: 0.9160 - val_loss: 0.4072 - val_accuracy: 0.8666\n",
            "Epoch 114/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2231 - accuracy: 0.9161 - val_loss: 0.3800 - val_accuracy: 0.8761\n",
            "Epoch 115/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2121 - accuracy: 0.9204 - val_loss: 0.4039 - val_accuracy: 0.8700\n",
            "Epoch 116/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2203 - accuracy: 0.9155 - val_loss: 0.4081 - val_accuracy: 0.8722\n",
            "Epoch 117/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2198 - accuracy: 0.9166 - val_loss: 0.3946 - val_accuracy: 0.8691\n",
            "Epoch 118/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2091 - accuracy: 0.9199 - val_loss: 0.3840 - val_accuracy: 0.8752\n",
            "Epoch 119/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2265 - accuracy: 0.9134 - val_loss: 0.3930 - val_accuracy: 0.8734\n",
            "Epoch 120/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2210 - accuracy: 0.9159 - val_loss: 0.3841 - val_accuracy: 0.8723\n",
            "Epoch 121/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2159 - accuracy: 0.9176 - val_loss: 0.3798 - val_accuracy: 0.8734\n",
            "Epoch 122/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2096 - accuracy: 0.9220 - val_loss: 0.4106 - val_accuracy: 0.8741\n",
            "Epoch 123/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2156 - accuracy: 0.9161 - val_loss: 0.4159 - val_accuracy: 0.8673\n",
            "Epoch 124/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2068 - accuracy: 0.9230 - val_loss: 0.3961 - val_accuracy: 0.8753\n",
            "Epoch 125/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2111 - accuracy: 0.9194 - val_loss: 0.3973 - val_accuracy: 0.8798\n",
            "Epoch 126/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2164 - accuracy: 0.9176 - val_loss: 0.4164 - val_accuracy: 0.8677\n",
            "Epoch 127/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2110 - accuracy: 0.9187 - val_loss: 0.4299 - val_accuracy: 0.8680\n",
            "Epoch 128/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2162 - accuracy: 0.9173 - val_loss: 0.3987 - val_accuracy: 0.8694\n",
            "Epoch 129/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2068 - accuracy: 0.9221 - val_loss: 0.3947 - val_accuracy: 0.8773\n",
            "Epoch 130/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2087 - accuracy: 0.9213 - val_loss: 0.4328 - val_accuracy: 0.8705\n",
            "Epoch 131/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2172 - accuracy: 0.9186 - val_loss: 0.3947 - val_accuracy: 0.8752\n",
            "Epoch 132/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2014 - accuracy: 0.9236 - val_loss: 0.4032 - val_accuracy: 0.8725\n",
            "Epoch 133/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2128 - accuracy: 0.9207 - val_loss: 0.4144 - val_accuracy: 0.8698\n",
            "Epoch 134/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2027 - accuracy: 0.9236 - val_loss: 0.4126 - val_accuracy: 0.8697\n",
            "Epoch 135/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2080 - accuracy: 0.9210 - val_loss: 0.4048 - val_accuracy: 0.8756\n",
            "Epoch 136/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2069 - accuracy: 0.9235 - val_loss: 0.4016 - val_accuracy: 0.8797\n",
            "Epoch 137/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2038 - accuracy: 0.9221 - val_loss: 0.4126 - val_accuracy: 0.8813\n",
            "Epoch 138/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2017 - accuracy: 0.9256 - val_loss: 0.4082 - val_accuracy: 0.8756\n",
            "Epoch 139/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2062 - accuracy: 0.9209 - val_loss: 0.4080 - val_accuracy: 0.8736\n",
            "Epoch 140/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2018 - accuracy: 0.9241 - val_loss: 0.4133 - val_accuracy: 0.8717\n",
            "Epoch 141/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1988 - accuracy: 0.9247 - val_loss: 0.4095 - val_accuracy: 0.8770\n",
            "Epoch 142/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2046 - accuracy: 0.9239 - val_loss: 0.4036 - val_accuracy: 0.8719\n",
            "Epoch 143/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1929 - accuracy: 0.9242 - val_loss: 0.4113 - val_accuracy: 0.8742\n",
            "Epoch 144/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1973 - accuracy: 0.9251 - val_loss: 0.4373 - val_accuracy: 0.8697\n",
            "Epoch 145/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2046 - accuracy: 0.9220 - val_loss: 0.4226 - val_accuracy: 0.8680\n",
            "Epoch 146/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1920 - accuracy: 0.9272 - val_loss: 0.4507 - val_accuracy: 0.8655\n",
            "Epoch 147/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1950 - accuracy: 0.9269 - val_loss: 0.4191 - val_accuracy: 0.8739\n",
            "Epoch 148/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1968 - accuracy: 0.9255 - val_loss: 0.4178 - val_accuracy: 0.8739\n",
            "Epoch 149/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1950 - accuracy: 0.9245 - val_loss: 0.4104 - val_accuracy: 0.8780\n",
            "Epoch 150/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1955 - accuracy: 0.9265 - val_loss: 0.4084 - val_accuracy: 0.8717\n",
            "Epoch 151/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1967 - accuracy: 0.9238 - val_loss: 0.4432 - val_accuracy: 0.8709\n",
            "Epoch 152/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1895 - accuracy: 0.9292 - val_loss: 0.4290 - val_accuracy: 0.8786\n",
            "Epoch 153/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1960 - accuracy: 0.9241 - val_loss: 0.4081 - val_accuracy: 0.8706\n",
            "Epoch 154/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1848 - accuracy: 0.9292 - val_loss: 0.4294 - val_accuracy: 0.8736\n",
            "Epoch 155/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1861 - accuracy: 0.9289 - val_loss: 0.4378 - val_accuracy: 0.8747\n",
            "Epoch 156/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1950 - accuracy: 0.9262 - val_loss: 0.4320 - val_accuracy: 0.8741\n",
            "Epoch 157/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1892 - accuracy: 0.9271 - val_loss: 0.4580 - val_accuracy: 0.8666\n",
            "Epoch 158/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1905 - accuracy: 0.9268 - val_loss: 0.4093 - val_accuracy: 0.8775\n",
            "Epoch 159/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1933 - accuracy: 0.9238 - val_loss: 0.4581 - val_accuracy: 0.8620\n",
            "Epoch 160/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1882 - accuracy: 0.9268 - val_loss: 0.5141 - val_accuracy: 0.8627\n",
            "Epoch 161/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1900 - accuracy: 0.9269 - val_loss: 0.4192 - val_accuracy: 0.8784\n",
            "Epoch 162/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1918 - accuracy: 0.9266 - val_loss: 0.4726 - val_accuracy: 0.8681\n",
            "Epoch 163/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1936 - accuracy: 0.9272 - val_loss: 0.4394 - val_accuracy: 0.8698\n",
            "Epoch 164/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1871 - accuracy: 0.9291 - val_loss: 0.4440 - val_accuracy: 0.8627\n",
            "Epoch 165/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1822 - accuracy: 0.9294 - val_loss: 0.4295 - val_accuracy: 0.8772\n",
            "Epoch 166/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2009 - accuracy: 0.9257 - val_loss: 0.4233 - val_accuracy: 0.8781\n",
            "Epoch 167/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1937 - accuracy: 0.9258 - val_loss: 0.4291 - val_accuracy: 0.8697\n",
            "Epoch 168/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1913 - accuracy: 0.9257 - val_loss: 0.4449 - val_accuracy: 0.8739\n",
            "Epoch 169/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1885 - accuracy: 0.9292 - val_loss: 0.4342 - val_accuracy: 0.8777\n",
            "Epoch 170/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1922 - accuracy: 0.9254 - val_loss: 0.4228 - val_accuracy: 0.8775\n",
            "Epoch 171/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1809 - accuracy: 0.9342 - val_loss: 0.4447 - val_accuracy: 0.8666\n",
            "Epoch 172/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1904 - accuracy: 0.9266 - val_loss: 0.4170 - val_accuracy: 0.8755\n",
            "Epoch 173/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1870 - accuracy: 0.9297 - val_loss: 0.4501 - val_accuracy: 0.8670\n",
            "Epoch 174/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1821 - accuracy: 0.9308 - val_loss: 0.4667 - val_accuracy: 0.8695\n",
            "Epoch 175/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1882 - accuracy: 0.9290 - val_loss: 0.4364 - val_accuracy: 0.8705\n",
            "Epoch 176/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1924 - accuracy: 0.9291 - val_loss: 0.4382 - val_accuracy: 0.8730\n",
            "Epoch 177/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1819 - accuracy: 0.9284 - val_loss: 0.4625 - val_accuracy: 0.8695\n",
            "Epoch 178/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1784 - accuracy: 0.9335 - val_loss: 0.4345 - val_accuracy: 0.8687\n",
            "Epoch 179/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1846 - accuracy: 0.9305 - val_loss: 0.4365 - val_accuracy: 0.8712\n",
            "Epoch 180/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1893 - accuracy: 0.9296 - val_loss: 0.4624 - val_accuracy: 0.8769\n",
            "Epoch 181/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1959 - accuracy: 0.9252 - val_loss: 0.4363 - val_accuracy: 0.8673\n",
            "Epoch 182/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1776 - accuracy: 0.9322 - val_loss: 0.4455 - val_accuracy: 0.8741\n",
            "Epoch 183/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1789 - accuracy: 0.9328 - val_loss: 0.4473 - val_accuracy: 0.8731\n",
            "Epoch 184/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1925 - accuracy: 0.9259 - val_loss: 0.4598 - val_accuracy: 0.8720\n",
            "Epoch 185/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1807 - accuracy: 0.9330 - val_loss: 0.4384 - val_accuracy: 0.8737\n",
            "Epoch 186/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1848 - accuracy: 0.9289 - val_loss: 0.4525 - val_accuracy: 0.8737\n",
            "Epoch 187/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1725 - accuracy: 0.9350 - val_loss: 0.4560 - val_accuracy: 0.8662\n",
            "Epoch 188/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1813 - accuracy: 0.9311 - val_loss: 0.4817 - val_accuracy: 0.8698\n",
            "Epoch 189/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1874 - accuracy: 0.9289 - val_loss: 0.4859 - val_accuracy: 0.8659\n",
            "Epoch 190/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1830 - accuracy: 0.9305 - val_loss: 0.5107 - val_accuracy: 0.8637\n",
            "Epoch 191/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1834 - accuracy: 0.9288 - val_loss: 0.4617 - val_accuracy: 0.8730\n",
            "Epoch 192/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1758 - accuracy: 0.9341 - val_loss: 0.4360 - val_accuracy: 0.8752\n",
            "Epoch 193/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1775 - accuracy: 0.9332 - val_loss: 0.4639 - val_accuracy: 0.8633\n",
            "Epoch 194/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1816 - accuracy: 0.9313 - val_loss: 0.4614 - val_accuracy: 0.8775\n",
            "Epoch 195/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1803 - accuracy: 0.9328 - val_loss: 0.4436 - val_accuracy: 0.8750\n",
            "Epoch 196/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1731 - accuracy: 0.9307 - val_loss: 0.4429 - val_accuracy: 0.8786\n",
            "Epoch 197/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1721 - accuracy: 0.9362 - val_loss: 0.4478 - val_accuracy: 0.8791\n",
            "Epoch 198/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1796 - accuracy: 0.9302 - val_loss: 0.4716 - val_accuracy: 0.8756\n",
            "Epoch 199/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1753 - accuracy: 0.9335 - val_loss: 0.4216 - val_accuracy: 0.8781\n",
            "Epoch 200/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1804 - accuracy: 0.9298 - val_loss: 0.4846 - val_accuracy: 0.8744\n",
            "Epoch 201/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1729 - accuracy: 0.9337 - val_loss: 0.4573 - val_accuracy: 0.8755\n",
            "Epoch 202/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1718 - accuracy: 0.9362 - val_loss: 0.4984 - val_accuracy: 0.8592\n",
            "Epoch 203/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1755 - accuracy: 0.9340 - val_loss: 0.4399 - val_accuracy: 0.8756\n",
            "Epoch 204/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1751 - accuracy: 0.9350 - val_loss: 0.5081 - val_accuracy: 0.8634\n",
            "Epoch 205/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1749 - accuracy: 0.9328 - val_loss: 0.4718 - val_accuracy: 0.8748\n",
            "Epoch 206/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1755 - accuracy: 0.9312 - val_loss: 0.4358 - val_accuracy: 0.8780\n",
            "Epoch 207/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1714 - accuracy: 0.9350 - val_loss: 0.4506 - val_accuracy: 0.8662\n",
            "Epoch 208/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1762 - accuracy: 0.9326 - val_loss: 0.4544 - val_accuracy: 0.8756\n",
            "Epoch 209/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1742 - accuracy: 0.9320 - val_loss: 0.4527 - val_accuracy: 0.8798\n",
            "Epoch 210/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1711 - accuracy: 0.9345 - val_loss: 0.4523 - val_accuracy: 0.8769\n",
            "Epoch 211/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1667 - accuracy: 0.9381 - val_loss: 0.4468 - val_accuracy: 0.8756\n",
            "Epoch 212/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1785 - accuracy: 0.9320 - val_loss: 0.4328 - val_accuracy: 0.8828\n",
            "Epoch 213/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1707 - accuracy: 0.9363 - val_loss: 0.4515 - val_accuracy: 0.8795\n",
            "Epoch 214/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1694 - accuracy: 0.9348 - val_loss: 0.4625 - val_accuracy: 0.8752\n",
            "Epoch 215/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1657 - accuracy: 0.9390 - val_loss: 0.4891 - val_accuracy: 0.8733\n",
            "Epoch 216/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1697 - accuracy: 0.9330 - val_loss: 0.5078 - val_accuracy: 0.8623\n",
            "Epoch 217/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1827 - accuracy: 0.9292 - val_loss: 0.4923 - val_accuracy: 0.8677\n",
            "Epoch 218/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1779 - accuracy: 0.9327 - val_loss: 0.4477 - val_accuracy: 0.8758\n",
            "Epoch 219/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1691 - accuracy: 0.9345 - val_loss: 0.4411 - val_accuracy: 0.8816\n",
            "Epoch 220/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1639 - accuracy: 0.9388 - val_loss: 0.4682 - val_accuracy: 0.8741\n",
            "Epoch 221/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1641 - accuracy: 0.9377 - val_loss: 0.4775 - val_accuracy: 0.8725\n",
            "Epoch 222/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1782 - accuracy: 0.9323 - val_loss: 0.5021 - val_accuracy: 0.8686\n",
            "Epoch 223/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1625 - accuracy: 0.9391 - val_loss: 0.5085 - val_accuracy: 0.8678\n",
            "Epoch 224/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1706 - accuracy: 0.9353 - val_loss: 0.4755 - val_accuracy: 0.8764\n",
            "Epoch 225/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1582 - accuracy: 0.9416 - val_loss: 0.4679 - val_accuracy: 0.8759\n",
            "Epoch 226/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1722 - accuracy: 0.9336 - val_loss: 0.5246 - val_accuracy: 0.8623\n",
            "Epoch 227/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1758 - accuracy: 0.9325 - val_loss: 0.5230 - val_accuracy: 0.8703\n",
            "Epoch 228/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1622 - accuracy: 0.9378 - val_loss: 0.4508 - val_accuracy: 0.8803\n",
            "Epoch 229/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1557 - accuracy: 0.9409 - val_loss: 0.4865 - val_accuracy: 0.8773\n",
            "Epoch 230/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1611 - accuracy: 0.9373 - val_loss: 0.5311 - val_accuracy: 0.8681\n",
            "Epoch 231/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1736 - accuracy: 0.9330 - val_loss: 0.4502 - val_accuracy: 0.8791\n",
            "Epoch 232/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1703 - accuracy: 0.9362 - val_loss: 0.4993 - val_accuracy: 0.8717\n",
            "Epoch 233/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1685 - accuracy: 0.9362 - val_loss: 0.4853 - val_accuracy: 0.8800\n",
            "Epoch 234/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1623 - accuracy: 0.9373 - val_loss: 0.5122 - val_accuracy: 0.8636\n",
            "Epoch 235/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1609 - accuracy: 0.9395 - val_loss: 0.4935 - val_accuracy: 0.8722\n",
            "Epoch 236/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1719 - accuracy: 0.9337 - val_loss: 0.4716 - val_accuracy: 0.8755\n",
            "Epoch 237/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1634 - accuracy: 0.9373 - val_loss: 0.5163 - val_accuracy: 0.8717\n",
            "Epoch 238/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1652 - accuracy: 0.9367 - val_loss: 0.4759 - val_accuracy: 0.8763\n",
            "Epoch 239/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1569 - accuracy: 0.9408 - val_loss: 0.5346 - val_accuracy: 0.8706\n",
            "Epoch 240/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1668 - accuracy: 0.9348 - val_loss: 0.5939 - val_accuracy: 0.8541\n",
            "Epoch 241/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1624 - accuracy: 0.9382 - val_loss: 0.5208 - val_accuracy: 0.8748\n",
            "Epoch 242/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1632 - accuracy: 0.9370 - val_loss: 0.4772 - val_accuracy: 0.8714\n",
            "Epoch 243/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1579 - accuracy: 0.9398 - val_loss: 0.5274 - val_accuracy: 0.8662\n",
            "Epoch 244/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1579 - accuracy: 0.9382 - val_loss: 0.5331 - val_accuracy: 0.8709\n",
            "Epoch 245/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1670 - accuracy: 0.9356 - val_loss: 0.4758 - val_accuracy: 0.8747\n",
            "Epoch 246/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1589 - accuracy: 0.9386 - val_loss: 0.5016 - val_accuracy: 0.8642\n",
            "Epoch 247/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1639 - accuracy: 0.9373 - val_loss: 0.4993 - val_accuracy: 0.8750\n",
            "Epoch 248/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1524 - accuracy: 0.9420 - val_loss: 0.4824 - val_accuracy: 0.8720\n",
            "Epoch 249/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1584 - accuracy: 0.9397 - val_loss: 0.5501 - val_accuracy: 0.8673\n",
            "Epoch 250/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1611 - accuracy: 0.9377 - val_loss: 0.4764 - val_accuracy: 0.8755\n",
            "Epoch 251/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1587 - accuracy: 0.9391 - val_loss: 0.5197 - val_accuracy: 0.8750\n",
            "Epoch 252/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1595 - accuracy: 0.9391 - val_loss: 0.5249 - val_accuracy: 0.8722\n",
            "Epoch 253/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1531 - accuracy: 0.9406 - val_loss: 0.4816 - val_accuracy: 0.8767\n",
            "Epoch 254/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1550 - accuracy: 0.9390 - val_loss: 0.5017 - val_accuracy: 0.8767\n",
            "Epoch 255/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1485 - accuracy: 0.9427 - val_loss: 0.4803 - val_accuracy: 0.8794\n",
            "Epoch 256/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1653 - accuracy: 0.9370 - val_loss: 0.5315 - val_accuracy: 0.8656\n",
            "Epoch 257/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1569 - accuracy: 0.9391 - val_loss: 0.5224 - val_accuracy: 0.8778\n",
            "Epoch 258/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1584 - accuracy: 0.9390 - val_loss: 0.5125 - val_accuracy: 0.8755\n",
            "Epoch 259/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1622 - accuracy: 0.9370 - val_loss: 0.4957 - val_accuracy: 0.8744\n",
            "Epoch 260/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1589 - accuracy: 0.9402 - val_loss: 0.4931 - val_accuracy: 0.8677\n",
            "Epoch 261/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1653 - accuracy: 0.9373 - val_loss: 0.5123 - val_accuracy: 0.8755\n",
            "Epoch 262/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1551 - accuracy: 0.9422 - val_loss: 0.5676 - val_accuracy: 0.8569\n",
            "Epoch 263/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1543 - accuracy: 0.9437 - val_loss: 0.5642 - val_accuracy: 0.8703\n",
            "Epoch 264/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1484 - accuracy: 0.9427 - val_loss: 0.5361 - val_accuracy: 0.8678\n",
            "Epoch 265/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1543 - accuracy: 0.9416 - val_loss: 0.5278 - val_accuracy: 0.8727\n",
            "Epoch 266/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1495 - accuracy: 0.9409 - val_loss: 0.5330 - val_accuracy: 0.8769\n",
            "Epoch 267/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1477 - accuracy: 0.9459 - val_loss: 0.5755 - val_accuracy: 0.8620\n",
            "Epoch 268/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1546 - accuracy: 0.9405 - val_loss: 0.4884 - val_accuracy: 0.8784\n",
            "Epoch 269/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1544 - accuracy: 0.9416 - val_loss: 0.5427 - val_accuracy: 0.8747\n",
            "Epoch 270/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1589 - accuracy: 0.9406 - val_loss: 0.5480 - val_accuracy: 0.8722\n",
            "Epoch 271/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1429 - accuracy: 0.9445 - val_loss: 0.5195 - val_accuracy: 0.8709\n",
            "Epoch 272/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1492 - accuracy: 0.9422 - val_loss: 0.5405 - val_accuracy: 0.8658\n",
            "Epoch 273/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1489 - accuracy: 0.9404 - val_loss: 0.4858 - val_accuracy: 0.8748\n",
            "Epoch 274/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1464 - accuracy: 0.9431 - val_loss: 0.4908 - val_accuracy: 0.8714\n",
            "Epoch 275/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1498 - accuracy: 0.9421 - val_loss: 0.5323 - val_accuracy: 0.8739\n",
            "Epoch 276/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1438 - accuracy: 0.9461 - val_loss: 0.4953 - val_accuracy: 0.8769\n",
            "Epoch 277/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1577 - accuracy: 0.9403 - val_loss: 0.5802 - val_accuracy: 0.8687\n",
            "Epoch 278/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1448 - accuracy: 0.9440 - val_loss: 0.5208 - val_accuracy: 0.8734\n",
            "Epoch 279/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1478 - accuracy: 0.9446 - val_loss: 0.5925 - val_accuracy: 0.8648\n",
            "Epoch 280/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1487 - accuracy: 0.9405 - val_loss: 0.5566 - val_accuracy: 0.8730\n",
            "Epoch 281/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1387 - accuracy: 0.9484 - val_loss: 0.5442 - val_accuracy: 0.8670\n",
            "Epoch 282/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1497 - accuracy: 0.9433 - val_loss: 0.5399 - val_accuracy: 0.8730\n",
            "Epoch 283/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1436 - accuracy: 0.9459 - val_loss: 0.5784 - val_accuracy: 0.8730\n",
            "Epoch 284/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1447 - accuracy: 0.9452 - val_loss: 0.5373 - val_accuracy: 0.8723\n",
            "Epoch 285/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1430 - accuracy: 0.9436 - val_loss: 0.5255 - val_accuracy: 0.8737\n",
            "Epoch 286/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1512 - accuracy: 0.9409 - val_loss: 0.5143 - val_accuracy: 0.8769\n",
            "Epoch 287/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1447 - accuracy: 0.9448 - val_loss: 0.5373 - val_accuracy: 0.8714\n",
            "Epoch 288/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1418 - accuracy: 0.9455 - val_loss: 0.5527 - val_accuracy: 0.8636\n",
            "Epoch 289/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1467 - accuracy: 0.9429 - val_loss: 0.5310 - val_accuracy: 0.8755\n",
            "Epoch 290/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1407 - accuracy: 0.9463 - val_loss: 0.5657 - val_accuracy: 0.8714\n",
            "Epoch 291/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1510 - accuracy: 0.9409 - val_loss: 0.5856 - val_accuracy: 0.8697\n",
            "Epoch 292/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1472 - accuracy: 0.9444 - val_loss: 0.5445 - val_accuracy: 0.8717\n",
            "Epoch 293/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1492 - accuracy: 0.9441 - val_loss: 0.5931 - val_accuracy: 0.8697\n",
            "Epoch 294/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1456 - accuracy: 0.9403 - val_loss: 0.5755 - val_accuracy: 0.8764\n",
            "Epoch 295/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1383 - accuracy: 0.9474 - val_loss: 0.4933 - val_accuracy: 0.8783\n",
            "Epoch 296/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1505 - accuracy: 0.9416 - val_loss: 0.5443 - val_accuracy: 0.8680\n",
            "Epoch 297/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1370 - accuracy: 0.9483 - val_loss: 0.5873 - val_accuracy: 0.8748\n",
            "Epoch 298/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1544 - accuracy: 0.9394 - val_loss: 0.5357 - val_accuracy: 0.8637\n",
            "Epoch 299/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1387 - accuracy: 0.9457 - val_loss: 0.5408 - val_accuracy: 0.8739\n",
            "Epoch 300/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1376 - accuracy: 0.9485 - val_loss: 0.5511 - val_accuracy: 0.8748\n",
            "Epoch 301/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1424 - accuracy: 0.9441 - val_loss: 0.5336 - val_accuracy: 0.8736\n",
            "Epoch 302/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1357 - accuracy: 0.9488 - val_loss: 0.5307 - val_accuracy: 0.8670\n",
            "Epoch 303/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1450 - accuracy: 0.9457 - val_loss: 0.5462 - val_accuracy: 0.8734\n",
            "Epoch 304/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1254 - accuracy: 0.9532 - val_loss: 0.5489 - val_accuracy: 0.8778\n",
            "Epoch 305/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1384 - accuracy: 0.9463 - val_loss: 0.5917 - val_accuracy: 0.8694\n",
            "Epoch 306/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1351 - accuracy: 0.9459 - val_loss: 0.5256 - val_accuracy: 0.8764\n",
            "Epoch 307/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1344 - accuracy: 0.9480 - val_loss: 0.6149 - val_accuracy: 0.8612\n",
            "Epoch 308/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1431 - accuracy: 0.9432 - val_loss: 0.5558 - val_accuracy: 0.8773\n",
            "Epoch 309/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1362 - accuracy: 0.9476 - val_loss: 0.5847 - val_accuracy: 0.8659\n",
            "Epoch 310/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9463 - val_loss: 0.5840 - val_accuracy: 0.8656\n",
            "Epoch 311/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1339 - accuracy: 0.9491 - val_loss: 0.5827 - val_accuracy: 0.8717\n",
            "Epoch 312/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1412 - accuracy: 0.9469 - val_loss: 0.5650 - val_accuracy: 0.8687\n",
            "Epoch 313/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1338 - accuracy: 0.9484 - val_loss: 0.5598 - val_accuracy: 0.8719\n",
            "Epoch 314/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1362 - accuracy: 0.9480 - val_loss: 0.5764 - val_accuracy: 0.8711\n",
            "Epoch 315/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1450 - accuracy: 0.9430 - val_loss: 0.5478 - val_accuracy: 0.8752\n",
            "Epoch 316/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1352 - accuracy: 0.9479 - val_loss: 0.5738 - val_accuracy: 0.8683\n",
            "Epoch 317/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1498 - accuracy: 0.9410 - val_loss: 0.5600 - val_accuracy: 0.8681\n",
            "Epoch 318/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1283 - accuracy: 0.9494 - val_loss: 0.5727 - val_accuracy: 0.8736\n",
            "Epoch 319/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1388 - accuracy: 0.9457 - val_loss: 0.6250 - val_accuracy: 0.8545\n",
            "Epoch 320/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1371 - accuracy: 0.9484 - val_loss: 0.5264 - val_accuracy: 0.8778\n",
            "Epoch 321/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1309 - accuracy: 0.9506 - val_loss: 0.6248 - val_accuracy: 0.8659\n",
            "Epoch 322/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1479 - accuracy: 0.9406 - val_loss: 0.5558 - val_accuracy: 0.8805\n",
            "Epoch 323/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1297 - accuracy: 0.9516 - val_loss: 0.6248 - val_accuracy: 0.8644\n",
            "Epoch 324/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1338 - accuracy: 0.9498 - val_loss: 0.5639 - val_accuracy: 0.8691\n",
            "Epoch 325/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1339 - accuracy: 0.9487 - val_loss: 0.5609 - val_accuracy: 0.8734\n",
            "Epoch 326/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1364 - accuracy: 0.9459 - val_loss: 0.6698 - val_accuracy: 0.8631\n",
            "Epoch 327/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1429 - accuracy: 0.9458 - val_loss: 0.5932 - val_accuracy: 0.8733\n",
            "Epoch 328/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1268 - accuracy: 0.9509 - val_loss: 0.5896 - val_accuracy: 0.8730\n",
            "Epoch 329/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1319 - accuracy: 0.9489 - val_loss: 0.6021 - val_accuracy: 0.8695\n",
            "Epoch 330/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1343 - accuracy: 0.9488 - val_loss: 0.6118 - val_accuracy: 0.8723\n",
            "Epoch 331/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1438 - accuracy: 0.9451 - val_loss: 0.5803 - val_accuracy: 0.8697\n",
            "Epoch 332/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1301 - accuracy: 0.9498 - val_loss: 0.5709 - val_accuracy: 0.8763\n",
            "Epoch 333/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1332 - accuracy: 0.9487 - val_loss: 0.6156 - val_accuracy: 0.8633\n",
            "Epoch 334/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1371 - accuracy: 0.9464 - val_loss: 0.5746 - val_accuracy: 0.8677\n",
            "Epoch 335/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1409 - accuracy: 0.9473 - val_loss: 0.5832 - val_accuracy: 0.8694\n",
            "Epoch 336/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1490 - accuracy: 0.9399 - val_loss: 0.5500 - val_accuracy: 0.8763\n",
            "Epoch 337/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1395 - accuracy: 0.9473 - val_loss: 0.5509 - val_accuracy: 0.8720\n",
            "Epoch 338/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1332 - accuracy: 0.9495 - val_loss: 0.5997 - val_accuracy: 0.8653\n",
            "Epoch 339/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1366 - accuracy: 0.9481 - val_loss: 0.5697 - val_accuracy: 0.8698\n",
            "Epoch 340/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1331 - accuracy: 0.9501 - val_loss: 0.5911 - val_accuracy: 0.8675\n",
            "Epoch 341/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1337 - accuracy: 0.9484 - val_loss: 0.6136 - val_accuracy: 0.8769\n",
            "Epoch 342/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1263 - accuracy: 0.9528 - val_loss: 0.6020 - val_accuracy: 0.8750\n",
            "Epoch 343/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1265 - accuracy: 0.9506 - val_loss: 0.6216 - val_accuracy: 0.8683\n",
            "Epoch 344/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1263 - accuracy: 0.9527 - val_loss: 0.6126 - val_accuracy: 0.8683\n",
            "Epoch 345/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1414 - accuracy: 0.9448 - val_loss: 0.6030 - val_accuracy: 0.8625\n",
            "Epoch 346/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1292 - accuracy: 0.9505 - val_loss: 0.5871 - val_accuracy: 0.8788\n",
            "Epoch 347/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1311 - accuracy: 0.9491 - val_loss: 0.5907 - val_accuracy: 0.8683\n",
            "Epoch 348/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1272 - accuracy: 0.9509 - val_loss: 0.5559 - val_accuracy: 0.8759\n",
            "Epoch 349/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1233 - accuracy: 0.9533 - val_loss: 0.5866 - val_accuracy: 0.8683\n",
            "Epoch 350/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1388 - accuracy: 0.9443 - val_loss: 0.6040 - val_accuracy: 0.8755\n",
            "Epoch 351/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1220 - accuracy: 0.9526 - val_loss: 0.6091 - val_accuracy: 0.8703\n",
            "Epoch 352/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1301 - accuracy: 0.9482 - val_loss: 0.6646 - val_accuracy: 0.8672\n",
            "Epoch 353/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1315 - accuracy: 0.9482 - val_loss: 0.5332 - val_accuracy: 0.8781\n",
            "Epoch 354/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1309 - accuracy: 0.9513 - val_loss: 0.6571 - val_accuracy: 0.8625\n",
            "Epoch 355/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1397 - accuracy: 0.9475 - val_loss: 0.6191 - val_accuracy: 0.8731\n",
            "Epoch 356/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1267 - accuracy: 0.9516 - val_loss: 0.6020 - val_accuracy: 0.8755\n",
            "Epoch 357/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1328 - accuracy: 0.9470 - val_loss: 0.5965 - val_accuracy: 0.8742\n",
            "Epoch 358/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1243 - accuracy: 0.9539 - val_loss: 0.6065 - val_accuracy: 0.8719\n",
            "Epoch 359/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1341 - accuracy: 0.9463 - val_loss: 0.6314 - val_accuracy: 0.8691\n",
            "Epoch 360/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1214 - accuracy: 0.9531 - val_loss: 0.6672 - val_accuracy: 0.8561\n",
            "Epoch 361/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1237 - accuracy: 0.9538 - val_loss: 0.6221 - val_accuracy: 0.8667\n",
            "Epoch 362/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1236 - accuracy: 0.9515 - val_loss: 0.5940 - val_accuracy: 0.8680\n",
            "Epoch 363/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1247 - accuracy: 0.9532 - val_loss: 0.6455 - val_accuracy: 0.8656\n",
            "Epoch 364/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1431 - accuracy: 0.9448 - val_loss: 0.6142 - val_accuracy: 0.8706\n",
            "Epoch 365/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1277 - accuracy: 0.9522 - val_loss: 0.6023 - val_accuracy: 0.8716\n",
            "Epoch 366/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1249 - accuracy: 0.9525 - val_loss: 0.6834 - val_accuracy: 0.8667\n",
            "Epoch 367/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1198 - accuracy: 0.9532 - val_loss: 0.5719 - val_accuracy: 0.8758\n",
            "Epoch 368/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1245 - accuracy: 0.9530 - val_loss: 0.6446 - val_accuracy: 0.8670\n",
            "Epoch 369/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1376 - accuracy: 0.9464 - val_loss: 0.6243 - val_accuracy: 0.8731\n",
            "Epoch 370/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1165 - accuracy: 0.9534 - val_loss: 0.5964 - val_accuracy: 0.8722\n",
            "Epoch 371/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1248 - accuracy: 0.9511 - val_loss: 0.6238 - val_accuracy: 0.8739\n",
            "Epoch 372/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1182 - accuracy: 0.9552 - val_loss: 0.6325 - val_accuracy: 0.8753\n",
            "Epoch 373/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1354 - accuracy: 0.9477 - val_loss: 0.6157 - val_accuracy: 0.8720\n",
            "Epoch 374/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1258 - accuracy: 0.9507 - val_loss: 0.5916 - val_accuracy: 0.8744\n",
            "Epoch 375/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1284 - accuracy: 0.9505 - val_loss: 0.5977 - val_accuracy: 0.8716\n",
            "Epoch 376/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1167 - accuracy: 0.9538 - val_loss: 0.6091 - val_accuracy: 0.8759\n",
            "Epoch 377/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1222 - accuracy: 0.9540 - val_loss: 0.6336 - val_accuracy: 0.8687\n",
            "Epoch 378/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1338 - accuracy: 0.9465 - val_loss: 0.6553 - val_accuracy: 0.8714\n",
            "Epoch 379/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1263 - accuracy: 0.9512 - val_loss: 0.5925 - val_accuracy: 0.8719\n",
            "Epoch 380/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1376 - accuracy: 0.9477 - val_loss: 0.7158 - val_accuracy: 0.8672\n",
            "Epoch 381/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1177 - accuracy: 0.9543 - val_loss: 0.6395 - val_accuracy: 0.8763\n",
            "Epoch 382/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1181 - accuracy: 0.9547 - val_loss: 0.6549 - val_accuracy: 0.8719\n",
            "Epoch 383/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1294 - accuracy: 0.9502 - val_loss: 0.7120 - val_accuracy: 0.8675\n",
            "Epoch 384/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1212 - accuracy: 0.9542 - val_loss: 0.6459 - val_accuracy: 0.8637\n",
            "Epoch 385/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1278 - accuracy: 0.9516 - val_loss: 0.6662 - val_accuracy: 0.8661\n",
            "Epoch 386/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1107 - accuracy: 0.9592 - val_loss: 0.6233 - val_accuracy: 0.8775\n",
            "Epoch 387/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1312 - accuracy: 0.9480 - val_loss: 0.6397 - val_accuracy: 0.8683\n",
            "Epoch 388/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1238 - accuracy: 0.9524 - val_loss: 0.6614 - val_accuracy: 0.8692\n",
            "Epoch 389/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1296 - accuracy: 0.9492 - val_loss: 0.6687 - val_accuracy: 0.8722\n",
            "Epoch 390/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1232 - accuracy: 0.9521 - val_loss: 0.6190 - val_accuracy: 0.8747\n",
            "Epoch 391/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1112 - accuracy: 0.9573 - val_loss: 0.6701 - val_accuracy: 0.8730\n",
            "Epoch 392/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1263 - accuracy: 0.9509 - val_loss: 0.6612 - val_accuracy: 0.8739\n",
            "Epoch 393/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1265 - accuracy: 0.9509 - val_loss: 0.5919 - val_accuracy: 0.8723\n",
            "Epoch 394/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1433 - accuracy: 0.9474 - val_loss: 0.7675 - val_accuracy: 0.8645\n",
            "Epoch 395/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1176 - accuracy: 0.9563 - val_loss: 0.6387 - val_accuracy: 0.8756\n",
            "Epoch 396/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1220 - accuracy: 0.9527 - val_loss: 0.6302 - val_accuracy: 0.8795\n",
            "Epoch 397/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1306 - accuracy: 0.9488 - val_loss: 0.6332 - val_accuracy: 0.8681\n",
            "Epoch 398/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1212 - accuracy: 0.9539 - val_loss: 0.6398 - val_accuracy: 0.8684\n",
            "Epoch 399/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1211 - accuracy: 0.9534 - val_loss: 0.6654 - val_accuracy: 0.8702\n",
            "Epoch 400/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1140 - accuracy: 0.9589 - val_loss: 0.6842 - val_accuracy: 0.8756\n",
            "Epoch 401/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1200 - accuracy: 0.9533 - val_loss: 0.6882 - val_accuracy: 0.8669\n",
            "Epoch 402/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1240 - accuracy: 0.9520 - val_loss: 0.6599 - val_accuracy: 0.8783\n",
            "Epoch 403/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1235 - accuracy: 0.9527 - val_loss: 0.6755 - val_accuracy: 0.8727\n",
            "Epoch 404/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1142 - accuracy: 0.9542 - val_loss: 0.6593 - val_accuracy: 0.8759\n",
            "Epoch 405/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1032 - accuracy: 0.9620 - val_loss: 0.6746 - val_accuracy: 0.8767\n",
            "Epoch 406/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1202 - accuracy: 0.9536 - val_loss: 0.6824 - val_accuracy: 0.8736\n",
            "Epoch 407/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1218 - accuracy: 0.9529 - val_loss: 0.6555 - val_accuracy: 0.8734\n",
            "Epoch 408/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9504 - val_loss: 0.7497 - val_accuracy: 0.8605\n",
            "Epoch 409/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1158 - accuracy: 0.9557 - val_loss: 0.6644 - val_accuracy: 0.8719\n",
            "Epoch 410/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1245 - accuracy: 0.9517 - val_loss: 0.6641 - val_accuracy: 0.8680\n",
            "Epoch 411/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1287 - accuracy: 0.9497 - val_loss: 0.6543 - val_accuracy: 0.8678\n",
            "Epoch 412/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1204 - accuracy: 0.9522 - val_loss: 0.6928 - val_accuracy: 0.8667\n",
            "Epoch 413/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1259 - accuracy: 0.9519 - val_loss: 0.6527 - val_accuracy: 0.8711\n",
            "Epoch 414/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1062 - accuracy: 0.9598 - val_loss: 0.6512 - val_accuracy: 0.8783\n",
            "Epoch 415/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1161 - accuracy: 0.9551 - val_loss: 0.6954 - val_accuracy: 0.8669\n",
            "Epoch 416/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1185 - accuracy: 0.9520 - val_loss: 0.6648 - val_accuracy: 0.8773\n",
            "Epoch 417/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1250 - accuracy: 0.9521 - val_loss: 0.6727 - val_accuracy: 0.8736\n",
            "Epoch 418/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1187 - accuracy: 0.9543 - val_loss: 0.6724 - val_accuracy: 0.8747\n",
            "Epoch 419/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1069 - accuracy: 0.9598 - val_loss: 0.6831 - val_accuracy: 0.8703\n",
            "Epoch 420/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1222 - accuracy: 0.9519 - val_loss: 0.6612 - val_accuracy: 0.8717\n",
            "Epoch 421/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1135 - accuracy: 0.9556 - val_loss: 0.6486 - val_accuracy: 0.8712\n",
            "Epoch 422/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1259 - accuracy: 0.9520 - val_loss: 0.6693 - val_accuracy: 0.8675\n",
            "Epoch 423/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1101 - accuracy: 0.9583 - val_loss: 0.7092 - val_accuracy: 0.8750\n",
            "Epoch 424/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1087 - accuracy: 0.9577 - val_loss: 0.6992 - val_accuracy: 0.8644\n",
            "Epoch 425/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1153 - accuracy: 0.9552 - val_loss: 0.6913 - val_accuracy: 0.8714\n",
            "Epoch 426/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1261 - accuracy: 0.9513 - val_loss: 0.6988 - val_accuracy: 0.8687\n",
            "Epoch 427/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1219 - accuracy: 0.9550 - val_loss: 0.6818 - val_accuracy: 0.8636\n",
            "Epoch 428/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1064 - accuracy: 0.9596 - val_loss: 0.7227 - val_accuracy: 0.8705\n",
            "Epoch 429/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1227 - accuracy: 0.9535 - val_loss: 0.6964 - val_accuracy: 0.8712\n",
            "Epoch 430/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1169 - accuracy: 0.9539 - val_loss: 0.6912 - val_accuracy: 0.8734\n",
            "Epoch 431/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1157 - accuracy: 0.9572 - val_loss: 0.6748 - val_accuracy: 0.8672\n",
            "Epoch 432/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1215 - accuracy: 0.9521 - val_loss: 0.6340 - val_accuracy: 0.8763\n",
            "Epoch 433/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1059 - accuracy: 0.9606 - val_loss: 0.6946 - val_accuracy: 0.8648\n",
            "Epoch 434/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1124 - accuracy: 0.9557 - val_loss: 0.6623 - val_accuracy: 0.8667\n",
            "Epoch 435/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1146 - accuracy: 0.9543 - val_loss: 0.7127 - val_accuracy: 0.8684\n",
            "Epoch 436/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1200 - accuracy: 0.9544 - val_loss: 0.6790 - val_accuracy: 0.8659\n",
            "Epoch 437/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1057 - accuracy: 0.9605 - val_loss: 0.6810 - val_accuracy: 0.8767\n",
            "Epoch 438/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1125 - accuracy: 0.9565 - val_loss: 0.7095 - val_accuracy: 0.8667\n",
            "Epoch 439/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1148 - accuracy: 0.9536 - val_loss: 0.6976 - val_accuracy: 0.8775\n",
            "Epoch 440/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1119 - accuracy: 0.9558 - val_loss: 0.7186 - val_accuracy: 0.8650\n",
            "Epoch 441/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1252 - accuracy: 0.9509 - val_loss: 0.7227 - val_accuracy: 0.8573\n",
            "Epoch 442/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1080 - accuracy: 0.9597 - val_loss: 0.6638 - val_accuracy: 0.8728\n",
            "Epoch 443/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1116 - accuracy: 0.9566 - val_loss: 0.7351 - val_accuracy: 0.8628\n",
            "Epoch 444/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1234 - accuracy: 0.9514 - val_loss: 0.7019 - val_accuracy: 0.8687\n",
            "Epoch 445/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1124 - accuracy: 0.9563 - val_loss: 0.6859 - val_accuracy: 0.8689\n",
            "Epoch 446/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1313 - accuracy: 0.9522 - val_loss: 0.6809 - val_accuracy: 0.8788\n",
            "Epoch 447/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1072 - accuracy: 0.9596 - val_loss: 0.7705 - val_accuracy: 0.8602\n",
            "Epoch 448/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1211 - accuracy: 0.9535 - val_loss: 0.6656 - val_accuracy: 0.8672\n",
            "Epoch 449/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1189 - accuracy: 0.9552 - val_loss: 0.6882 - val_accuracy: 0.8692\n",
            "Epoch 450/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1250 - accuracy: 0.9521 - val_loss: 0.6838 - val_accuracy: 0.8697\n",
            "Epoch 451/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1064 - accuracy: 0.9590 - val_loss: 0.6540 - val_accuracy: 0.8775\n",
            "Epoch 452/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1038 - accuracy: 0.9615 - val_loss: 0.7024 - val_accuracy: 0.8675\n",
            "Epoch 453/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1191 - accuracy: 0.9526 - val_loss: 0.7276 - val_accuracy: 0.8709\n",
            "Epoch 454/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1129 - accuracy: 0.9563 - val_loss: 0.6328 - val_accuracy: 0.8703\n",
            "Epoch 455/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1164 - accuracy: 0.9547 - val_loss: 0.7567 - val_accuracy: 0.8630\n",
            "Epoch 456/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1121 - accuracy: 0.9583 - val_loss: 0.7217 - val_accuracy: 0.8683\n",
            "Epoch 457/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1164 - accuracy: 0.9563 - val_loss: 0.7196 - val_accuracy: 0.8683\n",
            "Epoch 458/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1183 - accuracy: 0.9535 - val_loss: 0.7215 - val_accuracy: 0.8675\n",
            "Epoch 459/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1087 - accuracy: 0.9577 - val_loss: 0.7326 - val_accuracy: 0.8598\n",
            "Epoch 460/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1125 - accuracy: 0.9565 - val_loss: 0.7274 - val_accuracy: 0.8739\n",
            "Epoch 461/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0981 - accuracy: 0.9635 - val_loss: 0.7453 - val_accuracy: 0.8634\n",
            "Epoch 462/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1047 - accuracy: 0.9579 - val_loss: 0.7301 - val_accuracy: 0.8594\n",
            "Epoch 463/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1087 - accuracy: 0.9578 - val_loss: 0.7693 - val_accuracy: 0.8577\n",
            "Epoch 464/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1222 - accuracy: 0.9529 - val_loss: 0.7229 - val_accuracy: 0.8611\n",
            "Epoch 465/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1000 - accuracy: 0.9609 - val_loss: 0.7092 - val_accuracy: 0.8759\n",
            "Epoch 466/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1086 - accuracy: 0.9583 - val_loss: 0.7466 - val_accuracy: 0.8694\n",
            "Epoch 467/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1160 - accuracy: 0.9529 - val_loss: 0.7120 - val_accuracy: 0.8748\n",
            "Epoch 468/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1178 - accuracy: 0.9548 - val_loss: 0.6984 - val_accuracy: 0.8667\n",
            "Epoch 469/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1161 - accuracy: 0.9546 - val_loss: 0.8546 - val_accuracy: 0.8595\n",
            "Epoch 470/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1073 - accuracy: 0.9595 - val_loss: 0.7231 - val_accuracy: 0.8698\n",
            "Epoch 471/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1099 - accuracy: 0.9566 - val_loss: 0.7758 - val_accuracy: 0.8591\n",
            "Epoch 472/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1143 - accuracy: 0.9528 - val_loss: 0.7313 - val_accuracy: 0.8695\n",
            "Epoch 473/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1119 - accuracy: 0.9577 - val_loss: 0.6839 - val_accuracy: 0.8700\n",
            "Epoch 474/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1137 - accuracy: 0.9571 - val_loss: 0.7205 - val_accuracy: 0.8753\n",
            "Epoch 475/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1163 - accuracy: 0.9584 - val_loss: 0.7468 - val_accuracy: 0.8711\n",
            "Epoch 476/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1149 - accuracy: 0.9538 - val_loss: 0.6911 - val_accuracy: 0.8650\n",
            "Epoch 477/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1111 - accuracy: 0.9572 - val_loss: 0.7362 - val_accuracy: 0.8717\n",
            "Epoch 478/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1158 - accuracy: 0.9567 - val_loss: 0.7332 - val_accuracy: 0.8662\n",
            "Epoch 479/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1057 - accuracy: 0.9590 - val_loss: 0.6727 - val_accuracy: 0.8719\n",
            "Epoch 480/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1017 - accuracy: 0.9602 - val_loss: 0.7450 - val_accuracy: 0.8716\n",
            "Epoch 481/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1029 - accuracy: 0.9613 - val_loss: 0.7615 - val_accuracy: 0.8677\n",
            "Epoch 482/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1077 - accuracy: 0.9558 - val_loss: 0.6978 - val_accuracy: 0.8683\n",
            "Epoch 483/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1177 - accuracy: 0.9538 - val_loss: 0.8424 - val_accuracy: 0.8639\n",
            "Epoch 484/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1075 - accuracy: 0.9598 - val_loss: 0.7138 - val_accuracy: 0.8767\n",
            "Epoch 485/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1124 - accuracy: 0.9572 - val_loss: 0.8392 - val_accuracy: 0.8641\n",
            "Epoch 486/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1220 - accuracy: 0.9529 - val_loss: 0.7724 - val_accuracy: 0.8669\n",
            "Epoch 487/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1129 - accuracy: 0.9557 - val_loss: 0.7782 - val_accuracy: 0.8583\n",
            "Epoch 488/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1141 - accuracy: 0.9557 - val_loss: 0.7283 - val_accuracy: 0.8652\n",
            "Epoch 489/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1008 - accuracy: 0.9620 - val_loss: 0.7602 - val_accuracy: 0.8677\n",
            "Epoch 490/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0992 - accuracy: 0.9608 - val_loss: 0.7909 - val_accuracy: 0.8667\n",
            "Epoch 491/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1040 - accuracy: 0.9593 - val_loss: 0.7693 - val_accuracy: 0.8725\n",
            "Epoch 492/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1081 - accuracy: 0.9598 - val_loss: 0.7794 - val_accuracy: 0.8734\n",
            "Epoch 493/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0998 - accuracy: 0.9616 - val_loss: 0.6986 - val_accuracy: 0.8781\n",
            "Epoch 494/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0976 - accuracy: 0.9627 - val_loss: 0.7275 - val_accuracy: 0.8736\n",
            "Epoch 495/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1036 - accuracy: 0.9574 - val_loss: 0.7626 - val_accuracy: 0.8670\n",
            "Epoch 496/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0976 - accuracy: 0.9619 - val_loss: 0.7286 - val_accuracy: 0.8767\n",
            "Epoch 497/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1110 - accuracy: 0.9584 - val_loss: 0.7852 - val_accuracy: 0.8687\n",
            "Epoch 498/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0978 - accuracy: 0.9623 - val_loss: 0.7502 - val_accuracy: 0.8750\n",
            "Epoch 499/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1019 - accuracy: 0.9597 - val_loss: 0.7949 - val_accuracy: 0.8667\n",
            "Epoch 500/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1037 - accuracy: 0.9592 - val_loss: 0.8412 - val_accuracy: 0.8652\n",
            "Epoch 501/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1002 - accuracy: 0.9630 - val_loss: 0.7477 - val_accuracy: 0.8695\n",
            "Epoch 502/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1093 - accuracy: 0.9583 - val_loss: 0.8000 - val_accuracy: 0.8650\n",
            "Epoch 503/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1100 - accuracy: 0.9592 - val_loss: 0.7659 - val_accuracy: 0.8725\n",
            "Epoch 504/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1263 - accuracy: 0.9526 - val_loss: 0.7831 - val_accuracy: 0.8627\n",
            "Epoch 505/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1223 - accuracy: 0.9525 - val_loss: 0.7436 - val_accuracy: 0.8734\n",
            "Epoch 506/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1173 - accuracy: 0.9573 - val_loss: 0.7551 - val_accuracy: 0.8761\n",
            "Epoch 507/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1083 - accuracy: 0.9556 - val_loss: 0.6812 - val_accuracy: 0.8786\n",
            "Epoch 508/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0947 - accuracy: 0.9648 - val_loss: 0.7441 - val_accuracy: 0.8692\n",
            "Epoch 509/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1091 - accuracy: 0.9579 - val_loss: 0.7393 - val_accuracy: 0.8730\n",
            "Epoch 510/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1008 - accuracy: 0.9614 - val_loss: 0.7040 - val_accuracy: 0.8741\n",
            "Epoch 511/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1049 - accuracy: 0.9600 - val_loss: 0.8464 - val_accuracy: 0.8631\n",
            "Epoch 512/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0991 - accuracy: 0.9603 - val_loss: 0.7615 - val_accuracy: 0.8767\n",
            "Epoch 513/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0902 - accuracy: 0.9660 - val_loss: 0.7294 - val_accuracy: 0.8731\n",
            "Epoch 514/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1022 - accuracy: 0.9599 - val_loss: 0.7504 - val_accuracy: 0.8717\n",
            "Epoch 515/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0986 - accuracy: 0.9609 - val_loss: 0.7518 - val_accuracy: 0.8720\n",
            "Epoch 516/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1172 - accuracy: 0.9557 - val_loss: 0.7376 - val_accuracy: 0.8683\n",
            "Epoch 517/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1122 - accuracy: 0.9569 - val_loss: 0.7578 - val_accuracy: 0.8725\n",
            "Epoch 518/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1068 - accuracy: 0.9571 - val_loss: 0.7229 - val_accuracy: 0.8714\n",
            "Epoch 519/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0955 - accuracy: 0.9613 - val_loss: 0.8276 - val_accuracy: 0.8684\n",
            "Epoch 520/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1005 - accuracy: 0.9625 - val_loss: 0.7545 - val_accuracy: 0.8708\n",
            "Epoch 521/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1059 - accuracy: 0.9582 - val_loss: 0.7276 - val_accuracy: 0.8764\n",
            "Epoch 522/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0930 - accuracy: 0.9658 - val_loss: 0.7705 - val_accuracy: 0.8684\n",
            "Epoch 523/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1025 - accuracy: 0.9597 - val_loss: 0.7605 - val_accuracy: 0.8709\n",
            "Epoch 524/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0938 - accuracy: 0.9645 - val_loss: 0.7632 - val_accuracy: 0.8748\n",
            "Epoch 525/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1050 - accuracy: 0.9601 - val_loss: 0.8043 - val_accuracy: 0.8633\n",
            "Epoch 526/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1121 - accuracy: 0.9564 - val_loss: 0.7737 - val_accuracy: 0.8759\n",
            "Epoch 527/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1034 - accuracy: 0.9602 - val_loss: 0.7529 - val_accuracy: 0.8722\n",
            "Epoch 528/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1081 - accuracy: 0.9581 - val_loss: 0.7864 - val_accuracy: 0.8723\n",
            "Epoch 529/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0945 - accuracy: 0.9632 - val_loss: 0.7792 - val_accuracy: 0.8667\n",
            "Epoch 530/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1110 - accuracy: 0.9587 - val_loss: 0.7799 - val_accuracy: 0.8620\n",
            "Epoch 531/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1039 - accuracy: 0.9626 - val_loss: 0.8701 - val_accuracy: 0.8652\n",
            "Epoch 532/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1101 - accuracy: 0.9573 - val_loss: 0.8440 - val_accuracy: 0.8575\n",
            "Epoch 533/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1064 - accuracy: 0.9592 - val_loss: 0.7885 - val_accuracy: 0.8648\n",
            "Epoch 534/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1000 - accuracy: 0.9609 - val_loss: 0.8159 - val_accuracy: 0.8650\n",
            "Epoch 535/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0993 - accuracy: 0.9609 - val_loss: 0.7452 - val_accuracy: 0.8788\n",
            "Epoch 536/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0949 - accuracy: 0.9642 - val_loss: 0.8097 - val_accuracy: 0.8652\n",
            "Epoch 537/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1038 - accuracy: 0.9577 - val_loss: 0.7569 - val_accuracy: 0.8656\n",
            "Epoch 538/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0935 - accuracy: 0.9642 - val_loss: 0.7891 - val_accuracy: 0.8684\n",
            "Epoch 539/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1018 - accuracy: 0.9609 - val_loss: 0.7999 - val_accuracy: 0.8622\n",
            "Epoch 540/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0896 - accuracy: 0.9644 - val_loss: 0.7342 - val_accuracy: 0.8784\n",
            "Epoch 541/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0970 - accuracy: 0.9632 - val_loss: 0.7847 - val_accuracy: 0.8716\n",
            "Epoch 542/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1055 - accuracy: 0.9602 - val_loss: 0.7963 - val_accuracy: 0.8780\n",
            "Epoch 543/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0987 - accuracy: 0.9621 - val_loss: 0.7540 - val_accuracy: 0.8653\n",
            "Epoch 544/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1048 - accuracy: 0.9612 - val_loss: 0.9063 - val_accuracy: 0.8547\n",
            "Epoch 545/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0984 - accuracy: 0.9608 - val_loss: 0.8185 - val_accuracy: 0.8687\n",
            "Epoch 546/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0963 - accuracy: 0.9612 - val_loss: 0.8539 - val_accuracy: 0.8602\n",
            "Epoch 547/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0977 - accuracy: 0.9613 - val_loss: 0.7861 - val_accuracy: 0.8694\n",
            "Epoch 548/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0989 - accuracy: 0.9614 - val_loss: 0.8559 - val_accuracy: 0.8667\n",
            "Epoch 549/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1044 - accuracy: 0.9592 - val_loss: 0.7862 - val_accuracy: 0.8744\n",
            "Epoch 550/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0984 - accuracy: 0.9642 - val_loss: 0.8145 - val_accuracy: 0.8730\n",
            "Epoch 551/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1062 - accuracy: 0.9573 - val_loss: 0.7932 - val_accuracy: 0.8653\n",
            "Epoch 552/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1041 - accuracy: 0.9592 - val_loss: 0.8094 - val_accuracy: 0.8634\n",
            "Epoch 553/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0991 - accuracy: 0.9598 - val_loss: 0.8243 - val_accuracy: 0.8633\n",
            "Epoch 554/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0955 - accuracy: 0.9645 - val_loss: 0.7558 - val_accuracy: 0.8798\n",
            "Epoch 555/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0885 - accuracy: 0.9663 - val_loss: 0.7873 - val_accuracy: 0.8708\n",
            "Epoch 556/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1099 - accuracy: 0.9567 - val_loss: 0.7824 - val_accuracy: 0.8753\n",
            "Epoch 557/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0947 - accuracy: 0.9637 - val_loss: 0.7304 - val_accuracy: 0.8712\n",
            "Epoch 558/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1089 - accuracy: 0.9577 - val_loss: 0.8014 - val_accuracy: 0.8634\n",
            "Epoch 559/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1194 - accuracy: 0.9562 - val_loss: 0.8745 - val_accuracy: 0.8586\n",
            "Epoch 560/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1169 - accuracy: 0.9548 - val_loss: 0.8278 - val_accuracy: 0.8633\n",
            "Epoch 561/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0972 - accuracy: 0.9636 - val_loss: 0.8650 - val_accuracy: 0.8625\n",
            "Epoch 562/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1017 - accuracy: 0.9620 - val_loss: 0.8493 - val_accuracy: 0.8645\n",
            "Epoch 563/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0994 - accuracy: 0.9607 - val_loss: 0.7646 - val_accuracy: 0.8770\n",
            "Epoch 564/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0882 - accuracy: 0.9682 - val_loss: 0.8978 - val_accuracy: 0.8667\n",
            "Epoch 565/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1011 - accuracy: 0.9597 - val_loss: 0.8514 - val_accuracy: 0.8598\n",
            "Epoch 566/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0869 - accuracy: 0.9661 - val_loss: 0.8453 - val_accuracy: 0.8677\n",
            "Epoch 567/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0945 - accuracy: 0.9616 - val_loss: 0.7840 - val_accuracy: 0.8673\n",
            "Epoch 568/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0897 - accuracy: 0.9657 - val_loss: 0.7914 - val_accuracy: 0.8722\n",
            "Epoch 569/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0888 - accuracy: 0.9667 - val_loss: 0.8326 - val_accuracy: 0.8687\n",
            "Epoch 570/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1034 - accuracy: 0.9588 - val_loss: 0.8570 - val_accuracy: 0.8705\n",
            "Epoch 571/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1108 - accuracy: 0.9566 - val_loss: 0.7015 - val_accuracy: 0.8692\n",
            "Epoch 572/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1068 - accuracy: 0.9591 - val_loss: 0.8246 - val_accuracy: 0.8689\n",
            "Epoch 573/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0854 - accuracy: 0.9679 - val_loss: 0.8283 - val_accuracy: 0.8702\n",
            "Epoch 574/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0930 - accuracy: 0.9640 - val_loss: 0.8432 - val_accuracy: 0.8673\n",
            "Epoch 575/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0997 - accuracy: 0.9618 - val_loss: 0.8174 - val_accuracy: 0.8691\n",
            "Epoch 576/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0902 - accuracy: 0.9645 - val_loss: 0.7733 - val_accuracy: 0.8667\n",
            "Epoch 577/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1042 - accuracy: 0.9576 - val_loss: 0.8002 - val_accuracy: 0.8741\n",
            "Epoch 578/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0876 - accuracy: 0.9671 - val_loss: 0.8937 - val_accuracy: 0.8683\n",
            "Epoch 579/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1014 - accuracy: 0.9599 - val_loss: 0.8142 - val_accuracy: 0.8623\n",
            "Epoch 580/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1013 - accuracy: 0.9605 - val_loss: 0.8091 - val_accuracy: 0.8666\n",
            "Epoch 581/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0949 - accuracy: 0.9617 - val_loss: 0.8256 - val_accuracy: 0.8673\n",
            "Epoch 582/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0839 - accuracy: 0.9666 - val_loss: 0.7734 - val_accuracy: 0.8756\n",
            "Epoch 583/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0953 - accuracy: 0.9645 - val_loss: 0.8116 - val_accuracy: 0.8702\n",
            "Epoch 584/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0983 - accuracy: 0.9618 - val_loss: 0.8130 - val_accuracy: 0.8706\n",
            "Epoch 585/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1028 - accuracy: 0.9609 - val_loss: 0.7581 - val_accuracy: 0.8737\n",
            "Epoch 586/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1036 - accuracy: 0.9596 - val_loss: 0.9406 - val_accuracy: 0.8591\n",
            "Epoch 587/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0959 - accuracy: 0.9634 - val_loss: 0.8292 - val_accuracy: 0.8706\n",
            "Epoch 588/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0916 - accuracy: 0.9641 - val_loss: 0.8715 - val_accuracy: 0.8687\n",
            "Epoch 589/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1001 - accuracy: 0.9606 - val_loss: 0.8918 - val_accuracy: 0.8622\n",
            "Epoch 590/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0916 - accuracy: 0.9627 - val_loss: 0.8057 - val_accuracy: 0.8706\n",
            "Epoch 591/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1014 - accuracy: 0.9602 - val_loss: 0.8914 - val_accuracy: 0.8659\n",
            "Epoch 592/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0824 - accuracy: 0.9684 - val_loss: 0.8752 - val_accuracy: 0.8691\n",
            "Epoch 593/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0952 - accuracy: 0.9620 - val_loss: 0.8431 - val_accuracy: 0.8725\n",
            "Epoch 594/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0989 - accuracy: 0.9626 - val_loss: 0.8382 - val_accuracy: 0.8672\n",
            "Epoch 595/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1006 - accuracy: 0.9613 - val_loss: 0.9121 - val_accuracy: 0.8737\n",
            "Epoch 596/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0950 - accuracy: 0.9641 - val_loss: 0.7847 - val_accuracy: 0.8772\n",
            "Epoch 597/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0933 - accuracy: 0.9663 - val_loss: 0.8515 - val_accuracy: 0.8742\n",
            "Epoch 598/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1053 - accuracy: 0.9582 - val_loss: 0.8343 - val_accuracy: 0.8631\n",
            "Epoch 599/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1044 - accuracy: 0.9616 - val_loss: 0.7630 - val_accuracy: 0.8748\n",
            "Epoch 600/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1037 - accuracy: 0.9607 - val_loss: 0.9307 - val_accuracy: 0.8709\n",
            "Epoch 601/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1074 - accuracy: 0.9595 - val_loss: 0.8798 - val_accuracy: 0.8681\n",
            "Epoch 602/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0972 - accuracy: 0.9613 - val_loss: 0.8423 - val_accuracy: 0.8712\n",
            "Epoch 603/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0965 - accuracy: 0.9632 - val_loss: 0.8734 - val_accuracy: 0.8658\n",
            "Epoch 604/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0869 - accuracy: 0.9649 - val_loss: 0.8682 - val_accuracy: 0.8709\n",
            "Epoch 605/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1103 - accuracy: 0.9563 - val_loss: 0.9038 - val_accuracy: 0.8645\n",
            "Epoch 606/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0886 - accuracy: 0.9670 - val_loss: 0.8094 - val_accuracy: 0.8745\n",
            "Epoch 607/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1089 - accuracy: 0.9595 - val_loss: 0.9119 - val_accuracy: 0.8642\n",
            "Epoch 608/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1010 - accuracy: 0.9613 - val_loss: 0.8467 - val_accuracy: 0.8644\n",
            "Epoch 609/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0884 - accuracy: 0.9644 - val_loss: 0.8383 - val_accuracy: 0.8752\n",
            "Epoch 610/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0891 - accuracy: 0.9649 - val_loss: 0.8466 - val_accuracy: 0.8773\n",
            "Epoch 611/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0860 - accuracy: 0.9673 - val_loss: 0.8929 - val_accuracy: 0.8677\n",
            "Epoch 612/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1087 - accuracy: 0.9577 - val_loss: 0.8361 - val_accuracy: 0.8692\n",
            "Epoch 613/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0880 - accuracy: 0.9658 - val_loss: 0.8520 - val_accuracy: 0.8659\n",
            "Epoch 614/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0992 - accuracy: 0.9604 - val_loss: 0.8445 - val_accuracy: 0.8664\n",
            "Epoch 615/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0854 - accuracy: 0.9669 - val_loss: 0.8317 - val_accuracy: 0.8772\n",
            "Epoch 616/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1002 - accuracy: 0.9612 - val_loss: 0.8673 - val_accuracy: 0.8716\n",
            "Epoch 617/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0943 - accuracy: 0.9618 - val_loss: 0.8165 - val_accuracy: 0.8737\n",
            "Epoch 618/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0872 - accuracy: 0.9666 - val_loss: 0.8336 - val_accuracy: 0.8677\n",
            "Epoch 619/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0943 - accuracy: 0.9628 - val_loss: 0.9184 - val_accuracy: 0.8666\n",
            "Epoch 620/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0814 - accuracy: 0.9688 - val_loss: 0.8386 - val_accuracy: 0.8712\n",
            "Epoch 621/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1111 - accuracy: 0.9559 - val_loss: 0.8489 - val_accuracy: 0.8655\n",
            "Epoch 622/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0918 - accuracy: 0.9638 - val_loss: 0.8415 - val_accuracy: 0.8733\n",
            "Epoch 623/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0852 - accuracy: 0.9647 - val_loss: 0.8290 - val_accuracy: 0.8706\n",
            "Epoch 624/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0904 - accuracy: 0.9646 - val_loss: 0.8391 - val_accuracy: 0.8748\n",
            "Epoch 625/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0821 - accuracy: 0.9691 - val_loss: 0.8930 - val_accuracy: 0.8700\n",
            "Epoch 626/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1011 - accuracy: 0.9613 - val_loss: 0.8895 - val_accuracy: 0.8673\n",
            "Epoch 627/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0935 - accuracy: 0.9634 - val_loss: 0.8470 - val_accuracy: 0.8684\n",
            "Epoch 628/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0969 - accuracy: 0.9615 - val_loss: 0.8680 - val_accuracy: 0.8673\n",
            "Epoch 629/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0799 - accuracy: 0.9691 - val_loss: 0.8308 - val_accuracy: 0.8798\n",
            "Epoch 630/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0834 - accuracy: 0.9676 - val_loss: 0.8319 - val_accuracy: 0.8694\n",
            "Epoch 631/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0967 - accuracy: 0.9621 - val_loss: 0.8391 - val_accuracy: 0.8702\n",
            "Epoch 632/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0892 - accuracy: 0.9634 - val_loss: 0.8304 - val_accuracy: 0.8714\n",
            "Epoch 633/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1026 - accuracy: 0.9610 - val_loss: 0.8625 - val_accuracy: 0.8636\n",
            "Epoch 634/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0834 - accuracy: 0.9682 - val_loss: 0.9180 - val_accuracy: 0.8675\n",
            "Epoch 635/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0932 - accuracy: 0.9645 - val_loss: 0.8641 - val_accuracy: 0.8636\n",
            "Epoch 636/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0915 - accuracy: 0.9645 - val_loss: 0.9029 - val_accuracy: 0.8680\n",
            "Epoch 637/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1036 - accuracy: 0.9587 - val_loss: 0.8968 - val_accuracy: 0.8666\n",
            "Epoch 638/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1011 - accuracy: 0.9592 - val_loss: 0.8453 - val_accuracy: 0.8767\n",
            "Epoch 639/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0847 - accuracy: 0.9690 - val_loss: 0.9081 - val_accuracy: 0.8719\n",
            "Epoch 640/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0936 - accuracy: 0.9638 - val_loss: 0.8811 - val_accuracy: 0.8664\n",
            "Epoch 641/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0979 - accuracy: 0.9647 - val_loss: 0.8026 - val_accuracy: 0.8716\n",
            "Epoch 642/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1013 - accuracy: 0.9610 - val_loss: 0.9344 - val_accuracy: 0.8645\n",
            "Epoch 643/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0881 - accuracy: 0.9669 - val_loss: 0.8506 - val_accuracy: 0.8834\n",
            "Epoch 644/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0937 - accuracy: 0.9657 - val_loss: 0.9444 - val_accuracy: 0.8581\n",
            "Epoch 645/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1063 - accuracy: 0.9606 - val_loss: 0.8257 - val_accuracy: 0.8792\n",
            "Epoch 646/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0918 - accuracy: 0.9652 - val_loss: 0.8898 - val_accuracy: 0.8627\n",
            "Epoch 647/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0950 - accuracy: 0.9641 - val_loss: 0.8661 - val_accuracy: 0.8666\n",
            "Epoch 648/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0736 - accuracy: 0.9732 - val_loss: 0.8835 - val_accuracy: 0.8747\n",
            "Epoch 649/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0853 - accuracy: 0.9680 - val_loss: 0.8415 - val_accuracy: 0.8681\n",
            "Epoch 650/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0934 - accuracy: 0.9635 - val_loss: 0.8750 - val_accuracy: 0.8669\n",
            "Epoch 651/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0906 - accuracy: 0.9655 - val_loss: 0.8663 - val_accuracy: 0.8653\n",
            "Epoch 652/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0876 - accuracy: 0.9652 - val_loss: 0.8703 - val_accuracy: 0.8730\n",
            "Epoch 653/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0855 - accuracy: 0.9684 - val_loss: 0.8802 - val_accuracy: 0.8700\n",
            "Epoch 654/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0947 - accuracy: 0.9618 - val_loss: 0.8904 - val_accuracy: 0.8661\n",
            "Epoch 655/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0894 - accuracy: 0.9655 - val_loss: 0.8106 - val_accuracy: 0.8681\n",
            "Epoch 656/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1074 - accuracy: 0.9595 - val_loss: 0.8688 - val_accuracy: 0.8622\n",
            "Epoch 657/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0863 - accuracy: 0.9667 - val_loss: 0.8486 - val_accuracy: 0.8764\n",
            "Epoch 658/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0844 - accuracy: 0.9669 - val_loss: 0.9042 - val_accuracy: 0.8608\n",
            "Epoch 659/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0866 - accuracy: 0.9658 - val_loss: 0.8986 - val_accuracy: 0.8769\n",
            "Epoch 660/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0913 - accuracy: 0.9645 - val_loss: 0.8808 - val_accuracy: 0.8677\n",
            "Epoch 661/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1007 - accuracy: 0.9629 - val_loss: 0.8941 - val_accuracy: 0.8616\n",
            "Epoch 662/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0891 - accuracy: 0.9657 - val_loss: 0.9014 - val_accuracy: 0.8697\n",
            "Epoch 663/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0880 - accuracy: 0.9655 - val_loss: 0.8929 - val_accuracy: 0.8661\n",
            "Epoch 664/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0849 - accuracy: 0.9670 - val_loss: 0.8964 - val_accuracy: 0.8675\n",
            "Epoch 665/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0814 - accuracy: 0.9672 - val_loss: 0.8963 - val_accuracy: 0.8723\n",
            "Epoch 666/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0895 - accuracy: 0.9648 - val_loss: 0.8912 - val_accuracy: 0.8761\n",
            "Epoch 667/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0870 - accuracy: 0.9668 - val_loss: 0.9394 - val_accuracy: 0.8687\n",
            "Epoch 668/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0879 - accuracy: 0.9645 - val_loss: 0.8845 - val_accuracy: 0.8731\n",
            "Epoch 669/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0822 - accuracy: 0.9684 - val_loss: 0.8929 - val_accuracy: 0.8645\n",
            "Epoch 670/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0887 - accuracy: 0.9652 - val_loss: 0.8724 - val_accuracy: 0.8652\n",
            "Epoch 671/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0937 - accuracy: 0.9643 - val_loss: 0.8599 - val_accuracy: 0.8730\n",
            "Epoch 672/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0803 - accuracy: 0.9703 - val_loss: 0.9015 - val_accuracy: 0.8653\n",
            "Epoch 673/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0969 - accuracy: 0.9614 - val_loss: 0.9147 - val_accuracy: 0.8719\n",
            "Epoch 674/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0981 - accuracy: 0.9636 - val_loss: 0.8355 - val_accuracy: 0.8747\n",
            "Epoch 675/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0942 - accuracy: 0.9638 - val_loss: 0.9336 - val_accuracy: 0.8653\n",
            "Epoch 676/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0871 - accuracy: 0.9680 - val_loss: 0.9772 - val_accuracy: 0.8628\n",
            "Epoch 677/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0825 - accuracy: 0.9667 - val_loss: 0.9237 - val_accuracy: 0.8653\n",
            "Epoch 678/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0890 - accuracy: 0.9662 - val_loss: 0.8910 - val_accuracy: 0.8770\n",
            "Epoch 679/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0957 - accuracy: 0.9624 - val_loss: 0.9057 - val_accuracy: 0.8708\n",
            "Epoch 680/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0982 - accuracy: 0.9604 - val_loss: 0.9507 - val_accuracy: 0.8720\n",
            "Epoch 681/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0896 - accuracy: 0.9661 - val_loss: 0.8889 - val_accuracy: 0.8706\n",
            "Epoch 682/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0905 - accuracy: 0.9644 - val_loss: 0.8893 - val_accuracy: 0.8702\n",
            "Epoch 683/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0910 - accuracy: 0.9630 - val_loss: 0.8693 - val_accuracy: 0.8652\n",
            "Epoch 684/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0878 - accuracy: 0.9651 - val_loss: 0.8607 - val_accuracy: 0.8716\n",
            "Epoch 685/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0856 - accuracy: 0.9663 - val_loss: 0.8484 - val_accuracy: 0.8788\n",
            "Epoch 686/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0787 - accuracy: 0.9702 - val_loss: 0.8844 - val_accuracy: 0.8712\n",
            "Epoch 687/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0800 - accuracy: 0.9682 - val_loss: 0.9779 - val_accuracy: 0.8700\n",
            "Epoch 688/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0836 - accuracy: 0.9686 - val_loss: 0.8095 - val_accuracy: 0.8745\n",
            "Epoch 689/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0884 - accuracy: 0.9663 - val_loss: 1.0448 - val_accuracy: 0.8598\n",
            "Epoch 690/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0819 - accuracy: 0.9683 - val_loss: 0.9857 - val_accuracy: 0.8656\n",
            "Epoch 691/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0850 - accuracy: 0.9674 - val_loss: 0.8846 - val_accuracy: 0.8723\n",
            "Epoch 692/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0814 - accuracy: 0.9667 - val_loss: 0.9372 - val_accuracy: 0.8731\n",
            "Epoch 693/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0796 - accuracy: 0.9695 - val_loss: 0.8441 - val_accuracy: 0.8753\n",
            "Epoch 694/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0936 - accuracy: 0.9644 - val_loss: 0.8818 - val_accuracy: 0.8727\n",
            "Epoch 695/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0876 - accuracy: 0.9676 - val_loss: 0.8530 - val_accuracy: 0.8734\n",
            "Epoch 696/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0841 - accuracy: 0.9670 - val_loss: 0.9307 - val_accuracy: 0.8628\n",
            "Epoch 697/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0869 - accuracy: 0.9676 - val_loss: 0.9308 - val_accuracy: 0.8666\n",
            "Epoch 698/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0850 - accuracy: 0.9660 - val_loss: 0.9094 - val_accuracy: 0.8697\n",
            "Epoch 699/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0870 - accuracy: 0.9656 - val_loss: 0.8740 - val_accuracy: 0.8786\n",
            "Epoch 700/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0749 - accuracy: 0.9716 - val_loss: 0.9401 - val_accuracy: 0.8686\n",
            "Epoch 701/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0914 - accuracy: 0.9637 - val_loss: 0.9647 - val_accuracy: 0.8637\n",
            "Epoch 702/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0953 - accuracy: 0.9623 - val_loss: 0.7929 - val_accuracy: 0.8764\n",
            "Epoch 703/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0921 - accuracy: 0.9649 - val_loss: 0.9553 - val_accuracy: 0.8647\n",
            "Epoch 704/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0819 - accuracy: 0.9688 - val_loss: 0.9158 - val_accuracy: 0.8711\n",
            "Epoch 705/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0882 - accuracy: 0.9669 - val_loss: 0.9970 - val_accuracy: 0.8728\n",
            "Epoch 706/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0903 - accuracy: 0.9651 - val_loss: 0.9524 - val_accuracy: 0.8708\n",
            "Epoch 707/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0936 - accuracy: 0.9638 - val_loss: 0.8749 - val_accuracy: 0.8717\n",
            "Epoch 708/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0922 - accuracy: 0.9632 - val_loss: 0.9534 - val_accuracy: 0.8662\n",
            "Epoch 709/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0817 - accuracy: 0.9679 - val_loss: 0.9334 - val_accuracy: 0.8711\n",
            "Epoch 710/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0816 - accuracy: 0.9678 - val_loss: 0.9259 - val_accuracy: 0.8683\n",
            "Epoch 711/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0889 - accuracy: 0.9640 - val_loss: 0.9176 - val_accuracy: 0.8656\n",
            "Epoch 712/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0886 - accuracy: 0.9656 - val_loss: 0.8751 - val_accuracy: 0.8789\n",
            "Epoch 713/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0855 - accuracy: 0.9666 - val_loss: 0.8799 - val_accuracy: 0.8784\n",
            "Epoch 714/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0693 - accuracy: 0.9748 - val_loss: 0.9276 - val_accuracy: 0.8697\n",
            "Epoch 715/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0931 - accuracy: 0.9634 - val_loss: 0.9590 - val_accuracy: 0.8645\n",
            "Epoch 716/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0928 - accuracy: 0.9637 - val_loss: 0.9155 - val_accuracy: 0.8709\n",
            "Epoch 717/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0962 - accuracy: 0.9648 - val_loss: 0.9028 - val_accuracy: 0.8695\n",
            "Epoch 718/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0882 - accuracy: 0.9675 - val_loss: 0.9223 - val_accuracy: 0.8769\n",
            "Epoch 719/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0825 - accuracy: 0.9688 - val_loss: 0.9374 - val_accuracy: 0.8709\n",
            "Epoch 720/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0834 - accuracy: 0.9655 - val_loss: 0.9684 - val_accuracy: 0.8722\n",
            "Epoch 721/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0744 - accuracy: 0.9698 - val_loss: 0.9295 - val_accuracy: 0.8709\n",
            "Epoch 722/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0869 - accuracy: 0.9657 - val_loss: 0.9641 - val_accuracy: 0.8652\n",
            "Epoch 723/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0758 - accuracy: 0.9716 - val_loss: 0.9563 - val_accuracy: 0.8717\n",
            "Epoch 724/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0831 - accuracy: 0.9673 - val_loss: 0.8862 - val_accuracy: 0.8670\n",
            "Epoch 725/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0843 - accuracy: 0.9666 - val_loss: 0.9792 - val_accuracy: 0.8670\n",
            "Epoch 726/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0782 - accuracy: 0.9693 - val_loss: 0.9167 - val_accuracy: 0.8767\n",
            "Epoch 727/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0827 - accuracy: 0.9691 - val_loss: 0.8993 - val_accuracy: 0.8741\n",
            "Epoch 728/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0709 - accuracy: 0.9727 - val_loss: 1.0103 - val_accuracy: 0.8703\n",
            "Epoch 729/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0851 - accuracy: 0.9669 - val_loss: 0.9899 - val_accuracy: 0.8627\n",
            "Epoch 730/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0863 - accuracy: 0.9665 - val_loss: 0.8506 - val_accuracy: 0.8744\n",
            "Epoch 731/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0820 - accuracy: 0.9689 - val_loss: 1.0052 - val_accuracy: 0.8692\n",
            "Epoch 732/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0770 - accuracy: 0.9701 - val_loss: 0.9832 - val_accuracy: 0.8727\n",
            "Epoch 733/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0803 - accuracy: 0.9708 - val_loss: 0.9869 - val_accuracy: 0.8702\n",
            "Epoch 734/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0869 - accuracy: 0.9657 - val_loss: 0.9641 - val_accuracy: 0.8717\n",
            "Epoch 735/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0843 - accuracy: 0.9677 - val_loss: 0.9789 - val_accuracy: 0.8675\n",
            "Epoch 736/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0908 - accuracy: 0.9660 - val_loss: 0.9537 - val_accuracy: 0.8653\n",
            "Epoch 737/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0809 - accuracy: 0.9709 - val_loss: 0.9782 - val_accuracy: 0.8706\n",
            "Epoch 738/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0786 - accuracy: 0.9713 - val_loss: 0.9480 - val_accuracy: 0.8650\n",
            "Epoch 739/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0849 - accuracy: 0.9661 - val_loss: 0.9544 - val_accuracy: 0.8692\n",
            "Epoch 740/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0842 - accuracy: 0.9657 - val_loss: 0.9464 - val_accuracy: 0.8727\n",
            "Epoch 741/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0841 - accuracy: 0.9677 - val_loss: 0.9370 - val_accuracy: 0.8705\n",
            "Epoch 742/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0742 - accuracy: 0.9706 - val_loss: 0.9911 - val_accuracy: 0.8728\n",
            "Epoch 743/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0880 - accuracy: 0.9667 - val_loss: 0.9830 - val_accuracy: 0.8680\n",
            "Epoch 744/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0764 - accuracy: 0.9710 - val_loss: 0.9460 - val_accuracy: 0.8706\n",
            "Epoch 745/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0800 - accuracy: 0.9686 - val_loss: 0.9562 - val_accuracy: 0.8700\n",
            "Epoch 746/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0742 - accuracy: 0.9707 - val_loss: 0.9945 - val_accuracy: 0.8753\n",
            "Epoch 747/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0906 - accuracy: 0.9671 - val_loss: 0.9260 - val_accuracy: 0.8720\n",
            "Epoch 748/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0822 - accuracy: 0.9673 - val_loss: 0.9634 - val_accuracy: 0.8737\n",
            "Epoch 749/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0900 - accuracy: 0.9661 - val_loss: 0.9381 - val_accuracy: 0.8684\n",
            "Epoch 750/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0886 - accuracy: 0.9649 - val_loss: 0.8772 - val_accuracy: 0.8717\n",
            "Epoch 751/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0659 - accuracy: 0.9741 - val_loss: 1.0558 - val_accuracy: 0.8683\n",
            "Epoch 752/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0719 - accuracy: 0.9705 - val_loss: 0.9772 - val_accuracy: 0.8669\n",
            "Epoch 753/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0749 - accuracy: 0.9720 - val_loss: 1.0098 - val_accuracy: 0.8689\n",
            "Epoch 754/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0785 - accuracy: 0.9698 - val_loss: 0.9465 - val_accuracy: 0.8683\n",
            "Epoch 755/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0881 - accuracy: 0.9677 - val_loss: 0.9865 - val_accuracy: 0.8656\n",
            "Epoch 756/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0805 - accuracy: 0.9684 - val_loss: 1.0295 - val_accuracy: 0.8686\n",
            "Epoch 757/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0930 - accuracy: 0.9630 - val_loss: 0.9741 - val_accuracy: 0.8698\n",
            "Epoch 758/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0795 - accuracy: 0.9714 - val_loss: 0.9343 - val_accuracy: 0.8694\n",
            "Epoch 759/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0756 - accuracy: 0.9691 - val_loss: 0.9307 - val_accuracy: 0.8683\n",
            "Epoch 760/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0789 - accuracy: 0.9704 - val_loss: 0.9532 - val_accuracy: 0.8769\n",
            "Epoch 761/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0780 - accuracy: 0.9714 - val_loss: 0.9734 - val_accuracy: 0.8622\n",
            "Epoch 762/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0859 - accuracy: 0.9647 - val_loss: 0.9604 - val_accuracy: 0.8748\n",
            "Epoch 763/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0742 - accuracy: 0.9716 - val_loss: 0.9370 - val_accuracy: 0.8716\n",
            "Epoch 764/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0858 - accuracy: 0.9659 - val_loss: 1.0362 - val_accuracy: 0.8611\n",
            "Epoch 765/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0774 - accuracy: 0.9716 - val_loss: 0.9851 - val_accuracy: 0.8705\n",
            "Epoch 766/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0853 - accuracy: 0.9665 - val_loss: 1.0366 - val_accuracy: 0.8661\n",
            "Epoch 767/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0766 - accuracy: 0.9689 - val_loss: 0.9397 - val_accuracy: 0.8711\n",
            "Epoch 768/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0747 - accuracy: 0.9715 - val_loss: 0.9362 - val_accuracy: 0.8700\n",
            "Epoch 769/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0910 - accuracy: 0.9667 - val_loss: 0.9321 - val_accuracy: 0.8737\n",
            "Epoch 770/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0911 - accuracy: 0.9669 - val_loss: 1.0187 - val_accuracy: 0.8669\n",
            "Epoch 771/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0929 - accuracy: 0.9642 - val_loss: 0.9468 - val_accuracy: 0.8656\n",
            "Epoch 772/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0757 - accuracy: 0.9702 - val_loss: 0.9249 - val_accuracy: 0.8686\n",
            "Epoch 773/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0753 - accuracy: 0.9709 - val_loss: 0.9737 - val_accuracy: 0.8655\n",
            "Epoch 774/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0758 - accuracy: 0.9709 - val_loss: 0.9501 - val_accuracy: 0.8745\n",
            "Epoch 775/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0892 - accuracy: 0.9667 - val_loss: 0.9509 - val_accuracy: 0.8737\n",
            "Epoch 776/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0920 - accuracy: 0.9654 - val_loss: 0.9687 - val_accuracy: 0.8761\n",
            "Epoch 777/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1008 - accuracy: 0.9619 - val_loss: 0.9650 - val_accuracy: 0.8714\n",
            "Epoch 778/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0813 - accuracy: 0.9691 - val_loss: 0.9827 - val_accuracy: 0.8670\n",
            "Epoch 779/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0746 - accuracy: 0.9719 - val_loss: 1.0562 - val_accuracy: 0.8706\n",
            "Epoch 780/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0926 - accuracy: 0.9647 - val_loss: 1.0055 - val_accuracy: 0.8705\n",
            "Epoch 781/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0903 - accuracy: 0.9654 - val_loss: 0.9207 - val_accuracy: 0.8761\n",
            "Epoch 782/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0728 - accuracy: 0.9729 - val_loss: 0.9354 - val_accuracy: 0.8695\n",
            "Epoch 783/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0818 - accuracy: 0.9694 - val_loss: 0.9701 - val_accuracy: 0.8753\n",
            "Epoch 784/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0776 - accuracy: 0.9709 - val_loss: 0.9924 - val_accuracy: 0.8681\n",
            "Epoch 785/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0783 - accuracy: 0.9703 - val_loss: 0.9746 - val_accuracy: 0.8662\n",
            "Epoch 786/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0838 - accuracy: 0.9693 - val_loss: 0.9524 - val_accuracy: 0.8655\n",
            "Epoch 787/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0798 - accuracy: 0.9688 - val_loss: 0.9422 - val_accuracy: 0.8717\n",
            "Epoch 788/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0798 - accuracy: 0.9700 - val_loss: 0.9625 - val_accuracy: 0.8758\n",
            "Epoch 789/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0753 - accuracy: 0.9735 - val_loss: 0.9307 - val_accuracy: 0.8745\n",
            "Epoch 790/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0813 - accuracy: 0.9698 - val_loss: 1.0953 - val_accuracy: 0.8619\n",
            "Epoch 791/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0779 - accuracy: 0.9706 - val_loss: 0.9857 - val_accuracy: 0.8694\n",
            "Epoch 792/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0777 - accuracy: 0.9692 - val_loss: 1.0358 - val_accuracy: 0.8636\n",
            "Epoch 793/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0789 - accuracy: 0.9698 - val_loss: 1.1152 - val_accuracy: 0.8661\n",
            "Epoch 794/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0776 - accuracy: 0.9696 - val_loss: 1.0052 - val_accuracy: 0.8677\n",
            "Epoch 795/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0768 - accuracy: 0.9695 - val_loss: 0.9886 - val_accuracy: 0.8712\n",
            "Epoch 796/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0802 - accuracy: 0.9695 - val_loss: 0.9383 - val_accuracy: 0.8716\n",
            "Epoch 797/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0772 - accuracy: 0.9699 - val_loss: 0.9699 - val_accuracy: 0.8772\n",
            "Epoch 798/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0854 - accuracy: 0.9666 - val_loss: 1.0023 - val_accuracy: 0.8661\n",
            "Epoch 799/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0746 - accuracy: 0.9708 - val_loss: 0.9416 - val_accuracy: 0.8708\n",
            "Epoch 800/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0755 - accuracy: 0.9700 - val_loss: 1.0035 - val_accuracy: 0.8698\n",
            "Epoch 801/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9688 - val_loss: 0.9680 - val_accuracy: 0.8709\n",
            "Epoch 802/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0913 - accuracy: 0.9659 - val_loss: 0.9062 - val_accuracy: 0.8767\n",
            "Epoch 803/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0756 - accuracy: 0.9716 - val_loss: 1.0302 - val_accuracy: 0.8678\n",
            "Epoch 804/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0730 - accuracy: 0.9698 - val_loss: 1.0266 - val_accuracy: 0.8655\n",
            "Epoch 805/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0776 - accuracy: 0.9694 - val_loss: 0.9626 - val_accuracy: 0.8728\n",
            "Epoch 806/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0761 - accuracy: 0.9705 - val_loss: 1.0482 - val_accuracy: 0.8702\n",
            "Epoch 807/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0857 - accuracy: 0.9700 - val_loss: 1.0456 - val_accuracy: 0.8734\n",
            "Epoch 808/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0737 - accuracy: 0.9716 - val_loss: 1.0070 - val_accuracy: 0.8711\n",
            "Epoch 809/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0764 - accuracy: 0.9698 - val_loss: 1.0213 - val_accuracy: 0.8689\n",
            "Epoch 810/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0833 - accuracy: 0.9689 - val_loss: 0.9460 - val_accuracy: 0.8727\n",
            "Epoch 811/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0852 - accuracy: 0.9670 - val_loss: 1.0410 - val_accuracy: 0.8733\n",
            "Epoch 812/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0844 - accuracy: 0.9698 - val_loss: 1.0081 - val_accuracy: 0.8755\n",
            "Epoch 813/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0757 - accuracy: 0.9709 - val_loss: 0.9475 - val_accuracy: 0.8656\n",
            "Epoch 814/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0741 - accuracy: 0.9712 - val_loss: 1.0287 - val_accuracy: 0.8659\n",
            "Epoch 815/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0795 - accuracy: 0.9684 - val_loss: 0.9648 - val_accuracy: 0.8744\n",
            "Epoch 816/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0812 - accuracy: 0.9682 - val_loss: 0.9373 - val_accuracy: 0.8773\n",
            "Epoch 817/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0722 - accuracy: 0.9715 - val_loss: 0.9981 - val_accuracy: 0.8675\n",
            "Epoch 818/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0819 - accuracy: 0.9673 - val_loss: 0.9744 - val_accuracy: 0.8734\n",
            "Epoch 819/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0734 - accuracy: 0.9714 - val_loss: 0.9805 - val_accuracy: 0.8744\n",
            "Epoch 820/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0719 - accuracy: 0.9721 - val_loss: 0.9733 - val_accuracy: 0.8692\n",
            "Epoch 821/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0732 - accuracy: 0.9734 - val_loss: 1.0319 - val_accuracy: 0.8764\n",
            "Epoch 822/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0698 - accuracy: 0.9720 - val_loss: 0.9869 - val_accuracy: 0.8709\n",
            "Epoch 823/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0686 - accuracy: 0.9737 - val_loss: 1.0201 - val_accuracy: 0.8695\n",
            "Epoch 824/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0758 - accuracy: 0.9717 - val_loss: 0.9891 - val_accuracy: 0.8691\n",
            "Epoch 825/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0704 - accuracy: 0.9722 - val_loss: 1.0240 - val_accuracy: 0.8708\n",
            "Epoch 826/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0649 - accuracy: 0.9745 - val_loss: 1.0453 - val_accuracy: 0.8711\n",
            "Epoch 827/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0770 - accuracy: 0.9685 - val_loss: 1.0297 - val_accuracy: 0.8680\n",
            "Epoch 828/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0665 - accuracy: 0.9737 - val_loss: 1.0658 - val_accuracy: 0.8644\n",
            "Epoch 829/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0777 - accuracy: 0.9708 - val_loss: 1.0545 - val_accuracy: 0.8744\n",
            "Epoch 830/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0764 - accuracy: 0.9723 - val_loss: 0.9702 - val_accuracy: 0.8708\n",
            "Epoch 831/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0668 - accuracy: 0.9747 - val_loss: 1.0674 - val_accuracy: 0.8734\n",
            "Epoch 832/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0802 - accuracy: 0.9673 - val_loss: 1.1214 - val_accuracy: 0.8548\n",
            "Epoch 833/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0793 - accuracy: 0.9701 - val_loss: 1.0072 - val_accuracy: 0.8711\n",
            "Epoch 834/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0833 - accuracy: 0.9672 - val_loss: 1.0575 - val_accuracy: 0.8653\n",
            "Epoch 835/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0770 - accuracy: 0.9712 - val_loss: 1.0500 - val_accuracy: 0.8755\n",
            "Epoch 836/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0825 - accuracy: 0.9687 - val_loss: 0.9844 - val_accuracy: 0.8756\n",
            "Epoch 837/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0857 - accuracy: 0.9674 - val_loss: 1.0016 - val_accuracy: 0.8759\n",
            "Epoch 838/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0726 - accuracy: 0.9711 - val_loss: 1.0361 - val_accuracy: 0.8678\n",
            "Epoch 839/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0813 - accuracy: 0.9680 - val_loss: 1.0196 - val_accuracy: 0.8650\n",
            "Epoch 840/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0773 - accuracy: 0.9713 - val_loss: 1.0257 - val_accuracy: 0.8739\n",
            "Epoch 841/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0905 - accuracy: 0.9665 - val_loss: 1.0673 - val_accuracy: 0.8653\n",
            "Epoch 842/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0717 - accuracy: 0.9734 - val_loss: 1.0783 - val_accuracy: 0.8694\n",
            "Epoch 843/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0895 - accuracy: 0.9669 - val_loss: 0.9937 - val_accuracy: 0.8764\n",
            "Epoch 844/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0771 - accuracy: 0.9709 - val_loss: 1.0466 - val_accuracy: 0.8695\n",
            "Epoch 845/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0714 - accuracy: 0.9730 - val_loss: 1.0058 - val_accuracy: 0.8672\n",
            "Epoch 846/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9689 - val_loss: 1.0135 - val_accuracy: 0.8689\n",
            "Epoch 847/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0707 - accuracy: 0.9731 - val_loss: 1.0382 - val_accuracy: 0.8700\n",
            "Epoch 848/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0886 - accuracy: 0.9670 - val_loss: 1.0484 - val_accuracy: 0.8678\n",
            "Epoch 849/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0775 - accuracy: 0.9703 - val_loss: 1.1147 - val_accuracy: 0.8731\n",
            "Epoch 850/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0776 - accuracy: 0.9702 - val_loss: 1.0372 - val_accuracy: 0.8706\n",
            "Epoch 851/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0707 - accuracy: 0.9731 - val_loss: 0.9777 - val_accuracy: 0.8775\n",
            "Epoch 852/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0687 - accuracy: 0.9734 - val_loss: 1.1163 - val_accuracy: 0.8645\n",
            "Epoch 853/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0840 - accuracy: 0.9680 - val_loss: 0.9499 - val_accuracy: 0.8678\n",
            "Epoch 854/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0664 - accuracy: 0.9752 - val_loss: 1.1420 - val_accuracy: 0.8731\n",
            "Epoch 855/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0681 - accuracy: 0.9730 - val_loss: 1.0575 - val_accuracy: 0.8684\n",
            "Epoch 856/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0714 - accuracy: 0.9696 - val_loss: 1.0669 - val_accuracy: 0.8684\n",
            "Epoch 857/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0624 - accuracy: 0.9759 - val_loss: 1.0100 - val_accuracy: 0.8714\n",
            "Epoch 858/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0673 - accuracy: 0.9733 - val_loss: 1.0215 - val_accuracy: 0.8739\n",
            "Epoch 859/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0659 - accuracy: 0.9752 - val_loss: 1.0462 - val_accuracy: 0.8700\n",
            "Epoch 860/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 1.1011 - val_accuracy: 0.8711\n",
            "Epoch 861/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0680 - accuracy: 0.9734 - val_loss: 1.0588 - val_accuracy: 0.8683\n",
            "Epoch 862/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0741 - accuracy: 0.9716 - val_loss: 0.9907 - val_accuracy: 0.8691\n",
            "Epoch 863/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0882 - accuracy: 0.9672 - val_loss: 1.0304 - val_accuracy: 0.8756\n",
            "Epoch 864/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0824 - accuracy: 0.9680 - val_loss: 1.1433 - val_accuracy: 0.8636\n",
            "Epoch 865/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0865 - accuracy: 0.9657 - val_loss: 1.0981 - val_accuracy: 0.8736\n",
            "Epoch 866/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0678 - accuracy: 0.9734 - val_loss: 1.0905 - val_accuracy: 0.8695\n",
            "Epoch 867/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9707 - val_loss: 1.0235 - val_accuracy: 0.8661\n",
            "Epoch 868/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0848 - accuracy: 0.9692 - val_loss: 1.1082 - val_accuracy: 0.8739\n",
            "Epoch 869/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0849 - accuracy: 0.9677 - val_loss: 1.1283 - val_accuracy: 0.8627\n",
            "Epoch 870/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0809 - accuracy: 0.9688 - val_loss: 1.1013 - val_accuracy: 0.8667\n",
            "Epoch 871/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0751 - accuracy: 0.9715 - val_loss: 1.0738 - val_accuracy: 0.8691\n",
            "Epoch 872/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0825 - accuracy: 0.9695 - val_loss: 1.0524 - val_accuracy: 0.8683\n",
            "Epoch 873/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0685 - accuracy: 0.9741 - val_loss: 1.0358 - val_accuracy: 0.8684\n",
            "Epoch 874/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0803 - accuracy: 0.9690 - val_loss: 1.0658 - val_accuracy: 0.8686\n",
            "Epoch 875/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9745 - val_loss: 1.0331 - val_accuracy: 0.8714\n",
            "Epoch 876/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0743 - accuracy: 0.9713 - val_loss: 0.9988 - val_accuracy: 0.8692\n",
            "Epoch 877/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0664 - accuracy: 0.9746 - val_loss: 1.0095 - val_accuracy: 0.8766\n",
            "Epoch 878/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0640 - accuracy: 0.9760 - val_loss: 1.0622 - val_accuracy: 0.8673\n",
            "Epoch 879/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0771 - accuracy: 0.9702 - val_loss: 1.0722 - val_accuracy: 0.8755\n",
            "Epoch 880/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0690 - accuracy: 0.9739 - val_loss: 1.1008 - val_accuracy: 0.8719\n",
            "Epoch 881/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0691 - accuracy: 0.9746 - val_loss: 1.0624 - val_accuracy: 0.8681\n",
            "Epoch 882/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0731 - accuracy: 0.9741 - val_loss: 1.1440 - val_accuracy: 0.8705\n",
            "Epoch 883/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0707 - accuracy: 0.9727 - val_loss: 1.0655 - val_accuracy: 0.8687\n",
            "Epoch 884/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0721 - accuracy: 0.9710 - val_loss: 1.0518 - val_accuracy: 0.8744\n",
            "Epoch 885/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0698 - accuracy: 0.9720 - val_loss: 1.0242 - val_accuracy: 0.8706\n",
            "Epoch 886/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0776 - accuracy: 0.9712 - val_loss: 1.0415 - val_accuracy: 0.8761\n",
            "Epoch 887/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0628 - accuracy: 0.9780 - val_loss: 1.0818 - val_accuracy: 0.8712\n",
            "Epoch 888/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0766 - accuracy: 0.9694 - val_loss: 1.0694 - val_accuracy: 0.8659\n",
            "Epoch 889/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0882 - accuracy: 0.9649 - val_loss: 1.0180 - val_accuracy: 0.8686\n",
            "Epoch 890/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0745 - accuracy: 0.9712 - val_loss: 0.9800 - val_accuracy: 0.8712\n",
            "Epoch 891/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0705 - accuracy: 0.9729 - val_loss: 1.0222 - val_accuracy: 0.8717\n",
            "Epoch 892/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0619 - accuracy: 0.9754 - val_loss: 1.0427 - val_accuracy: 0.8703\n",
            "Epoch 893/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0654 - accuracy: 0.9732 - val_loss: 1.0655 - val_accuracy: 0.8752\n",
            "Epoch 894/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0715 - accuracy: 0.9730 - val_loss: 1.0165 - val_accuracy: 0.8692\n",
            "Epoch 895/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0664 - accuracy: 0.9737 - val_loss: 1.0684 - val_accuracy: 0.8691\n",
            "Epoch 896/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0733 - accuracy: 0.9734 - val_loss: 1.1691 - val_accuracy: 0.8677\n",
            "Epoch 897/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0771 - accuracy: 0.9704 - val_loss: 1.1009 - val_accuracy: 0.8667\n",
            "Epoch 898/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0788 - accuracy: 0.9695 - val_loss: 1.1396 - val_accuracy: 0.8691\n",
            "Epoch 899/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0835 - accuracy: 0.9698 - val_loss: 1.0486 - val_accuracy: 0.8711\n",
            "Epoch 900/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0716 - accuracy: 0.9709 - val_loss: 1.0541 - val_accuracy: 0.8772\n",
            "Epoch 901/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9750 - val_loss: 1.0496 - val_accuracy: 0.8720\n",
            "Epoch 902/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0688 - accuracy: 0.9724 - val_loss: 1.0491 - val_accuracy: 0.8650\n",
            "Epoch 903/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0666 - accuracy: 0.9744 - val_loss: 1.0746 - val_accuracy: 0.8708\n",
            "Epoch 904/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0629 - accuracy: 0.9749 - val_loss: 1.0147 - val_accuracy: 0.8741\n",
            "Epoch 905/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0736 - accuracy: 0.9709 - val_loss: 1.0009 - val_accuracy: 0.8747\n",
            "Epoch 906/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0687 - accuracy: 0.9733 - val_loss: 1.0175 - val_accuracy: 0.8731\n",
            "Epoch 907/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0772 - accuracy: 0.9698 - val_loss: 1.0941 - val_accuracy: 0.8728\n",
            "Epoch 908/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0739 - accuracy: 0.9716 - val_loss: 1.0204 - val_accuracy: 0.8725\n",
            "Epoch 909/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0751 - accuracy: 0.9695 - val_loss: 1.1277 - val_accuracy: 0.8656\n",
            "Epoch 910/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0635 - accuracy: 0.9761 - val_loss: 1.1958 - val_accuracy: 0.8709\n",
            "Epoch 911/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0651 - accuracy: 0.9734 - val_loss: 1.1202 - val_accuracy: 0.8727\n",
            "Epoch 912/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0679 - accuracy: 0.9741 - val_loss: 1.0326 - val_accuracy: 0.8731\n",
            "Epoch 913/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0580 - accuracy: 0.9760 - val_loss: 1.0475 - val_accuracy: 0.8741\n",
            "Epoch 914/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0790 - accuracy: 0.9698 - val_loss: 1.1371 - val_accuracy: 0.8703\n",
            "Epoch 915/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0681 - accuracy: 0.9764 - val_loss: 1.1574 - val_accuracy: 0.8686\n",
            "Epoch 916/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0796 - accuracy: 0.9702 - val_loss: 1.0855 - val_accuracy: 0.8658\n",
            "Epoch 917/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0734 - accuracy: 0.9706 - val_loss: 1.1143 - val_accuracy: 0.8648\n",
            "Epoch 918/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0694 - accuracy: 0.9729 - val_loss: 1.0792 - val_accuracy: 0.8742\n",
            "Epoch 919/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0772 - accuracy: 0.9709 - val_loss: 1.0595 - val_accuracy: 0.8712\n",
            "Epoch 920/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0656 - accuracy: 0.9741 - val_loss: 1.0542 - val_accuracy: 0.8684\n",
            "Epoch 921/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0749 - accuracy: 0.9705 - val_loss: 1.1077 - val_accuracy: 0.8706\n",
            "Epoch 922/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0687 - accuracy: 0.9744 - val_loss: 1.0384 - val_accuracy: 0.8659\n",
            "Epoch 923/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0750 - accuracy: 0.9712 - val_loss: 1.1037 - val_accuracy: 0.8687\n",
            "Epoch 924/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0655 - accuracy: 0.9744 - val_loss: 1.2152 - val_accuracy: 0.8728\n",
            "Epoch 925/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0746 - accuracy: 0.9736 - val_loss: 1.0955 - val_accuracy: 0.8759\n",
            "Epoch 926/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0686 - accuracy: 0.9734 - val_loss: 1.0445 - val_accuracy: 0.8784\n",
            "Epoch 927/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0716 - accuracy: 0.9724 - val_loss: 1.0370 - val_accuracy: 0.8753\n",
            "Epoch 928/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0742 - accuracy: 0.9716 - val_loss: 1.1012 - val_accuracy: 0.8687\n",
            "Epoch 929/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0608 - accuracy: 0.9770 - val_loss: 1.1175 - val_accuracy: 0.8748\n",
            "Epoch 930/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0708 - accuracy: 0.9717 - val_loss: 1.0881 - val_accuracy: 0.8692\n",
            "Epoch 931/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0639 - accuracy: 0.9755 - val_loss: 1.0705 - val_accuracy: 0.8672\n",
            "Epoch 932/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0754 - accuracy: 0.9727 - val_loss: 1.1121 - val_accuracy: 0.8681\n",
            "Epoch 933/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0741 - accuracy: 0.9707 - val_loss: 1.0784 - val_accuracy: 0.8750\n",
            "Epoch 934/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0658 - accuracy: 0.9752 - val_loss: 1.1448 - val_accuracy: 0.8606\n",
            "Epoch 935/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0694 - accuracy: 0.9728 - val_loss: 1.0973 - val_accuracy: 0.8647\n",
            "Epoch 936/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0723 - accuracy: 0.9732 - val_loss: 1.1136 - val_accuracy: 0.8637\n",
            "Epoch 937/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0775 - accuracy: 0.9712 - val_loss: 1.0776 - val_accuracy: 0.8717\n",
            "Epoch 938/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0618 - accuracy: 0.9754 - val_loss: 1.0988 - val_accuracy: 0.8748\n",
            "Epoch 939/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0620 - accuracy: 0.9766 - val_loss: 1.0619 - val_accuracy: 0.8730\n",
            "Epoch 940/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0737 - accuracy: 0.9717 - val_loss: 1.0697 - val_accuracy: 0.8722\n",
            "Epoch 941/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0632 - accuracy: 0.9740 - val_loss: 1.0406 - val_accuracy: 0.8712\n",
            "Epoch 942/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0763 - accuracy: 0.9706 - val_loss: 1.1219 - val_accuracy: 0.8617\n",
            "Epoch 943/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0585 - accuracy: 0.9784 - val_loss: 1.1707 - val_accuracy: 0.8731\n",
            "Epoch 944/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0770 - accuracy: 0.9697 - val_loss: 1.0484 - val_accuracy: 0.8673\n",
            "Epoch 945/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0683 - accuracy: 0.9759 - val_loss: 1.1000 - val_accuracy: 0.8666\n",
            "Epoch 946/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0683 - accuracy: 0.9744 - val_loss: 1.1308 - val_accuracy: 0.8733\n",
            "Epoch 947/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0744 - accuracy: 0.9717 - val_loss: 1.0583 - val_accuracy: 0.8656\n",
            "Epoch 948/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0675 - accuracy: 0.9752 - val_loss: 1.1009 - val_accuracy: 0.8725\n",
            "Epoch 949/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0717 - accuracy: 0.9723 - val_loss: 1.1670 - val_accuracy: 0.8578\n",
            "Epoch 950/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0706 - accuracy: 0.9727 - val_loss: 1.0692 - val_accuracy: 0.8664\n",
            "Epoch 951/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0711 - accuracy: 0.9720 - val_loss: 0.9739 - val_accuracy: 0.8730\n",
            "Epoch 952/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0686 - accuracy: 0.9730 - val_loss: 1.1416 - val_accuracy: 0.8739\n",
            "Epoch 953/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0623 - accuracy: 0.9774 - val_loss: 1.0916 - val_accuracy: 0.8722\n",
            "Epoch 954/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0637 - accuracy: 0.9733 - val_loss: 1.0743 - val_accuracy: 0.8706\n",
            "Epoch 955/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0577 - accuracy: 0.9767 - val_loss: 1.1295 - val_accuracy: 0.8689\n",
            "Epoch 956/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0659 - accuracy: 0.9748 - val_loss: 1.0450 - val_accuracy: 0.8700\n",
            "Epoch 957/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0510 - accuracy: 0.9811 - val_loss: 1.1324 - val_accuracy: 0.8719\n",
            "Epoch 958/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0633 - accuracy: 0.9748 - val_loss: 1.1499 - val_accuracy: 0.8617\n",
            "Epoch 959/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0699 - accuracy: 0.9744 - val_loss: 1.0996 - val_accuracy: 0.8711\n",
            "Epoch 960/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0607 - accuracy: 0.9750 - val_loss: 1.1366 - val_accuracy: 0.8712\n",
            "Epoch 961/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0623 - accuracy: 0.9752 - val_loss: 1.1461 - val_accuracy: 0.8741\n",
            "Epoch 962/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0737 - accuracy: 0.9724 - val_loss: 1.1885 - val_accuracy: 0.8667\n",
            "Epoch 963/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0895 - accuracy: 0.9673 - val_loss: 1.1272 - val_accuracy: 0.8697\n",
            "Epoch 964/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0849 - accuracy: 0.9701 - val_loss: 1.0732 - val_accuracy: 0.8672\n",
            "Epoch 965/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0787 - accuracy: 0.9700 - val_loss: 1.0863 - val_accuracy: 0.8694\n",
            "Epoch 966/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0591 - accuracy: 0.9766 - val_loss: 1.1451 - val_accuracy: 0.8712\n",
            "Epoch 967/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0536 - accuracy: 0.9801 - val_loss: 1.1359 - val_accuracy: 0.8712\n",
            "Epoch 968/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0628 - accuracy: 0.9752 - val_loss: 1.1345 - val_accuracy: 0.8719\n",
            "Epoch 969/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0569 - accuracy: 0.9777 - val_loss: 1.1472 - val_accuracy: 0.8705\n",
            "Epoch 970/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0616 - accuracy: 0.9771 - val_loss: 1.0664 - val_accuracy: 0.8734\n",
            "Epoch 971/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0749 - accuracy: 0.9740 - val_loss: 1.2709 - val_accuracy: 0.8745\n",
            "Epoch 972/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0981 - accuracy: 0.9662 - val_loss: 1.1682 - val_accuracy: 0.8658\n",
            "Epoch 973/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0770 - accuracy: 0.9710 - val_loss: 1.1280 - val_accuracy: 0.8661\n",
            "Epoch 974/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0615 - accuracy: 0.9762 - val_loss: 1.1387 - val_accuracy: 0.8725\n",
            "Epoch 975/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0680 - accuracy: 0.9736 - val_loss: 1.0847 - val_accuracy: 0.8739\n",
            "Epoch 976/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0592 - accuracy: 0.9785 - val_loss: 1.1905 - val_accuracy: 0.8662\n",
            "Epoch 977/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0619 - accuracy: 0.9752 - val_loss: 1.1415 - val_accuracy: 0.8697\n",
            "Epoch 978/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0566 - accuracy: 0.9775 - val_loss: 1.1121 - val_accuracy: 0.8700\n",
            "Epoch 979/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0617 - accuracy: 0.9752 - val_loss: 1.0834 - val_accuracy: 0.8717\n",
            "Epoch 980/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0656 - accuracy: 0.9763 - val_loss: 1.1198 - val_accuracy: 0.8742\n",
            "Epoch 981/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0600 - accuracy: 0.9780 - val_loss: 1.1483 - val_accuracy: 0.8734\n",
            "Epoch 982/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0874 - accuracy: 0.9683 - val_loss: 1.1380 - val_accuracy: 0.8734\n",
            "Epoch 983/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0719 - accuracy: 0.9724 - val_loss: 1.1408 - val_accuracy: 0.8730\n",
            "Epoch 984/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0668 - accuracy: 0.9740 - val_loss: 1.1835 - val_accuracy: 0.8672\n",
            "Epoch 985/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0592 - accuracy: 0.9783 - val_loss: 1.1969 - val_accuracy: 0.8698\n",
            "Epoch 986/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0611 - accuracy: 0.9763 - val_loss: 1.1376 - val_accuracy: 0.8661\n",
            "Epoch 987/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0708 - accuracy: 0.9720 - val_loss: 1.1568 - val_accuracy: 0.8758\n",
            "Epoch 988/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0594 - accuracy: 0.9788 - val_loss: 1.1241 - val_accuracy: 0.8722\n",
            "Epoch 989/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0599 - accuracy: 0.9760 - val_loss: 1.1010 - val_accuracy: 0.8736\n",
            "Epoch 990/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0532 - accuracy: 0.9790 - val_loss: 1.2362 - val_accuracy: 0.8669\n",
            "Epoch 991/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0696 - accuracy: 0.9723 - val_loss: 1.0960 - val_accuracy: 0.8720\n",
            "Epoch 992/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0694 - accuracy: 0.9732 - val_loss: 1.1072 - val_accuracy: 0.8733\n",
            "Epoch 993/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0653 - accuracy: 0.9752 - val_loss: 1.1293 - val_accuracy: 0.8731\n",
            "Epoch 994/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0676 - accuracy: 0.9758 - val_loss: 1.1361 - val_accuracy: 0.8753\n",
            "Epoch 995/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0588 - accuracy: 0.9762 - val_loss: 1.1230 - val_accuracy: 0.8698\n",
            "Epoch 996/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0646 - accuracy: 0.9737 - val_loss: 1.1671 - val_accuracy: 0.8714\n",
            "Epoch 997/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0680 - accuracy: 0.9728 - val_loss: 1.1825 - val_accuracy: 0.8723\n",
            "Epoch 998/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0637 - accuracy: 0.9767 - val_loss: 1.1374 - val_accuracy: 0.8755\n",
            "Epoch 999/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0655 - accuracy: 0.9758 - val_loss: 1.2529 - val_accuracy: 0.8680\n",
            "Epoch 1000/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0628 - accuracy: 0.9771 - val_loss: 1.1951 - val_accuracy: 0.8656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDd8pTqasMlx",
        "outputId": "875b069b-964a-44ad-c1c7-cbb5ad5f3570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss_value,acc_value=model.evaluate(test_dataset,steps=50,verbose=0)\n",
        "print(\"Accuracy of our model is \", acc_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of our model is  0.8656250238418579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfFHYgwJ0_zM",
        "outputId": "2ac81fd6-3e58-46c0-9132-d5831d334514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df9H4efC3SQ3",
        "outputId": "d8478c44-cc77-42be-9913-f978a19b9604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJn-X1vdZWMH"
      },
      "source": [
        "From the above two plots, we can clearly see that there is overfitting in our model. From the training and validation loss plot, we can see that the validation loss decreases with training loss till about 200 epochs and then continues to increase.\n",
        "Similarly, for the training and validation accuracy plot, we can see that theaccuracy of the validation set doesn't increase with the training accuracy after 200 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EgXZCBNAzMs"
      },
      "source": [
        "## Task 5 Fine-tuning the model\n",
        "\n",
        "\n",
        "You may see above that your model is overfitting. There are multiple things you can do. Below are some options:\n",
        "\n",
        "1. Add dropout\n",
        "2. Add Batch Normalisation\n",
        "3. Add layer-specific weight regularizations\n",
        "4. Change the learning rate\n",
        "\n",
        "Apply different regularisation techniques to the model training. You may also try other techniques for improving training such as learning rate scheduling (see https://www.tensorflow.org/guide/keras/train_and_evaluate#using_learning_rate_schedules).\n",
        "\n",
        "Run **five or more** experiments of different training configurations and record the test accuracy achieved in the Markdown table below. You may modify the table heading to match your experiment design.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE41JApvsWtn"
      },
      "source": [
        "model_dropout = keras.Sequential()\n",
        "model_dropout.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model_dropout.add(keras.layers.Dense(128, activation='relu'))\n",
        "model_dropout.add(keras.layers.Dropout(0.5))\n",
        "model_dropout.add(keras.layers.Dense(128, activation='relu'))\n",
        "model_dropout.add(keras.layers.Dropout(0.5))\n",
        "model_dropout.add(keras.layers.Dense(10,activation='softmax'))\n",
        "model_dropout.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6-X9Y5RkiXw",
        "outputId": "1e77efbd-8bbe-482c-8993-44b8e5375f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "model_dropout.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEC0UiTckNfg",
        "outputId": "158c144a-5b1a-420f-fa2c-f7c18feada6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_dropout = model_dropout.fit(train_dataset,epochs=EPOCHS,steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,validation_data=test_dataset,batch_size=BATCH_SIZE,verbose = 1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.0930 - accuracy: 0.2570 - val_loss: 1.6601 - val_accuracy: 0.4923\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 1.4678 - accuracy: 0.4116 - val_loss: 1.1948 - val_accuracy: 0.5359\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.1963 - accuracy: 0.5216 - val_loss: 1.0193 - val_accuracy: 0.5983\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.0817 - accuracy: 0.5681 - val_loss: 0.9221 - val_accuracy: 0.6909\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 1.0001 - accuracy: 0.6106 - val_loss: 0.8500 - val_accuracy: 0.6986\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9380 - accuracy: 0.6439 - val_loss: 0.7984 - val_accuracy: 0.7275\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.8899 - accuracy: 0.6729 - val_loss: 0.7533 - val_accuracy: 0.7272\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.8379 - accuracy: 0.6793 - val_loss: 0.7231 - val_accuracy: 0.7395\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.8231 - accuracy: 0.6951 - val_loss: 0.7006 - val_accuracy: 0.7367\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.7919 - accuracy: 0.7068 - val_loss: 0.6824 - val_accuracy: 0.7491\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.7666 - accuracy: 0.7154 - val_loss: 0.6630 - val_accuracy: 0.7473\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.7532 - accuracy: 0.7162 - val_loss: 0.6527 - val_accuracy: 0.7509\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.7423 - accuracy: 0.7216 - val_loss: 0.6404 - val_accuracy: 0.7559\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.7147 - accuracy: 0.7328 - val_loss: 0.6312 - val_accuracy: 0.7617\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.7170 - accuracy: 0.7377 - val_loss: 0.6239 - val_accuracy: 0.7628\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.7026 - accuracy: 0.7381 - val_loss: 0.6174 - val_accuracy: 0.7648\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6815 - accuracy: 0.7473 - val_loss: 0.6052 - val_accuracy: 0.7644\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6893 - accuracy: 0.7366 - val_loss: 0.5975 - val_accuracy: 0.7727\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6616 - accuracy: 0.7554 - val_loss: 0.5950 - val_accuracy: 0.7784\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6797 - accuracy: 0.7509 - val_loss: 0.5901 - val_accuracy: 0.7806\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6497 - accuracy: 0.7630 - val_loss: 0.5833 - val_accuracy: 0.7741\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6466 - accuracy: 0.7602 - val_loss: 0.5720 - val_accuracy: 0.7889\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6311 - accuracy: 0.7705 - val_loss: 0.5662 - val_accuracy: 0.7872\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6329 - accuracy: 0.7648 - val_loss: 0.5593 - val_accuracy: 0.7880\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6232 - accuracy: 0.7727 - val_loss: 0.5553 - val_accuracy: 0.7917\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6124 - accuracy: 0.7716 - val_loss: 0.5519 - val_accuracy: 0.7908\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6229 - accuracy: 0.7716 - val_loss: 0.5475 - val_accuracy: 0.7950\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6004 - accuracy: 0.7785 - val_loss: 0.5406 - val_accuracy: 0.7927\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6035 - accuracy: 0.7787 - val_loss: 0.5376 - val_accuracy: 0.8030\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5968 - accuracy: 0.7818 - val_loss: 0.5322 - val_accuracy: 0.8036\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5861 - accuracy: 0.7898 - val_loss: 0.5284 - val_accuracy: 0.8094\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5821 - accuracy: 0.7864 - val_loss: 0.5217 - val_accuracy: 0.8109\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5724 - accuracy: 0.7941 - val_loss: 0.5193 - val_accuracy: 0.8144\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5840 - accuracy: 0.7941 - val_loss: 0.5164 - val_accuracy: 0.8184\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5634 - accuracy: 0.7986 - val_loss: 0.5152 - val_accuracy: 0.8142\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5708 - accuracy: 0.7953 - val_loss: 0.5095 - val_accuracy: 0.8172\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5586 - accuracy: 0.7963 - val_loss: 0.5075 - val_accuracy: 0.8205\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5610 - accuracy: 0.7985 - val_loss: 0.5077 - val_accuracy: 0.8180\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5563 - accuracy: 0.8041 - val_loss: 0.4996 - val_accuracy: 0.8231\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5525 - accuracy: 0.8044 - val_loss: 0.4963 - val_accuracy: 0.8219\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5551 - accuracy: 0.8030 - val_loss: 0.4959 - val_accuracy: 0.8194\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5331 - accuracy: 0.8074 - val_loss: 0.4936 - val_accuracy: 0.8227\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5496 - accuracy: 0.8071 - val_loss: 0.4889 - val_accuracy: 0.8250\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5397 - accuracy: 0.8050 - val_loss: 0.4860 - val_accuracy: 0.8277\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5299 - accuracy: 0.8138 - val_loss: 0.4835 - val_accuracy: 0.8263\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5335 - accuracy: 0.8088 - val_loss: 0.4815 - val_accuracy: 0.8272\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5296 - accuracy: 0.8083 - val_loss: 0.4777 - val_accuracy: 0.8278\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5223 - accuracy: 0.8171 - val_loss: 0.4772 - val_accuracy: 0.8275\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5248 - accuracy: 0.8147 - val_loss: 0.4787 - val_accuracy: 0.8278\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5269 - accuracy: 0.8134 - val_loss: 0.4756 - val_accuracy: 0.8288\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5157 - accuracy: 0.8162 - val_loss: 0.4696 - val_accuracy: 0.8309\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5165 - accuracy: 0.8155 - val_loss: 0.4675 - val_accuracy: 0.8338\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5164 - accuracy: 0.8173 - val_loss: 0.4673 - val_accuracy: 0.8319\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5062 - accuracy: 0.8185 - val_loss: 0.4650 - val_accuracy: 0.8359\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5090 - accuracy: 0.8173 - val_loss: 0.4670 - val_accuracy: 0.8292\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5034 - accuracy: 0.8214 - val_loss: 0.4652 - val_accuracy: 0.8350\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5102 - accuracy: 0.8194 - val_loss: 0.4576 - val_accuracy: 0.8370\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5019 - accuracy: 0.8208 - val_loss: 0.4575 - val_accuracy: 0.8375\n",
            "Epoch 59/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4944 - accuracy: 0.8266 - val_loss: 0.4576 - val_accuracy: 0.8372\n",
            "Epoch 60/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4969 - accuracy: 0.8260 - val_loss: 0.4556 - val_accuracy: 0.8395\n",
            "Epoch 61/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4922 - accuracy: 0.8252 - val_loss: 0.4532 - val_accuracy: 0.8408\n",
            "Epoch 62/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5071 - accuracy: 0.8251 - val_loss: 0.4577 - val_accuracy: 0.8350\n",
            "Epoch 63/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4926 - accuracy: 0.8247 - val_loss: 0.4504 - val_accuracy: 0.8383\n",
            "Epoch 64/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4960 - accuracy: 0.8227 - val_loss: 0.4552 - val_accuracy: 0.8366\n",
            "Epoch 65/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4861 - accuracy: 0.8259 - val_loss: 0.4496 - val_accuracy: 0.8389\n",
            "Epoch 66/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4863 - accuracy: 0.8254 - val_loss: 0.4455 - val_accuracy: 0.8431\n",
            "Epoch 67/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4929 - accuracy: 0.8312 - val_loss: 0.4462 - val_accuracy: 0.8423\n",
            "Epoch 68/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4715 - accuracy: 0.8308 - val_loss: 0.4466 - val_accuracy: 0.8417\n",
            "Epoch 69/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4826 - accuracy: 0.8279 - val_loss: 0.4412 - val_accuracy: 0.8422\n",
            "Epoch 70/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4750 - accuracy: 0.8313 - val_loss: 0.4462 - val_accuracy: 0.8423\n",
            "Epoch 71/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4892 - accuracy: 0.8269 - val_loss: 0.4394 - val_accuracy: 0.8461\n",
            "Epoch 72/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4768 - accuracy: 0.8340 - val_loss: 0.4380 - val_accuracy: 0.8448\n",
            "Epoch 73/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4754 - accuracy: 0.8351 - val_loss: 0.4398 - val_accuracy: 0.8427\n",
            "Epoch 74/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4705 - accuracy: 0.8309 - val_loss: 0.4363 - val_accuracy: 0.8477\n",
            "Epoch 75/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4626 - accuracy: 0.8352 - val_loss: 0.4356 - val_accuracy: 0.8470\n",
            "Epoch 76/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4766 - accuracy: 0.8334 - val_loss: 0.4335 - val_accuracy: 0.8473\n",
            "Epoch 77/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4716 - accuracy: 0.8325 - val_loss: 0.4340 - val_accuracy: 0.8456\n",
            "Epoch 78/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4657 - accuracy: 0.8361 - val_loss: 0.4337 - val_accuracy: 0.8484\n",
            "Epoch 79/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4604 - accuracy: 0.8384 - val_loss: 0.4323 - val_accuracy: 0.8477\n",
            "Epoch 80/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4719 - accuracy: 0.8348 - val_loss: 0.4297 - val_accuracy: 0.8492\n",
            "Epoch 81/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4618 - accuracy: 0.8369 - val_loss: 0.4308 - val_accuracy: 0.8486\n",
            "Epoch 82/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4604 - accuracy: 0.8398 - val_loss: 0.4373 - val_accuracy: 0.8462\n",
            "Epoch 83/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4641 - accuracy: 0.8341 - val_loss: 0.4292 - val_accuracy: 0.8481\n",
            "Epoch 84/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4510 - accuracy: 0.8395 - val_loss: 0.4275 - val_accuracy: 0.8494\n",
            "Epoch 85/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4684 - accuracy: 0.8347 - val_loss: 0.4282 - val_accuracy: 0.8512\n",
            "Epoch 86/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4610 - accuracy: 0.8394 - val_loss: 0.4251 - val_accuracy: 0.8503\n",
            "Epoch 87/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4575 - accuracy: 0.8387 - val_loss: 0.4275 - val_accuracy: 0.8492\n",
            "Epoch 88/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4517 - accuracy: 0.8370 - val_loss: 0.4217 - val_accuracy: 0.8509\n",
            "Epoch 89/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4554 - accuracy: 0.8381 - val_loss: 0.4210 - val_accuracy: 0.8542\n",
            "Epoch 90/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4578 - accuracy: 0.8368 - val_loss: 0.4214 - val_accuracy: 0.8530\n",
            "Epoch 91/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4529 - accuracy: 0.8413 - val_loss: 0.4218 - val_accuracy: 0.8509\n",
            "Epoch 92/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4546 - accuracy: 0.8414 - val_loss: 0.4216 - val_accuracy: 0.8522\n",
            "Epoch 93/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4452 - accuracy: 0.8417 - val_loss: 0.4236 - val_accuracy: 0.8519\n",
            "Epoch 94/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4536 - accuracy: 0.8391 - val_loss: 0.4202 - val_accuracy: 0.8516\n",
            "Epoch 95/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4614 - accuracy: 0.8431 - val_loss: 0.4210 - val_accuracy: 0.8541\n",
            "Epoch 96/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4458 - accuracy: 0.8449 - val_loss: 0.4210 - val_accuracy: 0.8517\n",
            "Epoch 97/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4479 - accuracy: 0.8447 - val_loss: 0.4180 - val_accuracy: 0.8556\n",
            "Epoch 98/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4416 - accuracy: 0.8412 - val_loss: 0.4168 - val_accuracy: 0.8544\n",
            "Epoch 99/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4533 - accuracy: 0.8368 - val_loss: 0.4165 - val_accuracy: 0.8573\n",
            "Epoch 100/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4457 - accuracy: 0.8454 - val_loss: 0.4121 - val_accuracy: 0.8552\n",
            "Epoch 101/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4453 - accuracy: 0.8436 - val_loss: 0.4137 - val_accuracy: 0.8553\n",
            "Epoch 102/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4446 - accuracy: 0.8405 - val_loss: 0.4132 - val_accuracy: 0.8545\n",
            "Epoch 103/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4332 - accuracy: 0.8423 - val_loss: 0.4134 - val_accuracy: 0.8562\n",
            "Epoch 104/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4439 - accuracy: 0.8431 - val_loss: 0.4150 - val_accuracy: 0.8527\n",
            "Epoch 105/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4370 - accuracy: 0.8448 - val_loss: 0.4137 - val_accuracy: 0.8550\n",
            "Epoch 106/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4371 - accuracy: 0.8482 - val_loss: 0.4150 - val_accuracy: 0.8536\n",
            "Epoch 107/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4343 - accuracy: 0.8425 - val_loss: 0.4114 - val_accuracy: 0.8570\n",
            "Epoch 108/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4434 - accuracy: 0.8405 - val_loss: 0.4107 - val_accuracy: 0.8564\n",
            "Epoch 109/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4436 - accuracy: 0.8473 - val_loss: 0.4113 - val_accuracy: 0.8528\n",
            "Epoch 110/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4348 - accuracy: 0.8476 - val_loss: 0.4104 - val_accuracy: 0.8537\n",
            "Epoch 111/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4373 - accuracy: 0.8475 - val_loss: 0.4072 - val_accuracy: 0.8575\n",
            "Epoch 112/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4358 - accuracy: 0.8438 - val_loss: 0.4130 - val_accuracy: 0.8550\n",
            "Epoch 113/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4450 - accuracy: 0.8405 - val_loss: 0.4065 - val_accuracy: 0.8594\n",
            "Epoch 114/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4288 - accuracy: 0.8484 - val_loss: 0.4104 - val_accuracy: 0.8536\n",
            "Epoch 115/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4315 - accuracy: 0.8483 - val_loss: 0.4090 - val_accuracy: 0.8559\n",
            "Epoch 116/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4381 - accuracy: 0.8454 - val_loss: 0.4072 - val_accuracy: 0.8592\n",
            "Epoch 117/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.8504 - val_loss: 0.4066 - val_accuracy: 0.8575\n",
            "Epoch 118/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4370 - accuracy: 0.8466 - val_loss: 0.4064 - val_accuracy: 0.8553\n",
            "Epoch 119/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4348 - accuracy: 0.8490 - val_loss: 0.4071 - val_accuracy: 0.8584\n",
            "Epoch 120/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4258 - accuracy: 0.8530 - val_loss: 0.4091 - val_accuracy: 0.8547\n",
            "Epoch 121/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4327 - accuracy: 0.8466 - val_loss: 0.4049 - val_accuracy: 0.8577\n",
            "Epoch 122/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8496 - val_loss: 0.4064 - val_accuracy: 0.8544\n",
            "Epoch 123/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.8494 - val_loss: 0.4088 - val_accuracy: 0.8520\n",
            "Epoch 124/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4260 - accuracy: 0.8473 - val_loss: 0.4057 - val_accuracy: 0.8580\n",
            "Epoch 125/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8483 - val_loss: 0.4030 - val_accuracy: 0.8608\n",
            "Epoch 126/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.8483 - val_loss: 0.4035 - val_accuracy: 0.8555\n",
            "Epoch 127/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8489 - val_loss: 0.4023 - val_accuracy: 0.8592\n",
            "Epoch 128/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8491 - val_loss: 0.4029 - val_accuracy: 0.8587\n",
            "Epoch 129/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8505 - val_loss: 0.4012 - val_accuracy: 0.8583\n",
            "Epoch 130/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4311 - accuracy: 0.8471 - val_loss: 0.4008 - val_accuracy: 0.8602\n",
            "Epoch 131/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8477 - val_loss: 0.4047 - val_accuracy: 0.8583\n",
            "Epoch 132/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4310 - accuracy: 0.8496 - val_loss: 0.4022 - val_accuracy: 0.8566\n",
            "Epoch 133/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8534 - val_loss: 0.3972 - val_accuracy: 0.8570\n",
            "Epoch 134/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4119 - accuracy: 0.8552 - val_loss: 0.4004 - val_accuracy: 0.8586\n",
            "Epoch 135/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4149 - accuracy: 0.8507 - val_loss: 0.3983 - val_accuracy: 0.8592\n",
            "Epoch 136/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4132 - accuracy: 0.8508 - val_loss: 0.4022 - val_accuracy: 0.8567\n",
            "Epoch 137/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.8464 - val_loss: 0.4068 - val_accuracy: 0.8556\n",
            "Epoch 138/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4108 - accuracy: 0.8537 - val_loss: 0.3987 - val_accuracy: 0.8628\n",
            "Epoch 139/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8495 - val_loss: 0.3956 - val_accuracy: 0.8597\n",
            "Epoch 140/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4188 - accuracy: 0.8505 - val_loss: 0.3996 - val_accuracy: 0.8573\n",
            "Epoch 141/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8499 - val_loss: 0.3953 - val_accuracy: 0.8634\n",
            "Epoch 142/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4111 - accuracy: 0.8564 - val_loss: 0.3966 - val_accuracy: 0.8609\n",
            "Epoch 143/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4026 - accuracy: 0.8548 - val_loss: 0.3947 - val_accuracy: 0.8616\n",
            "Epoch 144/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4210 - accuracy: 0.8515 - val_loss: 0.4020 - val_accuracy: 0.8587\n",
            "Epoch 145/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4103 - accuracy: 0.8565 - val_loss: 0.4001 - val_accuracy: 0.8620\n",
            "Epoch 146/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4259 - accuracy: 0.8494 - val_loss: 0.3916 - val_accuracy: 0.8619\n",
            "Epoch 147/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4107 - accuracy: 0.8557 - val_loss: 0.3940 - val_accuracy: 0.8616\n",
            "Epoch 148/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4069 - accuracy: 0.8562 - val_loss: 0.3952 - val_accuracy: 0.8612\n",
            "Epoch 149/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4101 - accuracy: 0.8514 - val_loss: 0.3936 - val_accuracy: 0.8625\n",
            "Epoch 150/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4126 - accuracy: 0.8541 - val_loss: 0.3954 - val_accuracy: 0.8630\n",
            "Epoch 151/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4178 - accuracy: 0.8498 - val_loss: 0.3990 - val_accuracy: 0.8586\n",
            "Epoch 152/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4082 - accuracy: 0.8598 - val_loss: 0.3969 - val_accuracy: 0.8603\n",
            "Epoch 153/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4111 - accuracy: 0.8562 - val_loss: 0.3930 - val_accuracy: 0.8664\n",
            "Epoch 154/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4031 - accuracy: 0.8552 - val_loss: 0.3896 - val_accuracy: 0.8636\n",
            "Epoch 155/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4178 - accuracy: 0.8505 - val_loss: 0.3926 - val_accuracy: 0.8630\n",
            "Epoch 156/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4119 - accuracy: 0.8565 - val_loss: 0.3952 - val_accuracy: 0.8609\n",
            "Epoch 157/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4050 - accuracy: 0.8584 - val_loss: 0.3900 - val_accuracy: 0.8616\n",
            "Epoch 158/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4095 - accuracy: 0.8559 - val_loss: 0.3981 - val_accuracy: 0.8633\n",
            "Epoch 159/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4029 - accuracy: 0.8525 - val_loss: 0.3945 - val_accuracy: 0.8605\n",
            "Epoch 160/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4195 - accuracy: 0.8530 - val_loss: 0.3883 - val_accuracy: 0.8630\n",
            "Epoch 161/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4106 - accuracy: 0.8534 - val_loss: 0.3913 - val_accuracy: 0.8614\n",
            "Epoch 162/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4018 - accuracy: 0.8627 - val_loss: 0.3906 - val_accuracy: 0.8642\n",
            "Epoch 163/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4084 - accuracy: 0.8535 - val_loss: 0.3892 - val_accuracy: 0.8634\n",
            "Epoch 164/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4085 - accuracy: 0.8526 - val_loss: 0.3900 - val_accuracy: 0.8645\n",
            "Epoch 165/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4086 - accuracy: 0.8561 - val_loss: 0.3918 - val_accuracy: 0.8603\n",
            "Epoch 166/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4016 - accuracy: 0.8594 - val_loss: 0.3925 - val_accuracy: 0.8642\n",
            "Epoch 167/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4021 - accuracy: 0.8555 - val_loss: 0.3960 - val_accuracy: 0.8592\n",
            "Epoch 168/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4035 - accuracy: 0.8561 - val_loss: 0.3885 - val_accuracy: 0.8648\n",
            "Epoch 169/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4051 - accuracy: 0.8565 - val_loss: 0.3889 - val_accuracy: 0.8648\n",
            "Epoch 170/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4003 - accuracy: 0.8544 - val_loss: 0.3917 - val_accuracy: 0.8595\n",
            "Epoch 171/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3926 - accuracy: 0.8595 - val_loss: 0.3886 - val_accuracy: 0.8653\n",
            "Epoch 172/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4013 - accuracy: 0.8559 - val_loss: 0.3881 - val_accuracy: 0.8623\n",
            "Epoch 173/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4038 - accuracy: 0.8542 - val_loss: 0.3939 - val_accuracy: 0.8644\n",
            "Epoch 174/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4087 - accuracy: 0.8555 - val_loss: 0.3865 - val_accuracy: 0.8652\n",
            "Epoch 175/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4085 - accuracy: 0.8584 - val_loss: 0.3845 - val_accuracy: 0.8648\n",
            "Epoch 176/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4013 - accuracy: 0.8587 - val_loss: 0.3904 - val_accuracy: 0.8612\n",
            "Epoch 177/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3926 - accuracy: 0.8559 - val_loss: 0.3854 - val_accuracy: 0.8652\n",
            "Epoch 178/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3961 - accuracy: 0.8562 - val_loss: 0.3844 - val_accuracy: 0.8644\n",
            "Epoch 179/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4095 - accuracy: 0.8533 - val_loss: 0.3887 - val_accuracy: 0.8623\n",
            "Epoch 180/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3975 - accuracy: 0.8605 - val_loss: 0.3886 - val_accuracy: 0.8620\n",
            "Epoch 181/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3975 - accuracy: 0.8595 - val_loss: 0.3903 - val_accuracy: 0.8641\n",
            "Epoch 182/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3925 - accuracy: 0.8584 - val_loss: 0.3865 - val_accuracy: 0.8658\n",
            "Epoch 183/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4039 - accuracy: 0.8566 - val_loss: 0.3838 - val_accuracy: 0.8650\n",
            "Epoch 184/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3931 - accuracy: 0.8608 - val_loss: 0.3883 - val_accuracy: 0.8644\n",
            "Epoch 185/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3990 - accuracy: 0.8607 - val_loss: 0.3849 - val_accuracy: 0.8636\n",
            "Epoch 186/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3918 - accuracy: 0.8581 - val_loss: 0.3885 - val_accuracy: 0.8664\n",
            "Epoch 187/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4015 - accuracy: 0.8568 - val_loss: 0.3879 - val_accuracy: 0.8650\n",
            "Epoch 188/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4072 - accuracy: 0.8559 - val_loss: 0.3838 - val_accuracy: 0.8656\n",
            "Epoch 189/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3958 - accuracy: 0.8584 - val_loss: 0.3839 - val_accuracy: 0.8662\n",
            "Epoch 190/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3911 - accuracy: 0.8641 - val_loss: 0.3856 - val_accuracy: 0.8616\n",
            "Epoch 191/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4003 - accuracy: 0.8562 - val_loss: 0.3818 - val_accuracy: 0.8667\n",
            "Epoch 192/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3926 - accuracy: 0.8614 - val_loss: 0.3834 - val_accuracy: 0.8648\n",
            "Epoch 193/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3996 - accuracy: 0.8594 - val_loss: 0.3840 - val_accuracy: 0.8647\n",
            "Epoch 194/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3937 - accuracy: 0.8605 - val_loss: 0.3861 - val_accuracy: 0.8664\n",
            "Epoch 195/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3903 - accuracy: 0.8635 - val_loss: 0.3857 - val_accuracy: 0.8648\n",
            "Epoch 196/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3833 - accuracy: 0.8633 - val_loss: 0.3835 - val_accuracy: 0.8669\n",
            "Epoch 197/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3917 - accuracy: 0.8606 - val_loss: 0.3814 - val_accuracy: 0.8645\n",
            "Epoch 198/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3959 - accuracy: 0.8637 - val_loss: 0.3836 - val_accuracy: 0.8639\n",
            "Epoch 199/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3915 - accuracy: 0.8612 - val_loss: 0.3883 - val_accuracy: 0.8655\n",
            "Epoch 200/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3868 - accuracy: 0.8630 - val_loss: 0.3851 - val_accuracy: 0.8672\n",
            "Epoch 201/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3842 - accuracy: 0.8630 - val_loss: 0.3808 - val_accuracy: 0.8667\n",
            "Epoch 202/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3959 - accuracy: 0.8599 - val_loss: 0.3828 - val_accuracy: 0.8656\n",
            "Epoch 203/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3913 - accuracy: 0.8607 - val_loss: 0.3811 - val_accuracy: 0.8680\n",
            "Epoch 204/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3944 - accuracy: 0.8642 - val_loss: 0.3815 - val_accuracy: 0.8678\n",
            "Epoch 205/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3896 - accuracy: 0.8603 - val_loss: 0.3805 - val_accuracy: 0.8652\n",
            "Epoch 206/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3937 - accuracy: 0.8574 - val_loss: 0.3821 - val_accuracy: 0.8652\n",
            "Epoch 207/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3887 - accuracy: 0.8635 - val_loss: 0.3801 - val_accuracy: 0.8656\n",
            "Epoch 208/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3901 - accuracy: 0.8625 - val_loss: 0.3842 - val_accuracy: 0.8644\n",
            "Epoch 209/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3906 - accuracy: 0.8625 - val_loss: 0.3810 - val_accuracy: 0.8691\n",
            "Epoch 210/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3812 - accuracy: 0.8602 - val_loss: 0.3775 - val_accuracy: 0.8684\n",
            "Epoch 211/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3915 - accuracy: 0.8620 - val_loss: 0.3797 - val_accuracy: 0.8689\n",
            "Epoch 212/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3925 - accuracy: 0.8598 - val_loss: 0.3829 - val_accuracy: 0.8627\n",
            "Epoch 213/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3844 - accuracy: 0.8658 - val_loss: 0.3846 - val_accuracy: 0.8659\n",
            "Epoch 214/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3861 - accuracy: 0.8614 - val_loss: 0.3814 - val_accuracy: 0.8677\n",
            "Epoch 215/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3919 - accuracy: 0.8625 - val_loss: 0.3788 - val_accuracy: 0.8666\n",
            "Epoch 216/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3916 - accuracy: 0.8609 - val_loss: 0.3778 - val_accuracy: 0.8673\n",
            "Epoch 217/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3834 - accuracy: 0.8663 - val_loss: 0.3743 - val_accuracy: 0.8678\n",
            "Epoch 218/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3881 - accuracy: 0.8640 - val_loss: 0.3786 - val_accuracy: 0.8653\n",
            "Epoch 219/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3859 - accuracy: 0.8620 - val_loss: 0.3784 - val_accuracy: 0.8677\n",
            "Epoch 220/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3844 - accuracy: 0.8625 - val_loss: 0.3773 - val_accuracy: 0.8678\n",
            "Epoch 221/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3905 - accuracy: 0.8618 - val_loss: 0.3777 - val_accuracy: 0.8667\n",
            "Epoch 222/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3858 - accuracy: 0.8618 - val_loss: 0.3770 - val_accuracy: 0.8652\n",
            "Epoch 223/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3790 - accuracy: 0.8652 - val_loss: 0.3785 - val_accuracy: 0.8664\n",
            "Epoch 224/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3831 - accuracy: 0.8607 - val_loss: 0.3778 - val_accuracy: 0.8664\n",
            "Epoch 225/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3863 - accuracy: 0.8637 - val_loss: 0.3772 - val_accuracy: 0.8678\n",
            "Epoch 226/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3849 - accuracy: 0.8631 - val_loss: 0.3781 - val_accuracy: 0.8662\n",
            "Epoch 227/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3803 - accuracy: 0.8624 - val_loss: 0.3780 - val_accuracy: 0.8673\n",
            "Epoch 228/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3814 - accuracy: 0.8648 - val_loss: 0.3775 - val_accuracy: 0.8670\n",
            "Epoch 229/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3860 - accuracy: 0.8663 - val_loss: 0.3757 - val_accuracy: 0.8667\n",
            "Epoch 230/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3891 - accuracy: 0.8632 - val_loss: 0.3760 - val_accuracy: 0.8670\n",
            "Epoch 231/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3817 - accuracy: 0.8636 - val_loss: 0.3738 - val_accuracy: 0.8687\n",
            "Epoch 232/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3813 - accuracy: 0.8643 - val_loss: 0.3752 - val_accuracy: 0.8678\n",
            "Epoch 233/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3823 - accuracy: 0.8631 - val_loss: 0.3783 - val_accuracy: 0.8695\n",
            "Epoch 234/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3730 - accuracy: 0.8673 - val_loss: 0.3831 - val_accuracy: 0.8653\n",
            "Epoch 235/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3883 - accuracy: 0.8627 - val_loss: 0.3772 - val_accuracy: 0.8672\n",
            "Epoch 236/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3833 - accuracy: 0.8623 - val_loss: 0.3753 - val_accuracy: 0.8697\n",
            "Epoch 237/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3789 - accuracy: 0.8692 - val_loss: 0.3770 - val_accuracy: 0.8675\n",
            "Epoch 238/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3732 - accuracy: 0.8655 - val_loss: 0.3731 - val_accuracy: 0.8691\n",
            "Epoch 239/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3815 - accuracy: 0.8662 - val_loss: 0.3747 - val_accuracy: 0.8680\n",
            "Epoch 240/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3858 - accuracy: 0.8637 - val_loss: 0.3766 - val_accuracy: 0.8658\n",
            "Epoch 241/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3752 - accuracy: 0.8678 - val_loss: 0.3775 - val_accuracy: 0.8698\n",
            "Epoch 242/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3760 - accuracy: 0.8624 - val_loss: 0.3793 - val_accuracy: 0.8687\n",
            "Epoch 243/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3838 - accuracy: 0.8641 - val_loss: 0.3754 - val_accuracy: 0.8687\n",
            "Epoch 244/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3827 - accuracy: 0.8619 - val_loss: 0.3773 - val_accuracy: 0.8653\n",
            "Epoch 245/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3817 - accuracy: 0.8659 - val_loss: 0.3743 - val_accuracy: 0.8662\n",
            "Epoch 246/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3739 - accuracy: 0.8667 - val_loss: 0.3751 - val_accuracy: 0.8689\n",
            "Epoch 247/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3820 - accuracy: 0.8649 - val_loss: 0.3792 - val_accuracy: 0.8642\n",
            "Epoch 248/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3721 - accuracy: 0.8636 - val_loss: 0.3772 - val_accuracy: 0.8681\n",
            "Epoch 249/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3793 - accuracy: 0.8666 - val_loss: 0.3741 - val_accuracy: 0.8672\n",
            "Epoch 250/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3762 - accuracy: 0.8655 - val_loss: 0.3721 - val_accuracy: 0.8697\n",
            "Epoch 251/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3806 - accuracy: 0.8684 - val_loss: 0.3715 - val_accuracy: 0.8717\n",
            "Epoch 252/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3734 - accuracy: 0.8631 - val_loss: 0.3712 - val_accuracy: 0.8712\n",
            "Epoch 253/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3770 - accuracy: 0.8632 - val_loss: 0.3723 - val_accuracy: 0.8683\n",
            "Epoch 254/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3838 - accuracy: 0.8609 - val_loss: 0.3768 - val_accuracy: 0.8675\n",
            "Epoch 255/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3744 - accuracy: 0.8680 - val_loss: 0.3741 - val_accuracy: 0.8686\n",
            "Epoch 256/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3735 - accuracy: 0.8648 - val_loss: 0.3719 - val_accuracy: 0.8714\n",
            "Epoch 257/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3774 - accuracy: 0.8671 - val_loss: 0.3748 - val_accuracy: 0.8692\n",
            "Epoch 258/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3779 - accuracy: 0.8651 - val_loss: 0.3741 - val_accuracy: 0.8703\n",
            "Epoch 259/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3801 - accuracy: 0.8663 - val_loss: 0.3712 - val_accuracy: 0.8684\n",
            "Epoch 260/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3715 - accuracy: 0.8662 - val_loss: 0.3697 - val_accuracy: 0.8694\n",
            "Epoch 261/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3733 - accuracy: 0.8660 - val_loss: 0.3759 - val_accuracy: 0.8684\n",
            "Epoch 262/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3715 - accuracy: 0.8665 - val_loss: 0.3752 - val_accuracy: 0.8673\n",
            "Epoch 263/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3809 - accuracy: 0.8647 - val_loss: 0.3722 - val_accuracy: 0.8702\n",
            "Epoch 264/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3744 - accuracy: 0.8670 - val_loss: 0.3710 - val_accuracy: 0.8723\n",
            "Epoch 265/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3721 - accuracy: 0.8689 - val_loss: 0.3698 - val_accuracy: 0.8703\n",
            "Epoch 266/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3713 - accuracy: 0.8644 - val_loss: 0.3703 - val_accuracy: 0.8694\n",
            "Epoch 267/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3808 - accuracy: 0.8629 - val_loss: 0.3713 - val_accuracy: 0.8702\n",
            "Epoch 268/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3803 - accuracy: 0.8651 - val_loss: 0.3787 - val_accuracy: 0.8655\n",
            "Epoch 269/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3602 - accuracy: 0.8726 - val_loss: 0.3737 - val_accuracy: 0.8694\n",
            "Epoch 270/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3744 - accuracy: 0.8658 - val_loss: 0.3729 - val_accuracy: 0.8703\n",
            "Epoch 271/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3750 - accuracy: 0.8662 - val_loss: 0.3707 - val_accuracy: 0.8683\n",
            "Epoch 272/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3836 - accuracy: 0.8627 - val_loss: 0.3705 - val_accuracy: 0.8708\n",
            "Epoch 273/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3661 - accuracy: 0.8700 - val_loss: 0.3723 - val_accuracy: 0.8675\n",
            "Epoch 274/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3674 - accuracy: 0.8703 - val_loss: 0.3690 - val_accuracy: 0.8698\n",
            "Epoch 275/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3744 - accuracy: 0.8668 - val_loss: 0.3732 - val_accuracy: 0.8680\n",
            "Epoch 276/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3626 - accuracy: 0.8702 - val_loss: 0.3731 - val_accuracy: 0.8698\n",
            "Epoch 277/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3864 - accuracy: 0.8628 - val_loss: 0.3687 - val_accuracy: 0.8697\n",
            "Epoch 278/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3775 - accuracy: 0.8653 - val_loss: 0.3683 - val_accuracy: 0.8686\n",
            "Epoch 279/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3678 - accuracy: 0.8713 - val_loss: 0.3680 - val_accuracy: 0.8683\n",
            "Epoch 280/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3683 - accuracy: 0.8679 - val_loss: 0.3731 - val_accuracy: 0.8706\n",
            "Epoch 281/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3698 - accuracy: 0.8677 - val_loss: 0.3702 - val_accuracy: 0.8709\n",
            "Epoch 282/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3765 - accuracy: 0.8615 - val_loss: 0.3730 - val_accuracy: 0.8664\n",
            "Epoch 283/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3675 - accuracy: 0.8691 - val_loss: 0.3750 - val_accuracy: 0.8677\n",
            "Epoch 284/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3684 - accuracy: 0.8684 - val_loss: 0.3802 - val_accuracy: 0.8661\n",
            "Epoch 285/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3631 - accuracy: 0.8723 - val_loss: 0.3690 - val_accuracy: 0.8722\n",
            "Epoch 286/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3789 - accuracy: 0.8605 - val_loss: 0.3719 - val_accuracy: 0.8706\n",
            "Epoch 287/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3650 - accuracy: 0.8687 - val_loss: 0.3764 - val_accuracy: 0.8670\n",
            "Epoch 288/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3661 - accuracy: 0.8714 - val_loss: 0.3666 - val_accuracy: 0.8706\n",
            "Epoch 289/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3697 - accuracy: 0.8644 - val_loss: 0.3742 - val_accuracy: 0.8709\n",
            "Epoch 290/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3646 - accuracy: 0.8707 - val_loss: 0.3716 - val_accuracy: 0.8686\n",
            "Epoch 291/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3715 - accuracy: 0.8655 - val_loss: 0.3706 - val_accuracy: 0.8698\n",
            "Epoch 292/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3768 - accuracy: 0.8648 - val_loss: 0.3679 - val_accuracy: 0.8731\n",
            "Epoch 293/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3670 - accuracy: 0.8701 - val_loss: 0.3657 - val_accuracy: 0.8689\n",
            "Epoch 294/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3664 - accuracy: 0.8680 - val_loss: 0.3694 - val_accuracy: 0.8683\n",
            "Epoch 295/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3730 - accuracy: 0.8649 - val_loss: 0.3663 - val_accuracy: 0.8714\n",
            "Epoch 296/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3742 - accuracy: 0.8662 - val_loss: 0.3709 - val_accuracy: 0.8706\n",
            "Epoch 297/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3665 - accuracy: 0.8692 - val_loss: 0.3701 - val_accuracy: 0.8694\n",
            "Epoch 298/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3653 - accuracy: 0.8698 - val_loss: 0.3733 - val_accuracy: 0.8673\n",
            "Epoch 299/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3611 - accuracy: 0.8708 - val_loss: 0.3700 - val_accuracy: 0.8706\n",
            "Epoch 300/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3702 - accuracy: 0.8661 - val_loss: 0.3680 - val_accuracy: 0.8700\n",
            "Epoch 301/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3619 - accuracy: 0.8687 - val_loss: 0.3718 - val_accuracy: 0.8677\n",
            "Epoch 302/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3649 - accuracy: 0.8727 - val_loss: 0.3690 - val_accuracy: 0.8719\n",
            "Epoch 303/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3735 - accuracy: 0.8663 - val_loss: 0.3685 - val_accuracy: 0.8692\n",
            "Epoch 304/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3649 - accuracy: 0.8709 - val_loss: 0.3715 - val_accuracy: 0.8722\n",
            "Epoch 305/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3722 - accuracy: 0.8681 - val_loss: 0.3686 - val_accuracy: 0.8700\n",
            "Epoch 306/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3677 - accuracy: 0.8691 - val_loss: 0.3678 - val_accuracy: 0.8684\n",
            "Epoch 307/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3621 - accuracy: 0.8724 - val_loss: 0.3688 - val_accuracy: 0.8711\n",
            "Epoch 308/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3591 - accuracy: 0.8655 - val_loss: 0.3674 - val_accuracy: 0.8706\n",
            "Epoch 309/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3646 - accuracy: 0.8718 - val_loss: 0.3646 - val_accuracy: 0.8733\n",
            "Epoch 310/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3684 - accuracy: 0.8705 - val_loss: 0.3676 - val_accuracy: 0.8709\n",
            "Epoch 311/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3659 - accuracy: 0.8698 - val_loss: 0.3694 - val_accuracy: 0.8689\n",
            "Epoch 312/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3543 - accuracy: 0.8744 - val_loss: 0.3657 - val_accuracy: 0.8705\n",
            "Epoch 313/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3575 - accuracy: 0.8711 - val_loss: 0.3675 - val_accuracy: 0.8712\n",
            "Epoch 314/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3666 - accuracy: 0.8671 - val_loss: 0.3659 - val_accuracy: 0.8672\n",
            "Epoch 315/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3686 - accuracy: 0.8695 - val_loss: 0.3662 - val_accuracy: 0.8686\n",
            "Epoch 316/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3559 - accuracy: 0.8728 - val_loss: 0.3740 - val_accuracy: 0.8700\n",
            "Epoch 317/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3642 - accuracy: 0.8677 - val_loss: 0.3739 - val_accuracy: 0.8691\n",
            "Epoch 318/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3577 - accuracy: 0.8697 - val_loss: 0.3677 - val_accuracy: 0.8706\n",
            "Epoch 319/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3697 - accuracy: 0.8662 - val_loss: 0.3692 - val_accuracy: 0.8708\n",
            "Epoch 320/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3602 - accuracy: 0.8725 - val_loss: 0.3703 - val_accuracy: 0.8725\n",
            "Epoch 321/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3651 - accuracy: 0.8730 - val_loss: 0.3644 - val_accuracy: 0.8706\n",
            "Epoch 322/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3596 - accuracy: 0.8679 - val_loss: 0.3669 - val_accuracy: 0.8716\n",
            "Epoch 323/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3573 - accuracy: 0.8692 - val_loss: 0.3637 - val_accuracy: 0.8677\n",
            "Epoch 324/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3676 - accuracy: 0.8656 - val_loss: 0.3651 - val_accuracy: 0.8698\n",
            "Epoch 325/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3635 - accuracy: 0.8725 - val_loss: 0.3680 - val_accuracy: 0.8691\n",
            "Epoch 326/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3572 - accuracy: 0.8716 - val_loss: 0.3676 - val_accuracy: 0.8712\n",
            "Epoch 327/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3563 - accuracy: 0.8716 - val_loss: 0.3688 - val_accuracy: 0.8722\n",
            "Epoch 328/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3610 - accuracy: 0.8705 - val_loss: 0.3665 - val_accuracy: 0.8705\n",
            "Epoch 329/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3618 - accuracy: 0.8733 - val_loss: 0.3660 - val_accuracy: 0.8712\n",
            "Epoch 330/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3599 - accuracy: 0.8722 - val_loss: 0.3649 - val_accuracy: 0.8708\n",
            "Epoch 331/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3559 - accuracy: 0.8734 - val_loss: 0.3695 - val_accuracy: 0.8722\n",
            "Epoch 332/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3588 - accuracy: 0.8719 - val_loss: 0.3680 - val_accuracy: 0.8695\n",
            "Epoch 333/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3696 - accuracy: 0.8673 - val_loss: 0.3650 - val_accuracy: 0.8700\n",
            "Epoch 334/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3514 - accuracy: 0.8753 - val_loss: 0.3655 - val_accuracy: 0.8703\n",
            "Epoch 335/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3620 - accuracy: 0.8720 - val_loss: 0.3648 - val_accuracy: 0.8692\n",
            "Epoch 336/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3590 - accuracy: 0.8709 - val_loss: 0.3632 - val_accuracy: 0.8694\n",
            "Epoch 337/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3585 - accuracy: 0.8684 - val_loss: 0.3650 - val_accuracy: 0.8719\n",
            "Epoch 338/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3567 - accuracy: 0.8723 - val_loss: 0.3672 - val_accuracy: 0.8720\n",
            "Epoch 339/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3558 - accuracy: 0.8708 - val_loss: 0.3636 - val_accuracy: 0.8709\n",
            "Epoch 340/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3590 - accuracy: 0.8725 - val_loss: 0.3706 - val_accuracy: 0.8702\n",
            "Epoch 341/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3582 - accuracy: 0.8704 - val_loss: 0.3632 - val_accuracy: 0.8728\n",
            "Epoch 342/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3624 - accuracy: 0.8670 - val_loss: 0.3623 - val_accuracy: 0.8712\n",
            "Epoch 343/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3625 - accuracy: 0.8727 - val_loss: 0.3691 - val_accuracy: 0.8680\n",
            "Epoch 344/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3511 - accuracy: 0.8741 - val_loss: 0.3680 - val_accuracy: 0.8720\n",
            "Epoch 345/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3589 - accuracy: 0.8702 - val_loss: 0.3658 - val_accuracy: 0.8714\n",
            "Epoch 346/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3589 - accuracy: 0.8748 - val_loss: 0.3657 - val_accuracy: 0.8711\n",
            "Epoch 347/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3653 - accuracy: 0.8677 - val_loss: 0.3646 - val_accuracy: 0.8695\n",
            "Epoch 348/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3543 - accuracy: 0.8748 - val_loss: 0.3631 - val_accuracy: 0.8716\n",
            "Epoch 349/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3565 - accuracy: 0.8763 - val_loss: 0.3632 - val_accuracy: 0.8716\n",
            "Epoch 350/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3579 - accuracy: 0.8668 - val_loss: 0.3638 - val_accuracy: 0.8722\n",
            "Epoch 351/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3515 - accuracy: 0.8748 - val_loss: 0.3652 - val_accuracy: 0.8717\n",
            "Epoch 352/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3586 - accuracy: 0.8755 - val_loss: 0.3646 - val_accuracy: 0.8719\n",
            "Epoch 353/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3573 - accuracy: 0.8713 - val_loss: 0.3638 - val_accuracy: 0.8725\n",
            "Epoch 354/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3552 - accuracy: 0.8718 - val_loss: 0.3619 - val_accuracy: 0.8725\n",
            "Epoch 355/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3448 - accuracy: 0.8734 - val_loss: 0.3635 - val_accuracy: 0.8727\n",
            "Epoch 356/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3529 - accuracy: 0.8737 - val_loss: 0.3632 - val_accuracy: 0.8725\n",
            "Epoch 357/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3615 - accuracy: 0.8726 - val_loss: 0.3654 - val_accuracy: 0.8691\n",
            "Epoch 358/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3491 - accuracy: 0.8735 - val_loss: 0.3679 - val_accuracy: 0.8733\n",
            "Epoch 359/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3518 - accuracy: 0.8735 - val_loss: 0.3671 - val_accuracy: 0.8725\n",
            "Epoch 360/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3667 - accuracy: 0.8701 - val_loss: 0.3630 - val_accuracy: 0.8744\n",
            "Epoch 361/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3600 - accuracy: 0.8705 - val_loss: 0.3601 - val_accuracy: 0.8722\n",
            "Epoch 362/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3590 - accuracy: 0.8707 - val_loss: 0.3641 - val_accuracy: 0.8719\n",
            "Epoch 363/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3563 - accuracy: 0.8720 - val_loss: 0.3627 - val_accuracy: 0.8714\n",
            "Epoch 364/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3590 - accuracy: 0.8730 - val_loss: 0.3661 - val_accuracy: 0.8698\n",
            "Epoch 365/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3516 - accuracy: 0.8738 - val_loss: 0.3649 - val_accuracy: 0.8717\n",
            "Epoch 366/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3659 - accuracy: 0.8702 - val_loss: 0.3628 - val_accuracy: 0.8703\n",
            "Epoch 367/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3571 - accuracy: 0.8718 - val_loss: 0.3640 - val_accuracy: 0.8687\n",
            "Epoch 368/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3500 - accuracy: 0.8730 - val_loss: 0.3620 - val_accuracy: 0.8706\n",
            "Epoch 369/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3520 - accuracy: 0.8719 - val_loss: 0.3652 - val_accuracy: 0.8708\n",
            "Epoch 370/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3563 - accuracy: 0.8698 - val_loss: 0.3625 - val_accuracy: 0.8733\n",
            "Epoch 371/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3642 - accuracy: 0.8690 - val_loss: 0.3632 - val_accuracy: 0.8709\n",
            "Epoch 372/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3508 - accuracy: 0.8761 - val_loss: 0.3628 - val_accuracy: 0.8752\n",
            "Epoch 373/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3594 - accuracy: 0.8699 - val_loss: 0.3633 - val_accuracy: 0.8708\n",
            "Epoch 374/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3445 - accuracy: 0.8741 - val_loss: 0.3612 - val_accuracy: 0.8748\n",
            "Epoch 375/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3604 - accuracy: 0.8693 - val_loss: 0.3628 - val_accuracy: 0.8736\n",
            "Epoch 376/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3545 - accuracy: 0.8743 - val_loss: 0.3652 - val_accuracy: 0.8700\n",
            "Epoch 377/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3519 - accuracy: 0.8730 - val_loss: 0.3603 - val_accuracy: 0.8742\n",
            "Epoch 378/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3583 - accuracy: 0.8716 - val_loss: 0.3704 - val_accuracy: 0.8698\n",
            "Epoch 379/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3460 - accuracy: 0.8742 - val_loss: 0.3715 - val_accuracy: 0.8705\n",
            "Epoch 380/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3582 - accuracy: 0.8677 - val_loss: 0.3637 - val_accuracy: 0.8708\n",
            "Epoch 381/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3516 - accuracy: 0.8767 - val_loss: 0.3633 - val_accuracy: 0.8714\n",
            "Epoch 382/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3463 - accuracy: 0.8745 - val_loss: 0.3614 - val_accuracy: 0.8725\n",
            "Epoch 383/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3495 - accuracy: 0.8730 - val_loss: 0.3646 - val_accuracy: 0.8714\n",
            "Epoch 384/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3567 - accuracy: 0.8705 - val_loss: 0.3623 - val_accuracy: 0.8737\n",
            "Epoch 385/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3508 - accuracy: 0.8730 - val_loss: 0.3694 - val_accuracy: 0.8680\n",
            "Epoch 386/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3473 - accuracy: 0.8784 - val_loss: 0.3647 - val_accuracy: 0.8703\n",
            "Epoch 387/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3555 - accuracy: 0.8688 - val_loss: 0.3664 - val_accuracy: 0.8667\n",
            "Epoch 388/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3435 - accuracy: 0.8770 - val_loss: 0.3635 - val_accuracy: 0.8716\n",
            "Epoch 389/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3537 - accuracy: 0.8741 - val_loss: 0.3607 - val_accuracy: 0.8739\n",
            "Epoch 390/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3494 - accuracy: 0.8741 - val_loss: 0.3663 - val_accuracy: 0.8655\n",
            "Epoch 391/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3450 - accuracy: 0.8759 - val_loss: 0.3602 - val_accuracy: 0.8730\n",
            "Epoch 392/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3479 - accuracy: 0.8754 - val_loss: 0.3715 - val_accuracy: 0.8691\n",
            "Epoch 393/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3540 - accuracy: 0.8684 - val_loss: 0.3664 - val_accuracy: 0.8714\n",
            "Epoch 394/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3610 - accuracy: 0.8736 - val_loss: 0.3631 - val_accuracy: 0.8706\n",
            "Epoch 395/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3540 - accuracy: 0.8723 - val_loss: 0.3610 - val_accuracy: 0.8714\n",
            "Epoch 396/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3492 - accuracy: 0.8780 - val_loss: 0.3595 - val_accuracy: 0.8730\n",
            "Epoch 397/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3524 - accuracy: 0.8716 - val_loss: 0.3599 - val_accuracy: 0.8731\n",
            "Epoch 398/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3519 - accuracy: 0.8755 - val_loss: 0.3592 - val_accuracy: 0.8737\n",
            "Epoch 399/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3588 - accuracy: 0.8708 - val_loss: 0.3669 - val_accuracy: 0.8683\n",
            "Epoch 400/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3467 - accuracy: 0.8749 - val_loss: 0.3646 - val_accuracy: 0.8719\n",
            "Epoch 401/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3575 - accuracy: 0.8689 - val_loss: 0.3660 - val_accuracy: 0.8678\n",
            "Epoch 402/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3471 - accuracy: 0.8748 - val_loss: 0.3634 - val_accuracy: 0.8744\n",
            "Epoch 403/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3583 - accuracy: 0.8715 - val_loss: 0.3625 - val_accuracy: 0.8745\n",
            "Epoch 404/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3523 - accuracy: 0.8735 - val_loss: 0.3648 - val_accuracy: 0.8700\n",
            "Epoch 405/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3455 - accuracy: 0.8742 - val_loss: 0.3596 - val_accuracy: 0.8734\n",
            "Epoch 406/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3431 - accuracy: 0.8761 - val_loss: 0.3670 - val_accuracy: 0.8700\n",
            "Epoch 407/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3443 - accuracy: 0.8752 - val_loss: 0.3652 - val_accuracy: 0.8714\n",
            "Epoch 408/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3552 - accuracy: 0.8700 - val_loss: 0.3657 - val_accuracy: 0.8692\n",
            "Epoch 409/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3501 - accuracy: 0.8753 - val_loss: 0.3613 - val_accuracy: 0.8737\n",
            "Epoch 410/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3521 - accuracy: 0.8785 - val_loss: 0.3608 - val_accuracy: 0.8716\n",
            "Epoch 411/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3467 - accuracy: 0.8713 - val_loss: 0.3609 - val_accuracy: 0.8717\n",
            "Epoch 412/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3467 - accuracy: 0.8742 - val_loss: 0.3589 - val_accuracy: 0.8719\n",
            "Epoch 413/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3578 - accuracy: 0.8725 - val_loss: 0.3601 - val_accuracy: 0.8727\n",
            "Epoch 414/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3461 - accuracy: 0.8733 - val_loss: 0.3659 - val_accuracy: 0.8698\n",
            "Epoch 415/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3432 - accuracy: 0.8776 - val_loss: 0.3707 - val_accuracy: 0.8684\n",
            "Epoch 416/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3469 - accuracy: 0.8760 - val_loss: 0.3620 - val_accuracy: 0.8752\n",
            "Epoch 417/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3470 - accuracy: 0.8731 - val_loss: 0.3635 - val_accuracy: 0.8728\n",
            "Epoch 418/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3514 - accuracy: 0.8727 - val_loss: 0.3675 - val_accuracy: 0.8677\n",
            "Epoch 419/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3443 - accuracy: 0.8765 - val_loss: 0.3653 - val_accuracy: 0.8717\n",
            "Epoch 420/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3465 - accuracy: 0.8777 - val_loss: 0.3622 - val_accuracy: 0.8741\n",
            "Epoch 421/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3384 - accuracy: 0.8780 - val_loss: 0.3631 - val_accuracy: 0.8728\n",
            "Epoch 422/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3566 - accuracy: 0.8681 - val_loss: 0.3579 - val_accuracy: 0.8723\n",
            "Epoch 423/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3406 - accuracy: 0.8783 - val_loss: 0.3629 - val_accuracy: 0.8730\n",
            "Epoch 424/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3411 - accuracy: 0.8800 - val_loss: 0.3599 - val_accuracy: 0.8741\n",
            "Epoch 425/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3463 - accuracy: 0.8738 - val_loss: 0.3626 - val_accuracy: 0.8687\n",
            "Epoch 426/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3456 - accuracy: 0.8757 - val_loss: 0.3600 - val_accuracy: 0.8742\n",
            "Epoch 427/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3526 - accuracy: 0.8727 - val_loss: 0.3594 - val_accuracy: 0.8756\n",
            "Epoch 428/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3401 - accuracy: 0.8788 - val_loss: 0.3611 - val_accuracy: 0.8723\n",
            "Epoch 429/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3498 - accuracy: 0.8761 - val_loss: 0.3629 - val_accuracy: 0.8719\n",
            "Epoch 430/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.8774 - val_loss: 0.3578 - val_accuracy: 0.8745\n",
            "Epoch 431/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3476 - accuracy: 0.8767 - val_loss: 0.3615 - val_accuracy: 0.8741\n",
            "Epoch 432/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3450 - accuracy: 0.8757 - val_loss: 0.3633 - val_accuracy: 0.8728\n",
            "Epoch 433/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3381 - accuracy: 0.8793 - val_loss: 0.3604 - val_accuracy: 0.8728\n",
            "Epoch 434/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3482 - accuracy: 0.8766 - val_loss: 0.3601 - val_accuracy: 0.8723\n",
            "Epoch 435/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3371 - accuracy: 0.8770 - val_loss: 0.3603 - val_accuracy: 0.8748\n",
            "Epoch 436/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3531 - accuracy: 0.8749 - val_loss: 0.3610 - val_accuracy: 0.8733\n",
            "Epoch 437/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3453 - accuracy: 0.8788 - val_loss: 0.3636 - val_accuracy: 0.8737\n",
            "Epoch 438/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.8795 - val_loss: 0.3609 - val_accuracy: 0.8744\n",
            "Epoch 439/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3397 - accuracy: 0.8754 - val_loss: 0.3617 - val_accuracy: 0.8739\n",
            "Epoch 440/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3417 - accuracy: 0.8780 - val_loss: 0.3631 - val_accuracy: 0.8727\n",
            "Epoch 441/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3442 - accuracy: 0.8754 - val_loss: 0.3574 - val_accuracy: 0.8753\n",
            "Epoch 442/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3453 - accuracy: 0.8791 - val_loss: 0.3579 - val_accuracy: 0.8722\n",
            "Epoch 443/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3408 - accuracy: 0.8770 - val_loss: 0.3604 - val_accuracy: 0.8730\n",
            "Epoch 444/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3388 - accuracy: 0.8763 - val_loss: 0.3602 - val_accuracy: 0.8741\n",
            "Epoch 445/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3378 - accuracy: 0.8778 - val_loss: 0.3622 - val_accuracy: 0.8734\n",
            "Epoch 446/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3448 - accuracy: 0.8746 - val_loss: 0.3612 - val_accuracy: 0.8705\n",
            "Epoch 447/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3433 - accuracy: 0.8768 - val_loss: 0.3616 - val_accuracy: 0.8725\n",
            "Epoch 448/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3534 - accuracy: 0.8740 - val_loss: 0.3614 - val_accuracy: 0.8737\n",
            "Epoch 449/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.8766 - val_loss: 0.3609 - val_accuracy: 0.8730\n",
            "Epoch 450/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3511 - accuracy: 0.8727 - val_loss: 0.3618 - val_accuracy: 0.8744\n",
            "Epoch 451/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3436 - accuracy: 0.8777 - val_loss: 0.3621 - val_accuracy: 0.8711\n",
            "Epoch 452/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3412 - accuracy: 0.8804 - val_loss: 0.3607 - val_accuracy: 0.8728\n",
            "Epoch 453/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3454 - accuracy: 0.8757 - val_loss: 0.3602 - val_accuracy: 0.8734\n",
            "Epoch 454/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3382 - accuracy: 0.8753 - val_loss: 0.3643 - val_accuracy: 0.8727\n",
            "Epoch 455/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3481 - accuracy: 0.8778 - val_loss: 0.3645 - val_accuracy: 0.8716\n",
            "Epoch 456/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3429 - accuracy: 0.8789 - val_loss: 0.3604 - val_accuracy: 0.8730\n",
            "Epoch 457/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3378 - accuracy: 0.8778 - val_loss: 0.3652 - val_accuracy: 0.8712\n",
            "Epoch 458/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3424 - accuracy: 0.8768 - val_loss: 0.3638 - val_accuracy: 0.8722\n",
            "Epoch 459/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3427 - accuracy: 0.8741 - val_loss: 0.3572 - val_accuracy: 0.8730\n",
            "Epoch 460/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3483 - accuracy: 0.8747 - val_loss: 0.3582 - val_accuracy: 0.8750\n",
            "Epoch 461/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3401 - accuracy: 0.8780 - val_loss: 0.3609 - val_accuracy: 0.8750\n",
            "Epoch 462/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3378 - accuracy: 0.8773 - val_loss: 0.3639 - val_accuracy: 0.8716\n",
            "Epoch 463/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3391 - accuracy: 0.8799 - val_loss: 0.3607 - val_accuracy: 0.8731\n",
            "Epoch 464/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3474 - accuracy: 0.8755 - val_loss: 0.3571 - val_accuracy: 0.8737\n",
            "Epoch 465/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3385 - accuracy: 0.8774 - val_loss: 0.3601 - val_accuracy: 0.8750\n",
            "Epoch 466/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3396 - accuracy: 0.8772 - val_loss: 0.3588 - val_accuracy: 0.8745\n",
            "Epoch 467/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3443 - accuracy: 0.8719 - val_loss: 0.3595 - val_accuracy: 0.8723\n",
            "Epoch 468/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3377 - accuracy: 0.8800 - val_loss: 0.3658 - val_accuracy: 0.8727\n",
            "Epoch 469/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3476 - accuracy: 0.8736 - val_loss: 0.3620 - val_accuracy: 0.8711\n",
            "Epoch 470/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3411 - accuracy: 0.8764 - val_loss: 0.3606 - val_accuracy: 0.8742\n",
            "Epoch 471/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3410 - accuracy: 0.8774 - val_loss: 0.3559 - val_accuracy: 0.8748\n",
            "Epoch 472/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3360 - accuracy: 0.8771 - val_loss: 0.3606 - val_accuracy: 0.8733\n",
            "Epoch 473/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3370 - accuracy: 0.8781 - val_loss: 0.3581 - val_accuracy: 0.8759\n",
            "Epoch 474/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3456 - accuracy: 0.8774 - val_loss: 0.3619 - val_accuracy: 0.8702\n",
            "Epoch 475/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3304 - accuracy: 0.8804 - val_loss: 0.3679 - val_accuracy: 0.8725\n",
            "Epoch 476/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3370 - accuracy: 0.8791 - val_loss: 0.3596 - val_accuracy: 0.8752\n",
            "Epoch 477/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3402 - accuracy: 0.8772 - val_loss: 0.3599 - val_accuracy: 0.8717\n",
            "Epoch 478/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3392 - accuracy: 0.8736 - val_loss: 0.3622 - val_accuracy: 0.8755\n",
            "Epoch 479/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3422 - accuracy: 0.8788 - val_loss: 0.3604 - val_accuracy: 0.8747\n",
            "Epoch 480/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3335 - accuracy: 0.8787 - val_loss: 0.3652 - val_accuracy: 0.8734\n",
            "Epoch 481/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3399 - accuracy: 0.8786 - val_loss: 0.3622 - val_accuracy: 0.8716\n",
            "Epoch 482/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3347 - accuracy: 0.8821 - val_loss: 0.3704 - val_accuracy: 0.8722\n",
            "Epoch 483/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3475 - accuracy: 0.8749 - val_loss: 0.3574 - val_accuracy: 0.8747\n",
            "Epoch 484/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3368 - accuracy: 0.8791 - val_loss: 0.3602 - val_accuracy: 0.8742\n",
            "Epoch 485/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3368 - accuracy: 0.8784 - val_loss: 0.3575 - val_accuracy: 0.8739\n",
            "Epoch 486/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3441 - accuracy: 0.8737 - val_loss: 0.3568 - val_accuracy: 0.8766\n",
            "Epoch 487/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3321 - accuracy: 0.8801 - val_loss: 0.3575 - val_accuracy: 0.8728\n",
            "Epoch 488/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3420 - accuracy: 0.8762 - val_loss: 0.3608 - val_accuracy: 0.8719\n",
            "Epoch 489/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3307 - accuracy: 0.8808 - val_loss: 0.3595 - val_accuracy: 0.8753\n",
            "Epoch 490/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3500 - accuracy: 0.8755 - val_loss: 0.3601 - val_accuracy: 0.8736\n",
            "Epoch 491/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3404 - accuracy: 0.8757 - val_loss: 0.3587 - val_accuracy: 0.8731\n",
            "Epoch 492/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3391 - accuracy: 0.8791 - val_loss: 0.3589 - val_accuracy: 0.8763\n",
            "Epoch 493/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3404 - accuracy: 0.8778 - val_loss: 0.3620 - val_accuracy: 0.8728\n",
            "Epoch 494/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3323 - accuracy: 0.8777 - val_loss: 0.3598 - val_accuracy: 0.8745\n",
            "Epoch 495/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3411 - accuracy: 0.8750 - val_loss: 0.3650 - val_accuracy: 0.8700\n",
            "Epoch 496/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3268 - accuracy: 0.8802 - val_loss: 0.3689 - val_accuracy: 0.8730\n",
            "Epoch 497/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3411 - accuracy: 0.8782 - val_loss: 0.3592 - val_accuracy: 0.8717\n",
            "Epoch 498/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3357 - accuracy: 0.8784 - val_loss: 0.3619 - val_accuracy: 0.8722\n",
            "Epoch 499/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3294 - accuracy: 0.8813 - val_loss: 0.3551 - val_accuracy: 0.8758\n",
            "Epoch 500/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3305 - accuracy: 0.8780 - val_loss: 0.3631 - val_accuracy: 0.8736\n",
            "Epoch 501/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3418 - accuracy: 0.8791 - val_loss: 0.3591 - val_accuracy: 0.8737\n",
            "Epoch 502/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3429 - accuracy: 0.8746 - val_loss: 0.3596 - val_accuracy: 0.8720\n",
            "Epoch 503/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3311 - accuracy: 0.8805 - val_loss: 0.3620 - val_accuracy: 0.8730\n",
            "Epoch 504/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3360 - accuracy: 0.8788 - val_loss: 0.3621 - val_accuracy: 0.8734\n",
            "Epoch 505/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3376 - accuracy: 0.8801 - val_loss: 0.3570 - val_accuracy: 0.8759\n",
            "Epoch 506/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3427 - accuracy: 0.8788 - val_loss: 0.3581 - val_accuracy: 0.8763\n",
            "Epoch 507/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3414 - accuracy: 0.8766 - val_loss: 0.3585 - val_accuracy: 0.8716\n",
            "Epoch 508/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.8788 - val_loss: 0.3585 - val_accuracy: 0.8755\n",
            "Epoch 509/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3385 - accuracy: 0.8773 - val_loss: 0.3621 - val_accuracy: 0.8717\n",
            "Epoch 510/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3310 - accuracy: 0.8802 - val_loss: 0.3628 - val_accuracy: 0.8733\n",
            "Epoch 511/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3396 - accuracy: 0.8759 - val_loss: 0.3582 - val_accuracy: 0.8733\n",
            "Epoch 512/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3411 - accuracy: 0.8776 - val_loss: 0.3574 - val_accuracy: 0.8761\n",
            "Epoch 513/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3336 - accuracy: 0.8810 - val_loss: 0.3581 - val_accuracy: 0.8728\n",
            "Epoch 514/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3322 - accuracy: 0.8746 - val_loss: 0.3612 - val_accuracy: 0.8747\n",
            "Epoch 515/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3329 - accuracy: 0.8813 - val_loss: 0.3568 - val_accuracy: 0.8734\n",
            "Epoch 516/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3418 - accuracy: 0.8775 - val_loss: 0.3599 - val_accuracy: 0.8733\n",
            "Epoch 517/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3327 - accuracy: 0.8811 - val_loss: 0.3606 - val_accuracy: 0.8733\n",
            "Epoch 518/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3345 - accuracy: 0.8764 - val_loss: 0.3737 - val_accuracy: 0.8681\n",
            "Epoch 519/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3316 - accuracy: 0.8770 - val_loss: 0.3607 - val_accuracy: 0.8772\n",
            "Epoch 520/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3400 - accuracy: 0.8787 - val_loss: 0.3625 - val_accuracy: 0.8742\n",
            "Epoch 521/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3371 - accuracy: 0.8773 - val_loss: 0.3598 - val_accuracy: 0.8716\n",
            "Epoch 522/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3314 - accuracy: 0.8852 - val_loss: 0.3599 - val_accuracy: 0.8770\n",
            "Epoch 523/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3296 - accuracy: 0.8796 - val_loss: 0.3594 - val_accuracy: 0.8744\n",
            "Epoch 524/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3366 - accuracy: 0.8762 - val_loss: 0.3659 - val_accuracy: 0.8730\n",
            "Epoch 525/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3346 - accuracy: 0.8777 - val_loss: 0.3580 - val_accuracy: 0.8700\n",
            "Epoch 526/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3361 - accuracy: 0.8763 - val_loss: 0.3587 - val_accuracy: 0.8778\n",
            "Epoch 527/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3387 - accuracy: 0.8795 - val_loss: 0.3564 - val_accuracy: 0.8753\n",
            "Epoch 528/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3330 - accuracy: 0.8786 - val_loss: 0.3584 - val_accuracy: 0.8739\n",
            "Epoch 529/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3327 - accuracy: 0.8803 - val_loss: 0.3554 - val_accuracy: 0.8750\n",
            "Epoch 530/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3477 - accuracy: 0.8727 - val_loss: 0.3583 - val_accuracy: 0.8736\n",
            "Epoch 531/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3302 - accuracy: 0.8831 - val_loss: 0.3637 - val_accuracy: 0.8717\n",
            "Epoch 532/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3330 - accuracy: 0.8784 - val_loss: 0.3624 - val_accuracy: 0.8733\n",
            "Epoch 533/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3285 - accuracy: 0.8825 - val_loss: 0.3603 - val_accuracy: 0.8763\n",
            "Epoch 534/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3279 - accuracy: 0.8827 - val_loss: 0.3581 - val_accuracy: 0.8764\n",
            "Epoch 535/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3392 - accuracy: 0.8752 - val_loss: 0.3592 - val_accuracy: 0.8739\n",
            "Epoch 536/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3269 - accuracy: 0.8825 - val_loss: 0.3581 - val_accuracy: 0.8756\n",
            "Epoch 537/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3324 - accuracy: 0.8810 - val_loss: 0.3586 - val_accuracy: 0.8747\n",
            "Epoch 538/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3319 - accuracy: 0.8833 - val_loss: 0.3590 - val_accuracy: 0.8761\n",
            "Epoch 539/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3409 - accuracy: 0.8787 - val_loss: 0.3611 - val_accuracy: 0.8731\n",
            "Epoch 540/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3362 - accuracy: 0.8801 - val_loss: 0.3574 - val_accuracy: 0.8750\n",
            "Epoch 541/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3256 - accuracy: 0.8816 - val_loss: 0.3584 - val_accuracy: 0.8731\n",
            "Epoch 542/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3386 - accuracy: 0.8783 - val_loss: 0.3581 - val_accuracy: 0.8720\n",
            "Epoch 543/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3273 - accuracy: 0.8829 - val_loss: 0.3544 - val_accuracy: 0.8764\n",
            "Epoch 544/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3339 - accuracy: 0.8788 - val_loss: 0.3603 - val_accuracy: 0.8741\n",
            "Epoch 545/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3368 - accuracy: 0.8805 - val_loss: 0.3602 - val_accuracy: 0.8733\n",
            "Epoch 546/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3268 - accuracy: 0.8826 - val_loss: 0.3650 - val_accuracy: 0.8739\n",
            "Epoch 547/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3270 - accuracy: 0.8819 - val_loss: 0.3615 - val_accuracy: 0.8741\n",
            "Epoch 548/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3366 - accuracy: 0.8755 - val_loss: 0.3603 - val_accuracy: 0.8737\n",
            "Epoch 549/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3348 - accuracy: 0.8784 - val_loss: 0.3603 - val_accuracy: 0.8752\n",
            "Epoch 550/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3356 - accuracy: 0.8776 - val_loss: 0.3601 - val_accuracy: 0.8763\n",
            "Epoch 551/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3302 - accuracy: 0.8811 - val_loss: 0.3578 - val_accuracy: 0.8747\n",
            "Epoch 552/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3339 - accuracy: 0.8796 - val_loss: 0.3564 - val_accuracy: 0.8767\n",
            "Epoch 553/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3318 - accuracy: 0.8776 - val_loss: 0.3573 - val_accuracy: 0.8737\n",
            "Epoch 554/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3268 - accuracy: 0.8799 - val_loss: 0.3536 - val_accuracy: 0.8769\n",
            "Epoch 555/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3258 - accuracy: 0.8789 - val_loss: 0.3562 - val_accuracy: 0.8733\n",
            "Epoch 556/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3239 - accuracy: 0.8803 - val_loss: 0.3602 - val_accuracy: 0.8703\n",
            "Epoch 557/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3360 - accuracy: 0.8785 - val_loss: 0.3571 - val_accuracy: 0.8722\n",
            "Epoch 558/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3299 - accuracy: 0.8802 - val_loss: 0.3555 - val_accuracy: 0.8742\n",
            "Epoch 559/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3318 - accuracy: 0.8820 - val_loss: 0.3573 - val_accuracy: 0.8758\n",
            "Epoch 560/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3266 - accuracy: 0.8791 - val_loss: 0.3573 - val_accuracy: 0.8767\n",
            "Epoch 561/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3309 - accuracy: 0.8802 - val_loss: 0.3613 - val_accuracy: 0.8739\n",
            "Epoch 562/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3351 - accuracy: 0.8769 - val_loss: 0.3557 - val_accuracy: 0.8755\n",
            "Epoch 563/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3357 - accuracy: 0.8773 - val_loss: 0.3602 - val_accuracy: 0.8716\n",
            "Epoch 564/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3267 - accuracy: 0.8826 - val_loss: 0.3615 - val_accuracy: 0.8761\n",
            "Epoch 565/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3335 - accuracy: 0.8776 - val_loss: 0.3567 - val_accuracy: 0.8747\n",
            "Epoch 566/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3239 - accuracy: 0.8815 - val_loss: 0.3603 - val_accuracy: 0.8748\n",
            "Epoch 567/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3349 - accuracy: 0.8773 - val_loss: 0.3568 - val_accuracy: 0.8722\n",
            "Epoch 568/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3291 - accuracy: 0.8847 - val_loss: 0.3589 - val_accuracy: 0.8753\n",
            "Epoch 569/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3319 - accuracy: 0.8801 - val_loss: 0.3598 - val_accuracy: 0.8725\n",
            "Epoch 570/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3332 - accuracy: 0.8770 - val_loss: 0.3620 - val_accuracy: 0.8741\n",
            "Epoch 571/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3321 - accuracy: 0.8795 - val_loss: 0.3626 - val_accuracy: 0.8711\n",
            "Epoch 572/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3310 - accuracy: 0.8801 - val_loss: 0.3589 - val_accuracy: 0.8742\n",
            "Epoch 573/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3332 - accuracy: 0.8818 - val_loss: 0.3611 - val_accuracy: 0.8764\n",
            "Epoch 574/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3220 - accuracy: 0.8817 - val_loss: 0.3596 - val_accuracy: 0.8752\n",
            "Epoch 575/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3297 - accuracy: 0.8792 - val_loss: 0.3588 - val_accuracy: 0.8753\n",
            "Epoch 576/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3298 - accuracy: 0.8772 - val_loss: 0.3617 - val_accuracy: 0.8730\n",
            "Epoch 577/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3393 - accuracy: 0.8788 - val_loss: 0.3606 - val_accuracy: 0.8709\n",
            "Epoch 578/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3297 - accuracy: 0.8808 - val_loss: 0.3628 - val_accuracy: 0.8770\n",
            "Epoch 579/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3323 - accuracy: 0.8791 - val_loss: 0.3593 - val_accuracy: 0.8730\n",
            "Epoch 580/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3294 - accuracy: 0.8840 - val_loss: 0.3597 - val_accuracy: 0.8747\n",
            "Epoch 581/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3332 - accuracy: 0.8763 - val_loss: 0.3576 - val_accuracy: 0.8777\n",
            "Epoch 582/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3266 - accuracy: 0.8777 - val_loss: 0.3547 - val_accuracy: 0.8773\n",
            "Epoch 583/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3285 - accuracy: 0.8834 - val_loss: 0.3596 - val_accuracy: 0.8727\n",
            "Epoch 584/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3221 - accuracy: 0.8832 - val_loss: 0.3592 - val_accuracy: 0.8761\n",
            "Epoch 585/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3280 - accuracy: 0.8812 - val_loss: 0.3638 - val_accuracy: 0.8730\n",
            "Epoch 586/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3285 - accuracy: 0.8815 - val_loss: 0.3601 - val_accuracy: 0.8722\n",
            "Epoch 587/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3315 - accuracy: 0.8774 - val_loss: 0.3551 - val_accuracy: 0.8764\n",
            "Epoch 588/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3234 - accuracy: 0.8827 - val_loss: 0.3564 - val_accuracy: 0.8778\n",
            "Epoch 589/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3206 - accuracy: 0.8833 - val_loss: 0.3600 - val_accuracy: 0.8764\n",
            "Epoch 590/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3287 - accuracy: 0.8812 - val_loss: 0.3581 - val_accuracy: 0.8759\n",
            "Epoch 591/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3286 - accuracy: 0.8796 - val_loss: 0.3631 - val_accuracy: 0.8727\n",
            "Epoch 592/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3308 - accuracy: 0.8816 - val_loss: 0.3604 - val_accuracy: 0.8769\n",
            "Epoch 593/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3237 - accuracy: 0.8820 - val_loss: 0.3596 - val_accuracy: 0.8741\n",
            "Epoch 594/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3325 - accuracy: 0.8783 - val_loss: 0.3584 - val_accuracy: 0.8763\n",
            "Epoch 595/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3353 - accuracy: 0.8779 - val_loss: 0.3605 - val_accuracy: 0.8764\n",
            "Epoch 596/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3251 - accuracy: 0.8814 - val_loss: 0.3611 - val_accuracy: 0.8752\n",
            "Epoch 597/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3276 - accuracy: 0.8805 - val_loss: 0.3602 - val_accuracy: 0.8742\n",
            "Epoch 598/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3276 - accuracy: 0.8812 - val_loss: 0.3580 - val_accuracy: 0.8759\n",
            "Epoch 599/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3286 - accuracy: 0.8814 - val_loss: 0.3635 - val_accuracy: 0.8717\n",
            "Epoch 600/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3318 - accuracy: 0.8789 - val_loss: 0.3584 - val_accuracy: 0.8737\n",
            "Epoch 601/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3268 - accuracy: 0.8827 - val_loss: 0.3564 - val_accuracy: 0.8778\n",
            "Epoch 602/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3245 - accuracy: 0.8830 - val_loss: 0.3571 - val_accuracy: 0.8766\n",
            "Epoch 603/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3267 - accuracy: 0.8816 - val_loss: 0.3584 - val_accuracy: 0.8741\n",
            "Epoch 604/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3298 - accuracy: 0.8806 - val_loss: 0.3553 - val_accuracy: 0.8769\n",
            "Epoch 605/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3277 - accuracy: 0.8813 - val_loss: 0.3547 - val_accuracy: 0.8755\n",
            "Epoch 606/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3233 - accuracy: 0.8860 - val_loss: 0.3633 - val_accuracy: 0.8763\n",
            "Epoch 607/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3310 - accuracy: 0.8763 - val_loss: 0.3570 - val_accuracy: 0.8733\n",
            "Epoch 608/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3302 - accuracy: 0.8805 - val_loss: 0.3553 - val_accuracy: 0.8773\n",
            "Epoch 609/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3293 - accuracy: 0.8820 - val_loss: 0.3598 - val_accuracy: 0.8742\n",
            "Epoch 610/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3180 - accuracy: 0.8841 - val_loss: 0.3565 - val_accuracy: 0.8764\n",
            "Epoch 611/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3252 - accuracy: 0.8819 - val_loss: 0.3589 - val_accuracy: 0.8756\n",
            "Epoch 612/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3294 - accuracy: 0.8804 - val_loss: 0.3647 - val_accuracy: 0.8727\n",
            "Epoch 613/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3242 - accuracy: 0.8849 - val_loss: 0.3698 - val_accuracy: 0.8730\n",
            "Epoch 614/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3348 - accuracy: 0.8790 - val_loss: 0.3584 - val_accuracy: 0.8764\n",
            "Epoch 615/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3281 - accuracy: 0.8818 - val_loss: 0.3565 - val_accuracy: 0.8759\n",
            "Epoch 616/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3193 - accuracy: 0.8861 - val_loss: 0.3546 - val_accuracy: 0.8761\n",
            "Epoch 617/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3283 - accuracy: 0.8793 - val_loss: 0.3609 - val_accuracy: 0.8753\n",
            "Epoch 618/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3279 - accuracy: 0.8815 - val_loss: 0.3532 - val_accuracy: 0.8777\n",
            "Epoch 619/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3321 - accuracy: 0.8776 - val_loss: 0.3653 - val_accuracy: 0.8728\n",
            "Epoch 620/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3246 - accuracy: 0.8863 - val_loss: 0.3645 - val_accuracy: 0.8736\n",
            "Epoch 621/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3363 - accuracy: 0.8748 - val_loss: 0.3568 - val_accuracy: 0.8770\n",
            "Epoch 622/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3231 - accuracy: 0.8830 - val_loss: 0.3624 - val_accuracy: 0.8767\n",
            "Epoch 623/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3316 - accuracy: 0.8780 - val_loss: 0.3597 - val_accuracy: 0.8763\n",
            "Epoch 624/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3250 - accuracy: 0.8789 - val_loss: 0.3613 - val_accuracy: 0.8706\n",
            "Epoch 625/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3251 - accuracy: 0.8820 - val_loss: 0.3572 - val_accuracy: 0.8780\n",
            "Epoch 626/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3270 - accuracy: 0.8800 - val_loss: 0.3639 - val_accuracy: 0.8763\n",
            "Epoch 627/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3224 - accuracy: 0.8812 - val_loss: 0.3676 - val_accuracy: 0.8741\n",
            "Epoch 628/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3308 - accuracy: 0.8801 - val_loss: 0.3610 - val_accuracy: 0.8764\n",
            "Epoch 629/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3308 - accuracy: 0.8802 - val_loss: 0.3598 - val_accuracy: 0.8761\n",
            "Epoch 630/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3211 - accuracy: 0.8845 - val_loss: 0.3586 - val_accuracy: 0.8714\n",
            "Epoch 631/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3240 - accuracy: 0.8817 - val_loss: 0.3611 - val_accuracy: 0.8722\n",
            "Epoch 632/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3200 - accuracy: 0.8843 - val_loss: 0.3581 - val_accuracy: 0.8736\n",
            "Epoch 633/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3269 - accuracy: 0.8791 - val_loss: 0.3595 - val_accuracy: 0.8761\n",
            "Epoch 634/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3224 - accuracy: 0.8827 - val_loss: 0.3601 - val_accuracy: 0.8761\n",
            "Epoch 635/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3288 - accuracy: 0.8825 - val_loss: 0.3615 - val_accuracy: 0.8727\n",
            "Epoch 636/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3173 - accuracy: 0.8863 - val_loss: 0.3566 - val_accuracy: 0.8783\n",
            "Epoch 637/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3298 - accuracy: 0.8798 - val_loss: 0.3612 - val_accuracy: 0.8769\n",
            "Epoch 638/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3233 - accuracy: 0.8811 - val_loss: 0.3600 - val_accuracy: 0.8753\n",
            "Epoch 639/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3168 - accuracy: 0.8849 - val_loss: 0.3586 - val_accuracy: 0.8791\n",
            "Epoch 640/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3245 - accuracy: 0.8786 - val_loss: 0.3598 - val_accuracy: 0.8755\n",
            "Epoch 641/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3298 - accuracy: 0.8830 - val_loss: 0.3590 - val_accuracy: 0.8753\n",
            "Epoch 642/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3219 - accuracy: 0.8820 - val_loss: 0.3609 - val_accuracy: 0.8741\n",
            "Epoch 643/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3268 - accuracy: 0.8832 - val_loss: 0.3565 - val_accuracy: 0.8748\n",
            "Epoch 644/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3203 - accuracy: 0.8827 - val_loss: 0.3576 - val_accuracy: 0.8708\n",
            "Epoch 645/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3256 - accuracy: 0.8822 - val_loss: 0.3657 - val_accuracy: 0.8723\n",
            "Epoch 646/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3254 - accuracy: 0.8841 - val_loss: 0.3552 - val_accuracy: 0.8763\n",
            "Epoch 647/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3256 - accuracy: 0.8811 - val_loss: 0.3565 - val_accuracy: 0.8736\n",
            "Epoch 648/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3257 - accuracy: 0.8852 - val_loss: 0.3580 - val_accuracy: 0.8769\n",
            "Epoch 649/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3212 - accuracy: 0.8827 - val_loss: 0.3657 - val_accuracy: 0.8720\n",
            "Epoch 650/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3149 - accuracy: 0.8840 - val_loss: 0.3593 - val_accuracy: 0.8736\n",
            "Epoch 651/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3293 - accuracy: 0.8810 - val_loss: 0.3551 - val_accuracy: 0.8748\n",
            "Epoch 652/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3211 - accuracy: 0.8842 - val_loss: 0.3606 - val_accuracy: 0.8756\n",
            "Epoch 653/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3206 - accuracy: 0.8852 - val_loss: 0.3651 - val_accuracy: 0.8759\n",
            "Epoch 654/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3181 - accuracy: 0.8799 - val_loss: 0.3655 - val_accuracy: 0.8708\n",
            "Epoch 655/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3205 - accuracy: 0.8845 - val_loss: 0.3588 - val_accuracy: 0.8769\n",
            "Epoch 656/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3315 - accuracy: 0.8795 - val_loss: 0.3652 - val_accuracy: 0.8731\n",
            "Epoch 657/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3274 - accuracy: 0.8823 - val_loss: 0.3599 - val_accuracy: 0.8736\n",
            "Epoch 658/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3250 - accuracy: 0.8815 - val_loss: 0.3560 - val_accuracy: 0.8741\n",
            "Epoch 659/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3205 - accuracy: 0.8810 - val_loss: 0.3560 - val_accuracy: 0.8758\n",
            "Epoch 660/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3179 - accuracy: 0.8864 - val_loss: 0.3571 - val_accuracy: 0.8736\n",
            "Epoch 661/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3247 - accuracy: 0.8817 - val_loss: 0.3586 - val_accuracy: 0.8709\n",
            "Epoch 662/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3267 - accuracy: 0.8840 - val_loss: 0.3586 - val_accuracy: 0.8750\n",
            "Epoch 663/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3256 - accuracy: 0.8788 - val_loss: 0.3566 - val_accuracy: 0.8769\n",
            "Epoch 664/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3230 - accuracy: 0.8831 - val_loss: 0.3565 - val_accuracy: 0.8778\n",
            "Epoch 665/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3324 - accuracy: 0.8798 - val_loss: 0.3605 - val_accuracy: 0.8714\n",
            "Epoch 666/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3215 - accuracy: 0.8846 - val_loss: 0.3627 - val_accuracy: 0.8750\n",
            "Epoch 667/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3275 - accuracy: 0.8827 - val_loss: 0.3574 - val_accuracy: 0.8767\n",
            "Epoch 668/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3212 - accuracy: 0.8809 - val_loss: 0.3580 - val_accuracy: 0.8753\n",
            "Epoch 669/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3129 - accuracy: 0.8863 - val_loss: 0.3567 - val_accuracy: 0.8758\n",
            "Epoch 670/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3266 - accuracy: 0.8812 - val_loss: 0.3597 - val_accuracy: 0.8752\n",
            "Epoch 671/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3203 - accuracy: 0.8819 - val_loss: 0.3586 - val_accuracy: 0.8773\n",
            "Epoch 672/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3178 - accuracy: 0.8868 - val_loss: 0.3607 - val_accuracy: 0.8736\n",
            "Epoch 673/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3227 - accuracy: 0.8825 - val_loss: 0.3588 - val_accuracy: 0.8780\n",
            "Epoch 674/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3169 - accuracy: 0.8848 - val_loss: 0.3593 - val_accuracy: 0.8728\n",
            "Epoch 675/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3260 - accuracy: 0.8815 - val_loss: 0.3554 - val_accuracy: 0.8781\n",
            "Epoch 676/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3213 - accuracy: 0.8863 - val_loss: 0.3622 - val_accuracy: 0.8770\n",
            "Epoch 677/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3173 - accuracy: 0.8816 - val_loss: 0.3619 - val_accuracy: 0.8758\n",
            "Epoch 678/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3232 - accuracy: 0.8822 - val_loss: 0.3590 - val_accuracy: 0.8756\n",
            "Epoch 679/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3236 - accuracy: 0.8844 - val_loss: 0.3577 - val_accuracy: 0.8747\n",
            "Epoch 680/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3276 - accuracy: 0.8830 - val_loss: 0.3569 - val_accuracy: 0.8763\n",
            "Epoch 681/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3219 - accuracy: 0.8849 - val_loss: 0.3603 - val_accuracy: 0.8788\n",
            "Epoch 682/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3201 - accuracy: 0.8828 - val_loss: 0.3598 - val_accuracy: 0.8789\n",
            "Epoch 683/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3205 - accuracy: 0.8812 - val_loss: 0.3568 - val_accuracy: 0.8756\n",
            "Epoch 684/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3279 - accuracy: 0.8826 - val_loss: 0.3597 - val_accuracy: 0.8759\n",
            "Epoch 685/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3130 - accuracy: 0.8848 - val_loss: 0.3621 - val_accuracy: 0.8769\n",
            "Epoch 686/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3188 - accuracy: 0.8851 - val_loss: 0.3616 - val_accuracy: 0.8752\n",
            "Epoch 687/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3177 - accuracy: 0.8814 - val_loss: 0.3702 - val_accuracy: 0.8716\n",
            "Epoch 688/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3191 - accuracy: 0.8868 - val_loss: 0.3673 - val_accuracy: 0.8695\n",
            "Epoch 689/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3187 - accuracy: 0.8852 - val_loss: 0.3629 - val_accuracy: 0.8747\n",
            "Epoch 690/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3249 - accuracy: 0.8808 - val_loss: 0.3594 - val_accuracy: 0.8773\n",
            "Epoch 691/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3153 - accuracy: 0.8848 - val_loss: 0.3610 - val_accuracy: 0.8763\n",
            "Epoch 692/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3204 - accuracy: 0.8852 - val_loss: 0.3647 - val_accuracy: 0.8714\n",
            "Epoch 693/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3220 - accuracy: 0.8846 - val_loss: 0.3592 - val_accuracy: 0.8761\n",
            "Epoch 694/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3211 - accuracy: 0.8845 - val_loss: 0.3619 - val_accuracy: 0.8723\n",
            "Epoch 695/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3218 - accuracy: 0.8859 - val_loss: 0.3611 - val_accuracy: 0.8761\n",
            "Epoch 696/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3217 - accuracy: 0.8827 - val_loss: 0.3601 - val_accuracy: 0.8763\n",
            "Epoch 697/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3158 - accuracy: 0.8855 - val_loss: 0.3588 - val_accuracy: 0.8769\n",
            "Epoch 698/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3217 - accuracy: 0.8823 - val_loss: 0.3594 - val_accuracy: 0.8763\n",
            "Epoch 699/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3225 - accuracy: 0.8836 - val_loss: 0.3565 - val_accuracy: 0.8769\n",
            "Epoch 700/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3124 - accuracy: 0.8886 - val_loss: 0.3622 - val_accuracy: 0.8756\n",
            "Epoch 701/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3198 - accuracy: 0.8834 - val_loss: 0.3595 - val_accuracy: 0.8770\n",
            "Epoch 702/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3183 - accuracy: 0.8834 - val_loss: 0.3688 - val_accuracy: 0.8748\n",
            "Epoch 703/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3274 - accuracy: 0.8834 - val_loss: 0.3584 - val_accuracy: 0.8761\n",
            "Epoch 704/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3182 - accuracy: 0.8834 - val_loss: 0.3586 - val_accuracy: 0.8773\n",
            "Epoch 705/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3243 - accuracy: 0.8811 - val_loss: 0.3578 - val_accuracy: 0.8781\n",
            "Epoch 706/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3193 - accuracy: 0.8842 - val_loss: 0.3575 - val_accuracy: 0.8750\n",
            "Epoch 707/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3189 - accuracy: 0.8840 - val_loss: 0.3620 - val_accuracy: 0.8722\n",
            "Epoch 708/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3235 - accuracy: 0.8807 - val_loss: 0.3667 - val_accuracy: 0.8733\n",
            "Epoch 709/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3160 - accuracy: 0.8848 - val_loss: 0.3600 - val_accuracy: 0.8766\n",
            "Epoch 710/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3140 - accuracy: 0.8863 - val_loss: 0.3621 - val_accuracy: 0.8761\n",
            "Epoch 711/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3203 - accuracy: 0.8833 - val_loss: 0.3594 - val_accuracy: 0.8758\n",
            "Epoch 712/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3199 - accuracy: 0.8848 - val_loss: 0.3573 - val_accuracy: 0.8777\n",
            "Epoch 713/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3238 - accuracy: 0.8799 - val_loss: 0.3565 - val_accuracy: 0.8794\n",
            "Epoch 714/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3137 - accuracy: 0.8868 - val_loss: 0.3575 - val_accuracy: 0.8772\n",
            "Epoch 715/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3181 - accuracy: 0.8854 - val_loss: 0.3619 - val_accuracy: 0.8756\n",
            "Epoch 716/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3160 - accuracy: 0.8835 - val_loss: 0.3709 - val_accuracy: 0.8722\n",
            "Epoch 717/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3243 - accuracy: 0.8819 - val_loss: 0.3607 - val_accuracy: 0.8761\n",
            "Epoch 718/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3229 - accuracy: 0.8834 - val_loss: 0.3599 - val_accuracy: 0.8769\n",
            "Epoch 719/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3165 - accuracy: 0.8847 - val_loss: 0.3543 - val_accuracy: 0.8763\n",
            "Epoch 720/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3147 - accuracy: 0.8834 - val_loss: 0.3594 - val_accuracy: 0.8789\n",
            "Epoch 721/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3163 - accuracy: 0.8860 - val_loss: 0.3542 - val_accuracy: 0.8748\n",
            "Epoch 722/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3264 - accuracy: 0.8801 - val_loss: 0.3584 - val_accuracy: 0.8753\n",
            "Epoch 723/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3132 - accuracy: 0.8881 - val_loss: 0.3616 - val_accuracy: 0.8763\n",
            "Epoch 724/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3191 - accuracy: 0.8837 - val_loss: 0.3600 - val_accuracy: 0.8753\n",
            "Epoch 725/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3053 - accuracy: 0.8911 - val_loss: 0.3621 - val_accuracy: 0.8783\n",
            "Epoch 726/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3220 - accuracy: 0.8833 - val_loss: 0.3608 - val_accuracy: 0.8772\n",
            "Epoch 727/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3171 - accuracy: 0.8841 - val_loss: 0.3628 - val_accuracy: 0.8728\n",
            "Epoch 728/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3128 - accuracy: 0.8869 - val_loss: 0.3588 - val_accuracy: 0.8783\n",
            "Epoch 729/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3245 - accuracy: 0.8838 - val_loss: 0.3585 - val_accuracy: 0.8767\n",
            "Epoch 730/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3118 - accuracy: 0.8896 - val_loss: 0.3647 - val_accuracy: 0.8747\n",
            "Epoch 731/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3199 - accuracy: 0.8847 - val_loss: 0.3620 - val_accuracy: 0.8745\n",
            "Epoch 732/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3198 - accuracy: 0.8860 - val_loss: 0.3551 - val_accuracy: 0.8784\n",
            "Epoch 733/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3104 - accuracy: 0.8902 - val_loss: 0.3553 - val_accuracy: 0.8763\n",
            "Epoch 734/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3166 - accuracy: 0.8840 - val_loss: 0.3627 - val_accuracy: 0.8753\n",
            "Epoch 735/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3182 - accuracy: 0.8851 - val_loss: 0.3550 - val_accuracy: 0.8758\n",
            "Epoch 736/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3148 - accuracy: 0.8860 - val_loss: 0.3615 - val_accuracy: 0.8753\n",
            "Epoch 737/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3144 - accuracy: 0.8877 - val_loss: 0.3585 - val_accuracy: 0.8770\n",
            "Epoch 738/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3106 - accuracy: 0.8855 - val_loss: 0.3605 - val_accuracy: 0.8758\n",
            "Epoch 739/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3124 - accuracy: 0.8856 - val_loss: 0.3579 - val_accuracy: 0.8767\n",
            "Epoch 740/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3183 - accuracy: 0.8820 - val_loss: 0.3610 - val_accuracy: 0.8795\n",
            "Epoch 741/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3105 - accuracy: 0.8850 - val_loss: 0.3653 - val_accuracy: 0.8758\n",
            "Epoch 742/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3128 - accuracy: 0.8884 - val_loss: 0.3622 - val_accuracy: 0.8753\n",
            "Epoch 743/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3137 - accuracy: 0.8830 - val_loss: 0.3621 - val_accuracy: 0.8756\n",
            "Epoch 744/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3106 - accuracy: 0.8879 - val_loss: 0.3653 - val_accuracy: 0.8758\n",
            "Epoch 745/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3228 - accuracy: 0.8810 - val_loss: 0.3638 - val_accuracy: 0.8737\n",
            "Epoch 746/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3155 - accuracy: 0.8857 - val_loss: 0.3587 - val_accuracy: 0.8748\n",
            "Epoch 747/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3103 - accuracy: 0.8889 - val_loss: 0.3627 - val_accuracy: 0.8750\n",
            "Epoch 748/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3162 - accuracy: 0.8845 - val_loss: 0.3661 - val_accuracy: 0.8747\n",
            "Epoch 749/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3091 - accuracy: 0.8870 - val_loss: 0.3577 - val_accuracy: 0.8758\n",
            "Epoch 750/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3249 - accuracy: 0.8817 - val_loss: 0.3601 - val_accuracy: 0.8730\n",
            "Epoch 751/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3211 - accuracy: 0.8829 - val_loss: 0.3590 - val_accuracy: 0.8769\n",
            "Epoch 752/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3154 - accuracy: 0.8860 - val_loss: 0.3623 - val_accuracy: 0.8756\n",
            "Epoch 753/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3138 - accuracy: 0.8891 - val_loss: 0.3605 - val_accuracy: 0.8775\n",
            "Epoch 754/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3200 - accuracy: 0.8828 - val_loss: 0.3580 - val_accuracy: 0.8739\n",
            "Epoch 755/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3105 - accuracy: 0.8877 - val_loss: 0.3654 - val_accuracy: 0.8745\n",
            "Epoch 756/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3122 - accuracy: 0.8862 - val_loss: 0.3584 - val_accuracy: 0.8777\n",
            "Epoch 757/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3166 - accuracy: 0.8863 - val_loss: 0.3621 - val_accuracy: 0.8731\n",
            "Epoch 758/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3101 - accuracy: 0.8874 - val_loss: 0.3621 - val_accuracy: 0.8763\n",
            "Epoch 759/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3183 - accuracy: 0.8843 - val_loss: 0.3564 - val_accuracy: 0.8777\n",
            "Epoch 760/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3138 - accuracy: 0.8885 - val_loss: 0.3579 - val_accuracy: 0.8784\n",
            "Epoch 761/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3164 - accuracy: 0.8884 - val_loss: 0.3558 - val_accuracy: 0.8758\n",
            "Epoch 762/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3116 - accuracy: 0.8848 - val_loss: 0.3591 - val_accuracy: 0.8755\n",
            "Epoch 763/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3184 - accuracy: 0.8841 - val_loss: 0.3530 - val_accuracy: 0.8777\n",
            "Epoch 764/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3260 - accuracy: 0.8827 - val_loss: 0.3548 - val_accuracy: 0.8752\n",
            "Epoch 765/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3135 - accuracy: 0.8903 - val_loss: 0.3591 - val_accuracy: 0.8759\n",
            "Epoch 766/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3177 - accuracy: 0.8841 - val_loss: 0.3647 - val_accuracy: 0.8741\n",
            "Epoch 767/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3070 - accuracy: 0.8866 - val_loss: 0.3561 - val_accuracy: 0.8777\n",
            "Epoch 768/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3220 - accuracy: 0.8873 - val_loss: 0.3556 - val_accuracy: 0.8755\n",
            "Epoch 769/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3146 - accuracy: 0.8867 - val_loss: 0.3635 - val_accuracy: 0.8741\n",
            "Epoch 770/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3086 - accuracy: 0.8859 - val_loss: 0.3619 - val_accuracy: 0.8778\n",
            "Epoch 771/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3131 - accuracy: 0.8865 - val_loss: 0.3637 - val_accuracy: 0.8769\n",
            "Epoch 772/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3160 - accuracy: 0.8848 - val_loss: 0.3564 - val_accuracy: 0.8778\n",
            "Epoch 773/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3244 - accuracy: 0.8806 - val_loss: 0.3561 - val_accuracy: 0.8781\n",
            "Epoch 774/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3145 - accuracy: 0.8866 - val_loss: 0.3581 - val_accuracy: 0.8756\n",
            "Epoch 775/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3099 - accuracy: 0.8876 - val_loss: 0.3566 - val_accuracy: 0.8755\n",
            "Epoch 776/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3124 - accuracy: 0.8852 - val_loss: 0.3577 - val_accuracy: 0.8753\n",
            "Epoch 777/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3115 - accuracy: 0.8886 - val_loss: 0.3558 - val_accuracy: 0.8753\n",
            "Epoch 778/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3212 - accuracy: 0.8826 - val_loss: 0.3549 - val_accuracy: 0.8742\n",
            "Epoch 779/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3106 - accuracy: 0.8874 - val_loss: 0.3618 - val_accuracy: 0.8769\n",
            "Epoch 780/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3140 - accuracy: 0.8845 - val_loss: 0.3592 - val_accuracy: 0.8761\n",
            "Epoch 781/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3181 - accuracy: 0.8826 - val_loss: 0.3584 - val_accuracy: 0.8772\n",
            "Epoch 782/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3213 - accuracy: 0.8828 - val_loss: 0.3567 - val_accuracy: 0.8750\n",
            "Epoch 783/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3135 - accuracy: 0.8832 - val_loss: 0.3612 - val_accuracy: 0.8741\n",
            "Epoch 784/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3170 - accuracy: 0.8843 - val_loss: 0.3629 - val_accuracy: 0.8769\n",
            "Epoch 785/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3159 - accuracy: 0.8834 - val_loss: 0.3568 - val_accuracy: 0.8784\n",
            "Epoch 786/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3186 - accuracy: 0.8860 - val_loss: 0.3555 - val_accuracy: 0.8788\n",
            "Epoch 787/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3166 - accuracy: 0.8834 - val_loss: 0.3581 - val_accuracy: 0.8777\n",
            "Epoch 788/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3094 - accuracy: 0.8853 - val_loss: 0.3616 - val_accuracy: 0.8788\n",
            "Epoch 789/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3138 - accuracy: 0.8877 - val_loss: 0.3583 - val_accuracy: 0.8766\n",
            "Epoch 790/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3167 - accuracy: 0.8820 - val_loss: 0.3632 - val_accuracy: 0.8741\n",
            "Epoch 791/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3094 - accuracy: 0.8872 - val_loss: 0.3600 - val_accuracy: 0.8764\n",
            "Epoch 792/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3071 - accuracy: 0.8880 - val_loss: 0.3578 - val_accuracy: 0.8764\n",
            "Epoch 793/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3098 - accuracy: 0.8872 - val_loss: 0.3602 - val_accuracy: 0.8789\n",
            "Epoch 794/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3084 - accuracy: 0.8895 - val_loss: 0.3594 - val_accuracy: 0.8794\n",
            "Epoch 795/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3133 - accuracy: 0.8871 - val_loss: 0.3632 - val_accuracy: 0.8767\n",
            "Epoch 796/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3119 - accuracy: 0.8855 - val_loss: 0.3597 - val_accuracy: 0.8772\n",
            "Epoch 797/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3140 - accuracy: 0.8860 - val_loss: 0.3623 - val_accuracy: 0.8747\n",
            "Epoch 798/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3071 - accuracy: 0.8905 - val_loss: 0.3636 - val_accuracy: 0.8784\n",
            "Epoch 799/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3115 - accuracy: 0.8852 - val_loss: 0.3600 - val_accuracy: 0.8761\n",
            "Epoch 800/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3123 - accuracy: 0.8911 - val_loss: 0.3566 - val_accuracy: 0.8764\n",
            "Epoch 801/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3095 - accuracy: 0.8851 - val_loss: 0.3610 - val_accuracy: 0.8747\n",
            "Epoch 802/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3169 - accuracy: 0.8849 - val_loss: 0.3584 - val_accuracy: 0.8792\n",
            "Epoch 803/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3146 - accuracy: 0.8876 - val_loss: 0.3598 - val_accuracy: 0.8778\n",
            "Epoch 804/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3164 - accuracy: 0.8845 - val_loss: 0.3573 - val_accuracy: 0.8775\n",
            "Epoch 805/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3124 - accuracy: 0.8838 - val_loss: 0.3622 - val_accuracy: 0.8753\n",
            "Epoch 806/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3174 - accuracy: 0.8866 - val_loss: 0.3598 - val_accuracy: 0.8778\n",
            "Epoch 807/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3117 - accuracy: 0.8881 - val_loss: 0.3609 - val_accuracy: 0.8788\n",
            "Epoch 808/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3040 - accuracy: 0.8870 - val_loss: 0.3593 - val_accuracy: 0.8788\n",
            "Epoch 809/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3085 - accuracy: 0.8877 - val_loss: 0.3640 - val_accuracy: 0.8773\n",
            "Epoch 810/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3185 - accuracy: 0.8810 - val_loss: 0.3601 - val_accuracy: 0.8744\n",
            "Epoch 811/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3133 - accuracy: 0.8861 - val_loss: 0.3629 - val_accuracy: 0.8733\n",
            "Epoch 812/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3120 - accuracy: 0.8891 - val_loss: 0.3625 - val_accuracy: 0.8808\n",
            "Epoch 813/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3122 - accuracy: 0.8845 - val_loss: 0.3592 - val_accuracy: 0.8802\n",
            "Epoch 814/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3084 - accuracy: 0.8888 - val_loss: 0.3621 - val_accuracy: 0.8781\n",
            "Epoch 815/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3159 - accuracy: 0.8816 - val_loss: 0.3633 - val_accuracy: 0.8788\n",
            "Epoch 816/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3122 - accuracy: 0.8856 - val_loss: 0.3569 - val_accuracy: 0.8791\n",
            "Epoch 817/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3061 - accuracy: 0.8857 - val_loss: 0.3583 - val_accuracy: 0.8777\n",
            "Epoch 818/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3112 - accuracy: 0.8843 - val_loss: 0.3620 - val_accuracy: 0.8784\n",
            "Epoch 819/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3054 - accuracy: 0.8891 - val_loss: 0.3656 - val_accuracy: 0.8758\n",
            "Epoch 820/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3103 - accuracy: 0.8879 - val_loss: 0.3681 - val_accuracy: 0.8783\n",
            "Epoch 821/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3135 - accuracy: 0.8828 - val_loss: 0.3577 - val_accuracy: 0.8794\n",
            "Epoch 822/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3015 - accuracy: 0.8912 - val_loss: 0.3644 - val_accuracy: 0.8755\n",
            "Epoch 823/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3119 - accuracy: 0.8831 - val_loss: 0.3604 - val_accuracy: 0.8809\n",
            "Epoch 824/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3147 - accuracy: 0.8883 - val_loss: 0.3576 - val_accuracy: 0.8755\n",
            "Epoch 825/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3053 - accuracy: 0.8895 - val_loss: 0.3698 - val_accuracy: 0.8728\n",
            "Epoch 826/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3076 - accuracy: 0.8908 - val_loss: 0.3658 - val_accuracy: 0.8772\n",
            "Epoch 827/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3150 - accuracy: 0.8859 - val_loss: 0.3600 - val_accuracy: 0.8775\n",
            "Epoch 828/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3127 - accuracy: 0.8872 - val_loss: 0.3617 - val_accuracy: 0.8805\n",
            "Epoch 829/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3086 - accuracy: 0.8869 - val_loss: 0.3625 - val_accuracy: 0.8769\n",
            "Epoch 830/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3194 - accuracy: 0.8855 - val_loss: 0.3621 - val_accuracy: 0.8789\n",
            "Epoch 831/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3081 - accuracy: 0.8901 - val_loss: 0.3672 - val_accuracy: 0.8759\n",
            "Epoch 832/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3123 - accuracy: 0.8852 - val_loss: 0.3606 - val_accuracy: 0.8773\n",
            "Epoch 833/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3045 - accuracy: 0.8899 - val_loss: 0.3711 - val_accuracy: 0.8753\n",
            "Epoch 834/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3153 - accuracy: 0.8860 - val_loss: 0.3645 - val_accuracy: 0.8755\n",
            "Epoch 835/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3139 - accuracy: 0.8864 - val_loss: 0.3557 - val_accuracy: 0.8791\n",
            "Epoch 836/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2981 - accuracy: 0.8915 - val_loss: 0.3558 - val_accuracy: 0.8772\n",
            "Epoch 837/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3088 - accuracy: 0.8884 - val_loss: 0.3603 - val_accuracy: 0.8766\n",
            "Epoch 838/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3083 - accuracy: 0.8877 - val_loss: 0.3535 - val_accuracy: 0.8769\n",
            "Epoch 839/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3126 - accuracy: 0.8852 - val_loss: 0.3601 - val_accuracy: 0.8764\n",
            "Epoch 840/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3096 - accuracy: 0.8873 - val_loss: 0.3702 - val_accuracy: 0.8773\n",
            "Epoch 841/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3123 - accuracy: 0.8855 - val_loss: 0.3605 - val_accuracy: 0.8783\n",
            "Epoch 842/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3105 - accuracy: 0.8872 - val_loss: 0.3605 - val_accuracy: 0.8800\n",
            "Epoch 843/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3161 - accuracy: 0.8846 - val_loss: 0.3574 - val_accuracy: 0.8753\n",
            "Epoch 844/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3057 - accuracy: 0.8907 - val_loss: 0.3573 - val_accuracy: 0.8772\n",
            "Epoch 845/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3014 - accuracy: 0.8865 - val_loss: 0.3608 - val_accuracy: 0.8794\n",
            "Epoch 846/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3227 - accuracy: 0.8796 - val_loss: 0.3639 - val_accuracy: 0.8756\n",
            "Epoch 847/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3067 - accuracy: 0.8870 - val_loss: 0.3671 - val_accuracy: 0.8761\n",
            "Epoch 848/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3229 - accuracy: 0.8841 - val_loss: 0.3574 - val_accuracy: 0.8770\n",
            "Epoch 849/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3136 - accuracy: 0.8841 - val_loss: 0.3613 - val_accuracy: 0.8783\n",
            "Epoch 850/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2998 - accuracy: 0.8905 - val_loss: 0.3579 - val_accuracy: 0.8778\n",
            "Epoch 851/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3040 - accuracy: 0.8862 - val_loss: 0.3620 - val_accuracy: 0.8767\n",
            "Epoch 852/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3088 - accuracy: 0.8855 - val_loss: 0.3583 - val_accuracy: 0.8772\n",
            "Epoch 853/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3146 - accuracy: 0.8832 - val_loss: 0.3599 - val_accuracy: 0.8770\n",
            "Epoch 854/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3072 - accuracy: 0.8895 - val_loss: 0.3669 - val_accuracy: 0.8773\n",
            "Epoch 855/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3130 - accuracy: 0.8827 - val_loss: 0.3613 - val_accuracy: 0.8781\n",
            "Epoch 856/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3095 - accuracy: 0.8889 - val_loss: 0.3629 - val_accuracy: 0.8803\n",
            "Epoch 857/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3190 - accuracy: 0.8838 - val_loss: 0.3597 - val_accuracy: 0.8798\n",
            "Epoch 858/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3059 - accuracy: 0.8891 - val_loss: 0.3627 - val_accuracy: 0.8750\n",
            "Epoch 859/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3070 - accuracy: 0.8873 - val_loss: 0.3628 - val_accuracy: 0.8777\n",
            "Epoch 860/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3132 - accuracy: 0.8849 - val_loss: 0.3634 - val_accuracy: 0.8750\n",
            "Epoch 861/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3121 - accuracy: 0.8858 - val_loss: 0.3646 - val_accuracy: 0.8761\n",
            "Epoch 862/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3178 - accuracy: 0.8845 - val_loss: 0.3698 - val_accuracy: 0.8759\n",
            "Epoch 863/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3091 - accuracy: 0.8867 - val_loss: 0.3599 - val_accuracy: 0.8797\n",
            "Epoch 864/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3062 - accuracy: 0.8886 - val_loss: 0.3564 - val_accuracy: 0.8748\n",
            "Epoch 865/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3087 - accuracy: 0.8857 - val_loss: 0.3606 - val_accuracy: 0.8770\n",
            "Epoch 866/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2994 - accuracy: 0.8902 - val_loss: 0.3595 - val_accuracy: 0.8745\n",
            "Epoch 867/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3056 - accuracy: 0.8839 - val_loss: 0.3612 - val_accuracy: 0.8769\n",
            "Epoch 868/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3129 - accuracy: 0.8852 - val_loss: 0.3673 - val_accuracy: 0.8742\n",
            "Epoch 869/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3102 - accuracy: 0.8869 - val_loss: 0.3668 - val_accuracy: 0.8748\n",
            "Epoch 870/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3057 - accuracy: 0.8891 - val_loss: 0.3637 - val_accuracy: 0.8797\n",
            "Epoch 871/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3090 - accuracy: 0.8875 - val_loss: 0.3628 - val_accuracy: 0.8773\n",
            "Epoch 872/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3107 - accuracy: 0.8857 - val_loss: 0.3626 - val_accuracy: 0.8766\n",
            "Epoch 873/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3116 - accuracy: 0.8866 - val_loss: 0.3649 - val_accuracy: 0.8770\n",
            "Epoch 874/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3071 - accuracy: 0.8864 - val_loss: 0.3652 - val_accuracy: 0.8752\n",
            "Epoch 875/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3116 - accuracy: 0.8886 - val_loss: 0.3629 - val_accuracy: 0.8780\n",
            "Epoch 876/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3081 - accuracy: 0.8874 - val_loss: 0.3597 - val_accuracy: 0.8769\n",
            "Epoch 877/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3159 - accuracy: 0.8860 - val_loss: 0.3624 - val_accuracy: 0.8778\n",
            "Epoch 878/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3079 - accuracy: 0.8900 - val_loss: 0.3615 - val_accuracy: 0.8711\n",
            "Epoch 879/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3107 - accuracy: 0.8818 - val_loss: 0.3605 - val_accuracy: 0.8792\n",
            "Epoch 880/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2996 - accuracy: 0.8907 - val_loss: 0.3574 - val_accuracy: 0.8789\n",
            "Epoch 881/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3091 - accuracy: 0.8893 - val_loss: 0.3619 - val_accuracy: 0.8761\n",
            "Epoch 882/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3082 - accuracy: 0.8875 - val_loss: 0.3675 - val_accuracy: 0.8761\n",
            "Epoch 883/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3021 - accuracy: 0.8880 - val_loss: 0.3719 - val_accuracy: 0.8717\n",
            "Epoch 884/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3010 - accuracy: 0.8894 - val_loss: 0.3587 - val_accuracy: 0.8803\n",
            "Epoch 885/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3139 - accuracy: 0.8877 - val_loss: 0.3631 - val_accuracy: 0.8764\n",
            "Epoch 886/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3090 - accuracy: 0.8880 - val_loss: 0.3658 - val_accuracy: 0.8755\n",
            "Epoch 887/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3007 - accuracy: 0.8925 - val_loss: 0.3601 - val_accuracy: 0.8780\n",
            "Epoch 888/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3169 - accuracy: 0.8848 - val_loss: 0.3621 - val_accuracy: 0.8763\n",
            "Epoch 889/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3117 - accuracy: 0.8859 - val_loss: 0.3667 - val_accuracy: 0.8763\n",
            "Epoch 890/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3090 - accuracy: 0.8874 - val_loss: 0.3629 - val_accuracy: 0.8763\n",
            "Epoch 891/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3074 - accuracy: 0.8860 - val_loss: 0.3605 - val_accuracy: 0.8786\n",
            "Epoch 892/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3082 - accuracy: 0.8926 - val_loss: 0.3617 - val_accuracy: 0.8767\n",
            "Epoch 893/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3109 - accuracy: 0.8864 - val_loss: 0.3620 - val_accuracy: 0.8745\n",
            "Epoch 894/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3062 - accuracy: 0.8915 - val_loss: 0.3569 - val_accuracy: 0.8761\n",
            "Epoch 895/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3024 - accuracy: 0.8911 - val_loss: 0.3614 - val_accuracy: 0.8744\n",
            "Epoch 896/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3075 - accuracy: 0.8894 - val_loss: 0.3603 - val_accuracy: 0.8781\n",
            "Epoch 897/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2971 - accuracy: 0.8895 - val_loss: 0.3655 - val_accuracy: 0.8767\n",
            "Epoch 898/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2998 - accuracy: 0.8898 - val_loss: 0.3635 - val_accuracy: 0.8761\n",
            "Epoch 899/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3077 - accuracy: 0.8885 - val_loss: 0.3664 - val_accuracy: 0.8733\n",
            "Epoch 900/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3069 - accuracy: 0.8884 - val_loss: 0.3697 - val_accuracy: 0.8742\n",
            "Epoch 901/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3037 - accuracy: 0.8894 - val_loss: 0.3689 - val_accuracy: 0.8775\n",
            "Epoch 902/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3147 - accuracy: 0.8859 - val_loss: 0.3596 - val_accuracy: 0.8775\n",
            "Epoch 903/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3033 - accuracy: 0.8896 - val_loss: 0.3681 - val_accuracy: 0.8764\n",
            "Epoch 904/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3147 - accuracy: 0.8877 - val_loss: 0.3661 - val_accuracy: 0.8761\n",
            "Epoch 905/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3018 - accuracy: 0.8912 - val_loss: 0.3604 - val_accuracy: 0.8780\n",
            "Epoch 906/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3094 - accuracy: 0.8847 - val_loss: 0.3689 - val_accuracy: 0.8766\n",
            "Epoch 907/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3140 - accuracy: 0.8850 - val_loss: 0.3619 - val_accuracy: 0.8784\n",
            "Epoch 908/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3114 - accuracy: 0.8885 - val_loss: 0.3607 - val_accuracy: 0.8789\n",
            "Epoch 909/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3071 - accuracy: 0.8885 - val_loss: 0.3614 - val_accuracy: 0.8769\n",
            "Epoch 910/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3116 - accuracy: 0.8873 - val_loss: 0.3661 - val_accuracy: 0.8753\n",
            "Epoch 911/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3049 - accuracy: 0.8881 - val_loss: 0.3613 - val_accuracy: 0.8789\n",
            "Epoch 912/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3097 - accuracy: 0.8887 - val_loss: 0.3619 - val_accuracy: 0.8783\n",
            "Epoch 913/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3115 - accuracy: 0.8900 - val_loss: 0.3649 - val_accuracy: 0.8747\n",
            "Epoch 914/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3004 - accuracy: 0.8905 - val_loss: 0.3639 - val_accuracy: 0.8759\n",
            "Epoch 915/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3072 - accuracy: 0.8896 - val_loss: 0.3668 - val_accuracy: 0.8788\n",
            "Epoch 916/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3035 - accuracy: 0.8890 - val_loss: 0.3698 - val_accuracy: 0.8756\n",
            "Epoch 917/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3029 - accuracy: 0.8865 - val_loss: 0.3644 - val_accuracy: 0.8772\n",
            "Epoch 918/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3096 - accuracy: 0.8844 - val_loss: 0.3640 - val_accuracy: 0.8758\n",
            "Epoch 919/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2977 - accuracy: 0.8881 - val_loss: 0.3629 - val_accuracy: 0.8794\n",
            "Epoch 920/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2997 - accuracy: 0.8886 - val_loss: 0.3618 - val_accuracy: 0.8775\n",
            "Epoch 921/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3080 - accuracy: 0.8847 - val_loss: 0.3632 - val_accuracy: 0.8784\n",
            "Epoch 922/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3049 - accuracy: 0.8912 - val_loss: 0.3645 - val_accuracy: 0.8755\n",
            "Epoch 923/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3121 - accuracy: 0.8887 - val_loss: 0.3625 - val_accuracy: 0.8767\n",
            "Epoch 924/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3166 - accuracy: 0.8867 - val_loss: 0.3617 - val_accuracy: 0.8797\n",
            "Epoch 925/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3027 - accuracy: 0.8852 - val_loss: 0.3632 - val_accuracy: 0.8792\n",
            "Epoch 926/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3039 - accuracy: 0.8886 - val_loss: 0.3599 - val_accuracy: 0.8808\n",
            "Epoch 927/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3019 - accuracy: 0.8895 - val_loss: 0.3631 - val_accuracy: 0.8748\n",
            "Epoch 928/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3018 - accuracy: 0.8902 - val_loss: 0.3667 - val_accuracy: 0.8755\n",
            "Epoch 929/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3039 - accuracy: 0.8899 - val_loss: 0.3684 - val_accuracy: 0.8750\n",
            "Epoch 930/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3035 - accuracy: 0.8871 - val_loss: 0.3617 - val_accuracy: 0.8797\n",
            "Epoch 931/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3045 - accuracy: 0.8913 - val_loss: 0.3621 - val_accuracy: 0.8781\n",
            "Epoch 932/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3053 - accuracy: 0.8877 - val_loss: 0.3601 - val_accuracy: 0.8795\n",
            "Epoch 933/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3061 - accuracy: 0.8910 - val_loss: 0.3630 - val_accuracy: 0.8758\n",
            "Epoch 934/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2964 - accuracy: 0.8905 - val_loss: 0.3638 - val_accuracy: 0.8783\n",
            "Epoch 935/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3022 - accuracy: 0.8875 - val_loss: 0.3657 - val_accuracy: 0.8773\n",
            "Epoch 936/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3076 - accuracy: 0.8872 - val_loss: 0.3745 - val_accuracy: 0.8745\n",
            "Epoch 937/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3026 - accuracy: 0.8875 - val_loss: 0.3699 - val_accuracy: 0.8764\n",
            "Epoch 938/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3132 - accuracy: 0.8870 - val_loss: 0.3636 - val_accuracy: 0.8767\n",
            "Epoch 939/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3050 - accuracy: 0.8868 - val_loss: 0.3614 - val_accuracy: 0.8786\n",
            "Epoch 940/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3020 - accuracy: 0.8893 - val_loss: 0.3655 - val_accuracy: 0.8758\n",
            "Epoch 941/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3002 - accuracy: 0.8885 - val_loss: 0.3586 - val_accuracy: 0.8777\n",
            "Epoch 942/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3019 - accuracy: 0.8891 - val_loss: 0.3639 - val_accuracy: 0.8756\n",
            "Epoch 943/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2944 - accuracy: 0.8920 - val_loss: 0.3719 - val_accuracy: 0.8772\n",
            "Epoch 944/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3058 - accuracy: 0.8873 - val_loss: 0.3660 - val_accuracy: 0.8798\n",
            "Epoch 945/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3052 - accuracy: 0.8890 - val_loss: 0.3665 - val_accuracy: 0.8794\n",
            "Epoch 946/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3050 - accuracy: 0.8882 - val_loss: 0.3651 - val_accuracy: 0.8778\n",
            "Epoch 947/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2965 - accuracy: 0.8913 - val_loss: 0.3605 - val_accuracy: 0.8809\n",
            "Epoch 948/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3003 - accuracy: 0.8934 - val_loss: 0.3632 - val_accuracy: 0.8798\n",
            "Epoch 949/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3021 - accuracy: 0.8859 - val_loss: 0.3692 - val_accuracy: 0.8770\n",
            "Epoch 950/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2994 - accuracy: 0.8901 - val_loss: 0.3719 - val_accuracy: 0.8759\n",
            "Epoch 951/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3048 - accuracy: 0.8926 - val_loss: 0.3658 - val_accuracy: 0.8766\n",
            "Epoch 952/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2977 - accuracy: 0.8905 - val_loss: 0.3624 - val_accuracy: 0.8788\n",
            "Epoch 953/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2981 - accuracy: 0.8909 - val_loss: 0.3594 - val_accuracy: 0.8783\n",
            "Epoch 954/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3012 - accuracy: 0.8895 - val_loss: 0.3670 - val_accuracy: 0.8744\n",
            "Epoch 955/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3033 - accuracy: 0.8874 - val_loss: 0.3606 - val_accuracy: 0.8777\n",
            "Epoch 956/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3064 - accuracy: 0.8891 - val_loss: 0.3629 - val_accuracy: 0.8756\n",
            "Epoch 957/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3059 - accuracy: 0.8897 - val_loss: 0.3657 - val_accuracy: 0.8784\n",
            "Epoch 958/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3050 - accuracy: 0.8880 - val_loss: 0.3664 - val_accuracy: 0.8758\n",
            "Epoch 959/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2986 - accuracy: 0.8925 - val_loss: 0.3683 - val_accuracy: 0.8794\n",
            "Epoch 960/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3170 - accuracy: 0.8859 - val_loss: 0.3617 - val_accuracy: 0.8780\n",
            "Epoch 961/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2964 - accuracy: 0.8934 - val_loss: 0.3623 - val_accuracy: 0.8780\n",
            "Epoch 962/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2985 - accuracy: 0.8926 - val_loss: 0.3621 - val_accuracy: 0.8800\n",
            "Epoch 963/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3033 - accuracy: 0.8860 - val_loss: 0.3723 - val_accuracy: 0.8766\n",
            "Epoch 964/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3038 - accuracy: 0.8905 - val_loss: 0.3646 - val_accuracy: 0.8764\n",
            "Epoch 965/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3037 - accuracy: 0.8887 - val_loss: 0.3671 - val_accuracy: 0.8791\n",
            "Epoch 966/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3022 - accuracy: 0.8905 - val_loss: 0.3615 - val_accuracy: 0.8773\n",
            "Epoch 967/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2993 - accuracy: 0.8903 - val_loss: 0.3607 - val_accuracy: 0.8775\n",
            "Epoch 968/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3048 - accuracy: 0.8900 - val_loss: 0.3676 - val_accuracy: 0.8772\n",
            "Epoch 969/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3066 - accuracy: 0.8868 - val_loss: 0.3600 - val_accuracy: 0.8767\n",
            "Epoch 970/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3065 - accuracy: 0.8891 - val_loss: 0.3640 - val_accuracy: 0.8756\n",
            "Epoch 971/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3006 - accuracy: 0.8885 - val_loss: 0.3640 - val_accuracy: 0.8794\n",
            "Epoch 972/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3048 - accuracy: 0.8890 - val_loss: 0.3683 - val_accuracy: 0.8756\n",
            "Epoch 973/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3015 - accuracy: 0.8882 - val_loss: 0.3629 - val_accuracy: 0.8814\n",
            "Epoch 974/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3088 - accuracy: 0.8873 - val_loss: 0.3652 - val_accuracy: 0.8781\n",
            "Epoch 975/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2933 - accuracy: 0.8936 - val_loss: 0.3611 - val_accuracy: 0.8772\n",
            "Epoch 976/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2989 - accuracy: 0.8912 - val_loss: 0.3641 - val_accuracy: 0.8773\n",
            "Epoch 977/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3028 - accuracy: 0.8864 - val_loss: 0.3735 - val_accuracy: 0.8733\n",
            "Epoch 978/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2950 - accuracy: 0.8900 - val_loss: 0.3710 - val_accuracy: 0.8773\n",
            "Epoch 979/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3053 - accuracy: 0.8894 - val_loss: 0.3722 - val_accuracy: 0.8777\n",
            "Epoch 980/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3078 - accuracy: 0.8866 - val_loss: 0.3594 - val_accuracy: 0.8777\n",
            "Epoch 981/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2971 - accuracy: 0.8920 - val_loss: 0.3612 - val_accuracy: 0.8741\n",
            "Epoch 982/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3022 - accuracy: 0.8897 - val_loss: 0.3643 - val_accuracy: 0.8772\n",
            "Epoch 983/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3067 - accuracy: 0.8868 - val_loss: 0.3563 - val_accuracy: 0.8775\n",
            "Epoch 984/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3101 - accuracy: 0.8884 - val_loss: 0.3647 - val_accuracy: 0.8756\n",
            "Epoch 985/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2908 - accuracy: 0.8959 - val_loss: 0.3697 - val_accuracy: 0.8759\n",
            "Epoch 986/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3125 - accuracy: 0.8866 - val_loss: 0.3691 - val_accuracy: 0.8770\n",
            "Epoch 987/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2963 - accuracy: 0.8907 - val_loss: 0.3672 - val_accuracy: 0.8809\n",
            "Epoch 988/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3072 - accuracy: 0.8873 - val_loss: 0.3636 - val_accuracy: 0.8780\n",
            "Epoch 989/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2980 - accuracy: 0.8910 - val_loss: 0.3699 - val_accuracy: 0.8725\n",
            "Epoch 990/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2978 - accuracy: 0.8955 - val_loss: 0.3665 - val_accuracy: 0.8788\n",
            "Epoch 991/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3026 - accuracy: 0.8910 - val_loss: 0.3696 - val_accuracy: 0.8767\n",
            "Epoch 992/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3048 - accuracy: 0.8898 - val_loss: 0.3685 - val_accuracy: 0.8781\n",
            "Epoch 993/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3072 - accuracy: 0.8873 - val_loss: 0.3691 - val_accuracy: 0.8769\n",
            "Epoch 994/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3122 - accuracy: 0.8857 - val_loss: 0.3624 - val_accuracy: 0.8769\n",
            "Epoch 995/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2955 - accuracy: 0.8932 - val_loss: 0.3586 - val_accuracy: 0.8741\n",
            "Epoch 996/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3025 - accuracy: 0.8884 - val_loss: 0.3591 - val_accuracy: 0.8764\n",
            "Epoch 997/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3008 - accuracy: 0.8900 - val_loss: 0.3608 - val_accuracy: 0.8792\n",
            "Epoch 998/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3041 - accuracy: 0.8891 - val_loss: 0.3629 - val_accuracy: 0.8789\n",
            "Epoch 999/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2984 - accuracy: 0.8929 - val_loss: 0.3666 - val_accuracy: 0.8803\n",
            "Epoch 1000/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3024 - accuracy: 0.8863 - val_loss: 0.3700 - val_accuracy: 0.8773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv-HYrBymx6_",
        "outputId": "31412568-b5c9-4fa5-8220-ca9098e26c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "dropout_loss,dropout_acc=model_dropout.evaluate(test_dataset,steps=50)\n",
        "print(\"Accuracy with dropout layers is \",dropout_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 0s 8ms/step - loss: 0.3700 - accuracy: 0.8773\n",
            "Accuracy with dropout layers is  0.8773437738418579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzFDzd97n3HR"
      },
      "source": [
        "batch_model = tf.keras.Sequential()\n",
        "batch_model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "batch_model.add(keras.layers.Dense(128, activation='relu'))\n",
        "batch_model.add(keras.layers.BatchNormalization())\n",
        "batch_model.add(keras.layers.Dense(128, activation='relu')) \n",
        "batch_model.add(keras.layers.BatchNormalization())                     \n",
        "batch_model.add(keras.layers.Dense(10,activation='softmax'))                            \n",
        "\n",
        "batch_model.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hsA4gnfomQ4",
        "outputId": "a42083b8-805c-41d6-b3f9-1c7a653be125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_batch = batch_model.fit(train_dataset,epochs=EPOCHS,steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,validation_data=test_dataset,batch_size=BATCH_SIZE,verbose = 1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6730 - accuracy: 0.7641 - val_loss: 2.2814 - val_accuracy: 0.0984\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4690 - accuracy: 0.8320 - val_loss: 2.2486 - val_accuracy: 0.0984\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4321 - accuracy: 0.8445 - val_loss: 2.1407 - val_accuracy: 0.1619\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4114 - accuracy: 0.8534 - val_loss: 1.8248 - val_accuracy: 0.2778\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3931 - accuracy: 0.8562 - val_loss: 1.2136 - val_accuracy: 0.7061\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3803 - accuracy: 0.8612 - val_loss: 0.7143 - val_accuracy: 0.8105\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3594 - accuracy: 0.8712 - val_loss: 0.5026 - val_accuracy: 0.8281\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3579 - accuracy: 0.8712 - val_loss: 0.4793 - val_accuracy: 0.8228\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3518 - accuracy: 0.8711 - val_loss: 0.5591 - val_accuracy: 0.7919\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3417 - accuracy: 0.8759 - val_loss: 0.4200 - val_accuracy: 0.8508\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3294 - accuracy: 0.8802 - val_loss: 0.4275 - val_accuracy: 0.8409\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3269 - accuracy: 0.8807 - val_loss: 0.4621 - val_accuracy: 0.8408\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3269 - accuracy: 0.8813 - val_loss: 0.4583 - val_accuracy: 0.8323\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3113 - accuracy: 0.8853 - val_loss: 0.5328 - val_accuracy: 0.8098\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3153 - accuracy: 0.8863 - val_loss: 0.7874 - val_accuracy: 0.7563\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3073 - accuracy: 0.8898 - val_loss: 0.4472 - val_accuracy: 0.8444\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3030 - accuracy: 0.8891 - val_loss: 0.4109 - val_accuracy: 0.8503\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2998 - accuracy: 0.8897 - val_loss: 0.4008 - val_accuracy: 0.8569\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2934 - accuracy: 0.8941 - val_loss: 0.4160 - val_accuracy: 0.8475\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2928 - accuracy: 0.8941 - val_loss: 0.4215 - val_accuracy: 0.8550\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2817 - accuracy: 0.8984 - val_loss: 0.4685 - val_accuracy: 0.8433\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2862 - accuracy: 0.8923 - val_loss: 0.5112 - val_accuracy: 0.8209\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2785 - accuracy: 0.8987 - val_loss: 0.4548 - val_accuracy: 0.8378\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2790 - accuracy: 0.8991 - val_loss: 0.4150 - val_accuracy: 0.8553\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2691 - accuracy: 0.9008 - val_loss: 0.4208 - val_accuracy: 0.8537\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2683 - accuracy: 0.9030 - val_loss: 0.4489 - val_accuracy: 0.8369\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2674 - accuracy: 0.9007 - val_loss: 0.4026 - val_accuracy: 0.8597\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2638 - accuracy: 0.9055 - val_loss: 0.4129 - val_accuracy: 0.8572\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2635 - accuracy: 0.9052 - val_loss: 0.4934 - val_accuracy: 0.8530\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2593 - accuracy: 0.9067 - val_loss: 0.4051 - val_accuracy: 0.8558\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2557 - accuracy: 0.9079 - val_loss: 0.4322 - val_accuracy: 0.8494\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2521 - accuracy: 0.9082 - val_loss: 0.4367 - val_accuracy: 0.8517\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2508 - accuracy: 0.9095 - val_loss: 0.6122 - val_accuracy: 0.7848\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2501 - accuracy: 0.9080 - val_loss: 0.5007 - val_accuracy: 0.8331\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2385 - accuracy: 0.9150 - val_loss: 0.4671 - val_accuracy: 0.8458\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2452 - accuracy: 0.9100 - val_loss: 0.4275 - val_accuracy: 0.8469\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2375 - accuracy: 0.9137 - val_loss: 0.4911 - val_accuracy: 0.8352\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2416 - accuracy: 0.9132 - val_loss: 0.4351 - val_accuracy: 0.8623\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2316 - accuracy: 0.9156 - val_loss: 0.4078 - val_accuracy: 0.8623\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2317 - accuracy: 0.9170 - val_loss: 0.5380 - val_accuracy: 0.8238\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2288 - accuracy: 0.9167 - val_loss: 0.4200 - val_accuracy: 0.8570\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2256 - accuracy: 0.9166 - val_loss: 0.4281 - val_accuracy: 0.8578\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2299 - accuracy: 0.9150 - val_loss: 0.5455 - val_accuracy: 0.8452\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2212 - accuracy: 0.9194 - val_loss: 0.4246 - val_accuracy: 0.8495\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2203 - accuracy: 0.9225 - val_loss: 0.4403 - val_accuracy: 0.8530\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2197 - accuracy: 0.9191 - val_loss: 0.3901 - val_accuracy: 0.8655\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2125 - accuracy: 0.9234 - val_loss: 0.5047 - val_accuracy: 0.8364\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2160 - accuracy: 0.9202 - val_loss: 0.4976 - val_accuracy: 0.8391\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2122 - accuracy: 0.9225 - val_loss: 0.4902 - val_accuracy: 0.8480\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2138 - accuracy: 0.9213 - val_loss: 0.4278 - val_accuracy: 0.8478\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2048 - accuracy: 0.9255 - val_loss: 0.5038 - val_accuracy: 0.8438\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2082 - accuracy: 0.9231 - val_loss: 0.4493 - val_accuracy: 0.8597\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2033 - accuracy: 0.9249 - val_loss: 0.4421 - val_accuracy: 0.8505\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2007 - accuracy: 0.9274 - val_loss: 0.4758 - val_accuracy: 0.8506\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1995 - accuracy: 0.9267 - val_loss: 0.6055 - val_accuracy: 0.8152\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1986 - accuracy: 0.9288 - val_loss: 0.4959 - val_accuracy: 0.8486\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2005 - accuracy: 0.9263 - val_loss: 0.7731 - val_accuracy: 0.7648\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1951 - accuracy: 0.9304 - val_loss: 0.4549 - val_accuracy: 0.8478\n",
            "Epoch 59/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1962 - accuracy: 0.9279 - val_loss: 0.4681 - val_accuracy: 0.8542\n",
            "Epoch 60/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1906 - accuracy: 0.9302 - val_loss: 0.4986 - val_accuracy: 0.8377\n",
            "Epoch 61/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1881 - accuracy: 0.9305 - val_loss: 0.5158 - val_accuracy: 0.8372\n",
            "Epoch 62/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1977 - accuracy: 0.9260 - val_loss: 0.8612 - val_accuracy: 0.7563\n",
            "Epoch 63/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1868 - accuracy: 0.9335 - val_loss: 0.5765 - val_accuracy: 0.8264\n",
            "Epoch 64/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1899 - accuracy: 0.9320 - val_loss: 0.4695 - val_accuracy: 0.8417\n",
            "Epoch 65/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1836 - accuracy: 0.9338 - val_loss: 0.4613 - val_accuracy: 0.8502\n",
            "Epoch 66/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1832 - accuracy: 0.9338 - val_loss: 0.4575 - val_accuracy: 0.8553\n",
            "Epoch 67/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1796 - accuracy: 0.9352 - val_loss: 0.4741 - val_accuracy: 0.8569\n",
            "Epoch 68/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1783 - accuracy: 0.9379 - val_loss: 0.4097 - val_accuracy: 0.8725\n",
            "Epoch 69/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1751 - accuracy: 0.9370 - val_loss: 0.4325 - val_accuracy: 0.8577\n",
            "Epoch 70/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1731 - accuracy: 0.9366 - val_loss: 0.4905 - val_accuracy: 0.8550\n",
            "Epoch 71/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1794 - accuracy: 0.9341 - val_loss: 0.4752 - val_accuracy: 0.8577\n",
            "Epoch 72/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1738 - accuracy: 0.9388 - val_loss: 0.6573 - val_accuracy: 0.8106\n",
            "Epoch 73/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1748 - accuracy: 0.9380 - val_loss: 0.4517 - val_accuracy: 0.8566\n",
            "Epoch 74/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1646 - accuracy: 0.9420 - val_loss: 0.4004 - val_accuracy: 0.8748\n",
            "Epoch 75/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1680 - accuracy: 0.9392 - val_loss: 0.5560 - val_accuracy: 0.8345\n",
            "Epoch 76/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1686 - accuracy: 0.9388 - val_loss: 0.4483 - val_accuracy: 0.8630\n",
            "Epoch 77/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1674 - accuracy: 0.9398 - val_loss: 0.4616 - val_accuracy: 0.8586\n",
            "Epoch 78/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1654 - accuracy: 0.9414 - val_loss: 0.4413 - val_accuracy: 0.8552\n",
            "Epoch 79/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1605 - accuracy: 0.9430 - val_loss: 0.4941 - val_accuracy: 0.8506\n",
            "Epoch 80/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1606 - accuracy: 0.9430 - val_loss: 0.4608 - val_accuracy: 0.8625\n",
            "Epoch 81/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1594 - accuracy: 0.9434 - val_loss: 0.5165 - val_accuracy: 0.8550\n",
            "Epoch 82/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1647 - accuracy: 0.9415 - val_loss: 0.5321 - val_accuracy: 0.8434\n",
            "Epoch 83/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1611 - accuracy: 0.9434 - val_loss: 0.7052 - val_accuracy: 0.8005\n",
            "Epoch 84/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1561 - accuracy: 0.9433 - val_loss: 0.6586 - val_accuracy: 0.8205\n",
            "Epoch 85/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1623 - accuracy: 0.9407 - val_loss: 0.4994 - val_accuracy: 0.8489\n",
            "Epoch 86/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1563 - accuracy: 0.9444 - val_loss: 0.5948 - val_accuracy: 0.8413\n",
            "Epoch 87/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1582 - accuracy: 0.9438 - val_loss: 1.2883 - val_accuracy: 0.6975\n",
            "Epoch 88/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1482 - accuracy: 0.9479 - val_loss: 0.5513 - val_accuracy: 0.8467\n",
            "Epoch 89/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1540 - accuracy: 0.9436 - val_loss: 0.5794 - val_accuracy: 0.8355\n",
            "Epoch 90/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1484 - accuracy: 0.9476 - val_loss: 0.4646 - val_accuracy: 0.8625\n",
            "Epoch 91/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1477 - accuracy: 0.9481 - val_loss: 0.8911 - val_accuracy: 0.7763\n",
            "Epoch 92/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1476 - accuracy: 0.9475 - val_loss: 0.5088 - val_accuracy: 0.8406\n",
            "Epoch 93/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1442 - accuracy: 0.9486 - val_loss: 0.4998 - val_accuracy: 0.8523\n",
            "Epoch 94/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1430 - accuracy: 0.9514 - val_loss: 0.5322 - val_accuracy: 0.8516\n",
            "Epoch 95/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1414 - accuracy: 0.9491 - val_loss: 0.4959 - val_accuracy: 0.8611\n",
            "Epoch 96/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1435 - accuracy: 0.9484 - val_loss: 0.8206 - val_accuracy: 0.7991\n",
            "Epoch 97/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1441 - accuracy: 0.9498 - val_loss: 0.5499 - val_accuracy: 0.8498\n",
            "Epoch 98/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1370 - accuracy: 0.9521 - val_loss: 0.6221 - val_accuracy: 0.8281\n",
            "Epoch 99/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1420 - accuracy: 0.9491 - val_loss: 0.4823 - val_accuracy: 0.8620\n",
            "Epoch 100/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1318 - accuracy: 0.9543 - val_loss: 0.5646 - val_accuracy: 0.8491\n",
            "Epoch 101/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1375 - accuracy: 0.9527 - val_loss: 0.8527 - val_accuracy: 0.7800\n",
            "Epoch 102/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1324 - accuracy: 0.9527 - val_loss: 0.4949 - val_accuracy: 0.8625\n",
            "Epoch 103/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1343 - accuracy: 0.9533 - val_loss: 0.8323 - val_accuracy: 0.7853\n",
            "Epoch 104/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1329 - accuracy: 0.9530 - val_loss: 0.5657 - val_accuracy: 0.8400\n",
            "Epoch 105/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1294 - accuracy: 0.9541 - val_loss: 0.6248 - val_accuracy: 0.8267\n",
            "Epoch 106/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1306 - accuracy: 0.9554 - val_loss: 0.4780 - val_accuracy: 0.8619\n",
            "Epoch 107/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1270 - accuracy: 0.9562 - val_loss: 0.6708 - val_accuracy: 0.8363\n",
            "Epoch 108/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1293 - accuracy: 0.9545 - val_loss: 0.5513 - val_accuracy: 0.8572\n",
            "Epoch 109/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1249 - accuracy: 0.9573 - val_loss: 0.8061 - val_accuracy: 0.8116\n",
            "Epoch 110/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1254 - accuracy: 0.9566 - val_loss: 0.6460 - val_accuracy: 0.8267\n",
            "Epoch 111/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1254 - accuracy: 0.9565 - val_loss: 0.5702 - val_accuracy: 0.8433\n",
            "Epoch 112/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1216 - accuracy: 0.9573 - val_loss: 0.6808 - val_accuracy: 0.8175\n",
            "Epoch 113/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1279 - accuracy: 0.9546 - val_loss: 0.6358 - val_accuracy: 0.8453\n",
            "Epoch 114/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1217 - accuracy: 0.9575 - val_loss: 0.5867 - val_accuracy: 0.8609\n",
            "Epoch 115/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1221 - accuracy: 0.9579 - val_loss: 0.6227 - val_accuracy: 0.8423\n",
            "Epoch 116/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1220 - accuracy: 0.9564 - val_loss: 0.4917 - val_accuracy: 0.8642\n",
            "Epoch 117/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1169 - accuracy: 0.9594 - val_loss: 0.6759 - val_accuracy: 0.8319\n",
            "Epoch 118/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1195 - accuracy: 0.9580 - val_loss: 0.8015 - val_accuracy: 0.7995\n",
            "Epoch 119/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1171 - accuracy: 0.9589 - val_loss: 0.7270 - val_accuracy: 0.8252\n",
            "Epoch 120/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1205 - accuracy: 0.9573 - val_loss: 0.5281 - val_accuracy: 0.8587\n",
            "Epoch 121/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1118 - accuracy: 0.9610 - val_loss: 0.6853 - val_accuracy: 0.8389\n",
            "Epoch 122/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1152 - accuracy: 0.9593 - val_loss: 0.6996 - val_accuracy: 0.8355\n",
            "Epoch 123/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1121 - accuracy: 0.9607 - val_loss: 0.6772 - val_accuracy: 0.8494\n",
            "Epoch 124/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1125 - accuracy: 0.9612 - val_loss: 0.6659 - val_accuracy: 0.8380\n",
            "Epoch 125/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1120 - accuracy: 0.9598 - val_loss: 0.5291 - val_accuracy: 0.8550\n",
            "Epoch 126/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1078 - accuracy: 0.9635 - val_loss: 0.6316 - val_accuracy: 0.8475\n",
            "Epoch 127/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1156 - accuracy: 0.9586 - val_loss: 0.6576 - val_accuracy: 0.8506\n",
            "Epoch 128/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1122 - accuracy: 0.9605 - val_loss: 0.7160 - val_accuracy: 0.8348\n",
            "Epoch 129/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1126 - accuracy: 0.9611 - val_loss: 0.6879 - val_accuracy: 0.8438\n",
            "Epoch 130/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1075 - accuracy: 0.9630 - val_loss: 0.6927 - val_accuracy: 0.8180\n",
            "Epoch 131/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1074 - accuracy: 0.9621 - val_loss: 0.6244 - val_accuracy: 0.8458\n",
            "Epoch 132/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1097 - accuracy: 0.9598 - val_loss: 0.8360 - val_accuracy: 0.8158\n",
            "Epoch 133/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1109 - accuracy: 0.9606 - val_loss: 0.6201 - val_accuracy: 0.8455\n",
            "Epoch 134/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1094 - accuracy: 0.9601 - val_loss: 0.6525 - val_accuracy: 0.8408\n",
            "Epoch 135/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1085 - accuracy: 0.9611 - val_loss: 0.6936 - val_accuracy: 0.8509\n",
            "Epoch 136/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1080 - accuracy: 0.9595 - val_loss: 0.6663 - val_accuracy: 0.8391\n",
            "Epoch 137/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1061 - accuracy: 0.9634 - val_loss: 0.6719 - val_accuracy: 0.8552\n",
            "Epoch 138/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1018 - accuracy: 0.9640 - val_loss: 0.6320 - val_accuracy: 0.8569\n",
            "Epoch 139/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1056 - accuracy: 0.9607 - val_loss: 0.5988 - val_accuracy: 0.8517\n",
            "Epoch 140/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0979 - accuracy: 0.9655 - val_loss: 0.6284 - val_accuracy: 0.8525\n",
            "Epoch 141/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1043 - accuracy: 0.9634 - val_loss: 0.8694 - val_accuracy: 0.8359\n",
            "Epoch 142/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1023 - accuracy: 0.9662 - val_loss: 0.7854 - val_accuracy: 0.8345\n",
            "Epoch 143/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1029 - accuracy: 0.9650 - val_loss: 0.7156 - val_accuracy: 0.8383\n",
            "Epoch 144/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0974 - accuracy: 0.9665 - val_loss: 0.5986 - val_accuracy: 0.8572\n",
            "Epoch 145/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0946 - accuracy: 0.9655 - val_loss: 0.6771 - val_accuracy: 0.8561\n",
            "Epoch 146/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1016 - accuracy: 0.9645 - val_loss: 0.6577 - val_accuracy: 0.8584\n",
            "Epoch 147/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1004 - accuracy: 0.9659 - val_loss: 0.7101 - val_accuracy: 0.8322\n",
            "Epoch 148/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0936 - accuracy: 0.9686 - val_loss: 0.8205 - val_accuracy: 0.8183\n",
            "Epoch 149/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0906 - accuracy: 0.9720 - val_loss: 0.6558 - val_accuracy: 0.8608\n",
            "Epoch 150/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0930 - accuracy: 0.9663 - val_loss: 0.8243 - val_accuracy: 0.8275\n",
            "Epoch 151/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1001 - accuracy: 0.9655 - val_loss: 0.6500 - val_accuracy: 0.8589\n",
            "Epoch 152/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0906 - accuracy: 0.9690 - val_loss: 0.7242 - val_accuracy: 0.8480\n",
            "Epoch 153/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0960 - accuracy: 0.9668 - val_loss: 0.7112 - val_accuracy: 0.8372\n",
            "Epoch 154/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0882 - accuracy: 0.9695 - val_loss: 0.6526 - val_accuracy: 0.8531\n",
            "Epoch 155/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0924 - accuracy: 0.9674 - val_loss: 0.7964 - val_accuracy: 0.8405\n",
            "Epoch 156/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0903 - accuracy: 0.9693 - val_loss: 0.7242 - val_accuracy: 0.8441\n",
            "Epoch 157/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0861 - accuracy: 0.9709 - val_loss: 0.7188 - val_accuracy: 0.8448\n",
            "Epoch 158/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0921 - accuracy: 0.9677 - val_loss: 0.6547 - val_accuracy: 0.8470\n",
            "Epoch 159/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0861 - accuracy: 0.9695 - val_loss: 0.7250 - val_accuracy: 0.8498\n",
            "Epoch 160/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0929 - accuracy: 0.9687 - val_loss: 0.6449 - val_accuracy: 0.8577\n",
            "Epoch 161/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0911 - accuracy: 0.9701 - val_loss: 0.7677 - val_accuracy: 0.8233\n",
            "Epoch 162/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0882 - accuracy: 0.9688 - val_loss: 0.7341 - val_accuracy: 0.8448\n",
            "Epoch 163/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0855 - accuracy: 0.9714 - val_loss: 0.6784 - val_accuracy: 0.8547\n",
            "Epoch 164/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0839 - accuracy: 0.9698 - val_loss: 0.9055 - val_accuracy: 0.8236\n",
            "Epoch 165/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0919 - accuracy: 0.9680 - val_loss: 0.6400 - val_accuracy: 0.8591\n",
            "Epoch 166/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0889 - accuracy: 0.9699 - val_loss: 0.8392 - val_accuracy: 0.8450\n",
            "Epoch 167/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0909 - accuracy: 0.9688 - val_loss: 0.7177 - val_accuracy: 0.8487\n",
            "Epoch 168/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0771 - accuracy: 0.9747 - val_loss: 0.7373 - val_accuracy: 0.8478\n",
            "Epoch 169/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0824 - accuracy: 0.9722 - val_loss: 0.8266 - val_accuracy: 0.8381\n",
            "Epoch 170/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0863 - accuracy: 0.9693 - val_loss: 0.7683 - val_accuracy: 0.8577\n",
            "Epoch 171/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0844 - accuracy: 0.9715 - val_loss: 0.8829 - val_accuracy: 0.8302\n",
            "Epoch 172/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0757 - accuracy: 0.9748 - val_loss: 0.7888 - val_accuracy: 0.8198\n",
            "Epoch 173/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0773 - accuracy: 0.9732 - val_loss: 0.7563 - val_accuracy: 0.8587\n",
            "Epoch 174/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0841 - accuracy: 0.9699 - val_loss: 0.9598 - val_accuracy: 0.8216\n",
            "Epoch 175/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0880 - accuracy: 0.9695 - val_loss: 0.8757 - val_accuracy: 0.8250\n",
            "Epoch 176/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0821 - accuracy: 0.9725 - val_loss: 0.7845 - val_accuracy: 0.8417\n",
            "Epoch 177/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0773 - accuracy: 0.9739 - val_loss: 0.7623 - val_accuracy: 0.8486\n",
            "Epoch 178/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0759 - accuracy: 0.9733 - val_loss: 1.8017 - val_accuracy: 0.7400\n",
            "Epoch 179/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1037 - accuracy: 0.9617 - val_loss: 1.8032 - val_accuracy: 0.7517\n",
            "Epoch 180/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0996 - accuracy: 0.9629 - val_loss: 0.9893 - val_accuracy: 0.8188\n",
            "Epoch 181/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0901 - accuracy: 0.9684 - val_loss: 0.7638 - val_accuracy: 0.8372\n",
            "Epoch 182/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0774 - accuracy: 0.9724 - val_loss: 0.9428 - val_accuracy: 0.8219\n",
            "Epoch 183/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0760 - accuracy: 0.9728 - val_loss: 1.0456 - val_accuracy: 0.8139\n",
            "Epoch 184/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0824 - accuracy: 0.9692 - val_loss: 0.8508 - val_accuracy: 0.8423\n",
            "Epoch 185/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9727 - val_loss: 0.7247 - val_accuracy: 0.8558\n",
            "Epoch 186/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0752 - accuracy: 0.9740 - val_loss: 0.7448 - val_accuracy: 0.8436\n",
            "Epoch 187/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0711 - accuracy: 0.9754 - val_loss: 0.7645 - val_accuracy: 0.8611\n",
            "Epoch 188/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0798 - accuracy: 0.9723 - val_loss: 0.7525 - val_accuracy: 0.8470\n",
            "Epoch 189/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0794 - accuracy: 0.9715 - val_loss: 0.8459 - val_accuracy: 0.8345\n",
            "Epoch 190/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0722 - accuracy: 0.9752 - val_loss: 0.7692 - val_accuracy: 0.8528\n",
            "Epoch 191/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0666 - accuracy: 0.9785 - val_loss: 0.7046 - val_accuracy: 0.8514\n",
            "Epoch 192/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0654 - accuracy: 0.9778 - val_loss: 0.7362 - val_accuracy: 0.8584\n",
            "Epoch 193/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0718 - accuracy: 0.9755 - val_loss: 0.7742 - val_accuracy: 0.8481\n",
            "Epoch 194/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0770 - accuracy: 0.9729 - val_loss: 0.8466 - val_accuracy: 0.8477\n",
            "Epoch 195/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0662 - accuracy: 0.9779 - val_loss: 0.7082 - val_accuracy: 0.8548\n",
            "Epoch 196/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0651 - accuracy: 0.9781 - val_loss: 0.9337 - val_accuracy: 0.8422\n",
            "Epoch 197/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0707 - accuracy: 0.9750 - val_loss: 0.9095 - val_accuracy: 0.8256\n",
            "Epoch 198/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0697 - accuracy: 0.9762 - val_loss: 0.7882 - val_accuracy: 0.8627\n",
            "Epoch 199/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0743 - accuracy: 0.9748 - val_loss: 0.7237 - val_accuracy: 0.8541\n",
            "Epoch 200/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0642 - accuracy: 0.9791 - val_loss: 0.7444 - val_accuracy: 0.8536\n",
            "Epoch 201/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0658 - accuracy: 0.9762 - val_loss: 0.7851 - val_accuracy: 0.8516\n",
            "Epoch 202/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0731 - accuracy: 0.9743 - val_loss: 0.8324 - val_accuracy: 0.8520\n",
            "Epoch 203/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0702 - accuracy: 0.9752 - val_loss: 0.8659 - val_accuracy: 0.8420\n",
            "Epoch 204/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0660 - accuracy: 0.9775 - val_loss: 0.8061 - val_accuracy: 0.8383\n",
            "Epoch 205/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0649 - accuracy: 0.9783 - val_loss: 0.7541 - val_accuracy: 0.8475\n",
            "Epoch 206/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0693 - accuracy: 0.9762 - val_loss: 0.7774 - val_accuracy: 0.8433\n",
            "Epoch 207/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0752 - accuracy: 0.9744 - val_loss: 1.2091 - val_accuracy: 0.7897\n",
            "Epoch 208/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0726 - accuracy: 0.9737 - val_loss: 1.0872 - val_accuracy: 0.8147\n",
            "Epoch 209/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0678 - accuracy: 0.9766 - val_loss: 0.8149 - val_accuracy: 0.8414\n",
            "Epoch 210/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0666 - accuracy: 0.9762 - val_loss: 0.9681 - val_accuracy: 0.8505\n",
            "Epoch 211/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0721 - accuracy: 0.9747 - val_loss: 0.9925 - val_accuracy: 0.8263\n",
            "Epoch 212/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0729 - accuracy: 0.9739 - val_loss: 0.7601 - val_accuracy: 0.8652\n",
            "Epoch 213/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0668 - accuracy: 0.9760 - val_loss: 0.8065 - val_accuracy: 0.8552\n",
            "Epoch 214/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0561 - accuracy: 0.9812 - val_loss: 0.7943 - val_accuracy: 0.8514\n",
            "Epoch 215/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0587 - accuracy: 0.9792 - val_loss: 0.7560 - val_accuracy: 0.8470\n",
            "Epoch 216/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9766 - val_loss: 0.9862 - val_accuracy: 0.8302\n",
            "Epoch 217/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0615 - accuracy: 0.9771 - val_loss: 0.8581 - val_accuracy: 0.8567\n",
            "Epoch 218/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0606 - accuracy: 0.9783 - val_loss: 0.8291 - val_accuracy: 0.8537\n",
            "Epoch 219/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0571 - accuracy: 0.9813 - val_loss: 0.7253 - val_accuracy: 0.8531\n",
            "Epoch 220/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0549 - accuracy: 0.9812 - val_loss: 0.8548 - val_accuracy: 0.8458\n",
            "Epoch 221/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0643 - accuracy: 0.9766 - val_loss: 0.8576 - val_accuracy: 0.8348\n",
            "Epoch 222/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0605 - accuracy: 0.9796 - val_loss: 0.8373 - val_accuracy: 0.8478\n",
            "Epoch 223/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0549 - accuracy: 0.9820 - val_loss: 0.8929 - val_accuracy: 0.8419\n",
            "Epoch 224/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0526 - accuracy: 0.9823 - val_loss: 1.4237 - val_accuracy: 0.7816\n",
            "Epoch 225/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0592 - accuracy: 0.9801 - val_loss: 1.1829 - val_accuracy: 0.7894\n",
            "Epoch 226/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0655 - accuracy: 0.9774 - val_loss: 1.0799 - val_accuracy: 0.8373\n",
            "Epoch 227/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0597 - accuracy: 0.9793 - val_loss: 0.9468 - val_accuracy: 0.8470\n",
            "Epoch 228/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0557 - accuracy: 0.9804 - val_loss: 0.8116 - val_accuracy: 0.8527\n",
            "Epoch 229/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0533 - accuracy: 0.9823 - val_loss: 1.2614 - val_accuracy: 0.7875\n",
            "Epoch 230/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0593 - accuracy: 0.9788 - val_loss: 0.9717 - val_accuracy: 0.8356\n",
            "Epoch 231/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0600 - accuracy: 0.9779 - val_loss: 0.9923 - val_accuracy: 0.8425\n",
            "Epoch 232/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0603 - accuracy: 0.9782 - val_loss: 0.9408 - val_accuracy: 0.8500\n",
            "Epoch 233/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0543 - accuracy: 0.9825 - val_loss: 0.8417 - val_accuracy: 0.8464\n",
            "Epoch 234/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.8954 - val_accuracy: 0.8545\n",
            "Epoch 235/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0564 - accuracy: 0.9796 - val_loss: 0.9758 - val_accuracy: 0.8361\n",
            "Epoch 236/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0586 - accuracy: 0.9800 - val_loss: 0.8439 - val_accuracy: 0.8487\n",
            "Epoch 237/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0531 - accuracy: 0.9802 - val_loss: 1.8247 - val_accuracy: 0.7314\n",
            "Epoch 238/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0550 - accuracy: 0.9795 - val_loss: 1.0792 - val_accuracy: 0.8220\n",
            "Epoch 239/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0528 - accuracy: 0.9815 - val_loss: 1.0669 - val_accuracy: 0.8294\n",
            "Epoch 240/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0533 - accuracy: 0.9822 - val_loss: 0.8288 - val_accuracy: 0.8673\n",
            "Epoch 241/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0505 - accuracy: 0.9828 - val_loss: 0.9523 - val_accuracy: 0.8492\n",
            "Epoch 242/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0585 - accuracy: 0.9791 - val_loss: 1.0411 - val_accuracy: 0.8167\n",
            "Epoch 243/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0526 - accuracy: 0.9820 - val_loss: 0.8968 - val_accuracy: 0.8469\n",
            "Epoch 244/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0525 - accuracy: 0.9817 - val_loss: 1.0007 - val_accuracy: 0.8503\n",
            "Epoch 245/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0541 - accuracy: 0.9802 - val_loss: 1.0598 - val_accuracy: 0.8427\n",
            "Epoch 246/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0496 - accuracy: 0.9830 - val_loss: 1.0630 - val_accuracy: 0.8462\n",
            "Epoch 247/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0552 - accuracy: 0.9797 - val_loss: 0.9171 - val_accuracy: 0.8508\n",
            "Epoch 248/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0594 - accuracy: 0.9790 - val_loss: 1.1549 - val_accuracy: 0.8325\n",
            "Epoch 249/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0516 - accuracy: 0.9821 - val_loss: 0.9336 - val_accuracy: 0.8448\n",
            "Epoch 250/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0589 - accuracy: 0.9781 - val_loss: 0.9955 - val_accuracy: 0.8277\n",
            "Epoch 251/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0594 - accuracy: 0.9798 - val_loss: 1.3230 - val_accuracy: 0.8130\n",
            "Epoch 252/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0526 - accuracy: 0.9825 - val_loss: 1.4659 - val_accuracy: 0.7716\n",
            "Epoch 253/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0535 - accuracy: 0.9802 - val_loss: 1.0908 - val_accuracy: 0.8283\n",
            "Epoch 254/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0501 - accuracy: 0.9841 - val_loss: 0.9235 - val_accuracy: 0.8537\n",
            "Epoch 255/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0517 - accuracy: 0.9809 - val_loss: 1.1195 - val_accuracy: 0.8447\n",
            "Epoch 256/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0532 - accuracy: 0.9813 - val_loss: 1.1721 - val_accuracy: 0.8302\n",
            "Epoch 257/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0509 - accuracy: 0.9823 - val_loss: 1.1807 - val_accuracy: 0.8377\n",
            "Epoch 258/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0494 - accuracy: 0.9824 - val_loss: 0.9690 - val_accuracy: 0.8352\n",
            "Epoch 259/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0492 - accuracy: 0.9817 - val_loss: 1.1144 - val_accuracy: 0.8333\n",
            "Epoch 260/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0514 - accuracy: 0.9826 - val_loss: 1.2470 - val_accuracy: 0.8103\n",
            "Epoch 261/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 1.1589 - val_accuracy: 0.8067\n",
            "Epoch 262/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0500 - accuracy: 0.9812 - val_loss: 1.1412 - val_accuracy: 0.8297\n",
            "Epoch 263/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0532 - accuracy: 0.9806 - val_loss: 0.9754 - val_accuracy: 0.8553\n",
            "Epoch 264/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0525 - accuracy: 0.9807 - val_loss: 1.2803 - val_accuracy: 0.8086\n",
            "Epoch 265/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0520 - accuracy: 0.9814 - val_loss: 1.5591 - val_accuracy: 0.7892\n",
            "Epoch 266/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0509 - accuracy: 0.9830 - val_loss: 1.0773 - val_accuracy: 0.8330\n",
            "Epoch 267/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0514 - accuracy: 0.9808 - val_loss: 1.6910 - val_accuracy: 0.7627\n",
            "Epoch 268/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0526 - accuracy: 0.9820 - val_loss: 1.0543 - val_accuracy: 0.8397\n",
            "Epoch 269/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0485 - accuracy: 0.9830 - val_loss: 1.3567 - val_accuracy: 0.7983\n",
            "Epoch 270/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0431 - accuracy: 0.9856 - val_loss: 0.9792 - val_accuracy: 0.8473\n",
            "Epoch 271/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0402 - accuracy: 0.9871 - val_loss: 1.1834 - val_accuracy: 0.8309\n",
            "Epoch 272/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0494 - accuracy: 0.9830 - val_loss: 1.1546 - val_accuracy: 0.8308\n",
            "Epoch 273/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0461 - accuracy: 0.9846 - val_loss: 1.2757 - val_accuracy: 0.8230\n",
            "Epoch 274/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0449 - accuracy: 0.9850 - val_loss: 1.1344 - val_accuracy: 0.8411\n",
            "Epoch 275/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0527 - accuracy: 0.9806 - val_loss: 1.2544 - val_accuracy: 0.8264\n",
            "Epoch 276/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0521 - accuracy: 0.9812 - val_loss: 1.2703 - val_accuracy: 0.8116\n",
            "Epoch 277/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0615 - accuracy: 0.9773 - val_loss: 1.0443 - val_accuracy: 0.8380\n",
            "Epoch 278/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0689 - accuracy: 0.9730 - val_loss: 2.4159 - val_accuracy: 0.7481\n",
            "Epoch 279/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0718 - accuracy: 0.9716 - val_loss: 1.3975 - val_accuracy: 0.8177\n",
            "Epoch 280/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0679 - accuracy: 0.9752 - val_loss: 1.0983 - val_accuracy: 0.8233\n",
            "Epoch 281/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0528 - accuracy: 0.9798 - val_loss: 1.2256 - val_accuracy: 0.8064\n",
            "Epoch 282/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0550 - accuracy: 0.9795 - val_loss: 0.9237 - val_accuracy: 0.8478\n",
            "Epoch 283/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0547 - accuracy: 0.9791 - val_loss: 1.1399 - val_accuracy: 0.8266\n",
            "Epoch 284/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0540 - accuracy: 0.9801 - val_loss: 1.1123 - val_accuracy: 0.8255\n",
            "Epoch 285/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 1.5271 - val_accuracy: 0.8214\n",
            "Epoch 286/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0433 - accuracy: 0.9858 - val_loss: 1.0380 - val_accuracy: 0.8427\n",
            "Epoch 287/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0502 - accuracy: 0.9816 - val_loss: 1.1868 - val_accuracy: 0.8314\n",
            "Epoch 288/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0423 - accuracy: 0.9857 - val_loss: 1.2453 - val_accuracy: 0.8325\n",
            "Epoch 289/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0434 - accuracy: 0.9837 - val_loss: 0.9481 - val_accuracy: 0.8477\n",
            "Epoch 290/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0445 - accuracy: 0.9834 - val_loss: 1.2755 - val_accuracy: 0.8033\n",
            "Epoch 291/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0426 - accuracy: 0.9854 - val_loss: 0.9694 - val_accuracy: 0.8455\n",
            "Epoch 292/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0451 - accuracy: 0.9837 - val_loss: 1.3980 - val_accuracy: 0.8106\n",
            "Epoch 293/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0429 - accuracy: 0.9849 - val_loss: 1.1602 - val_accuracy: 0.8450\n",
            "Epoch 294/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0398 - accuracy: 0.9866 - val_loss: 0.9839 - val_accuracy: 0.8322\n",
            "Epoch 295/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0384 - accuracy: 0.9868 - val_loss: 1.1292 - val_accuracy: 0.8300\n",
            "Epoch 296/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0398 - accuracy: 0.9866 - val_loss: 1.1617 - val_accuracy: 0.8319\n",
            "Epoch 297/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0452 - accuracy: 0.9852 - val_loss: 1.2123 - val_accuracy: 0.8356\n",
            "Epoch 298/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0462 - accuracy: 0.9831 - val_loss: 1.0922 - val_accuracy: 0.8400\n",
            "Epoch 299/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0414 - accuracy: 0.9852 - val_loss: 1.4093 - val_accuracy: 0.8209\n",
            "Epoch 300/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0415 - accuracy: 0.9851 - val_loss: 0.9680 - val_accuracy: 0.8545\n",
            "Epoch 301/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0457 - accuracy: 0.9823 - val_loss: 1.1278 - val_accuracy: 0.8389\n",
            "Epoch 302/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0427 - accuracy: 0.9845 - val_loss: 1.2057 - val_accuracy: 0.8427\n",
            "Epoch 303/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0397 - accuracy: 0.9862 - val_loss: 1.1881 - val_accuracy: 0.8363\n",
            "Epoch 304/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0386 - accuracy: 0.9866 - val_loss: 1.0393 - val_accuracy: 0.8439\n",
            "Epoch 305/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0417 - accuracy: 0.9844 - val_loss: 1.2430 - val_accuracy: 0.8323\n",
            "Epoch 306/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0416 - accuracy: 0.9850 - val_loss: 1.4065 - val_accuracy: 0.8142\n",
            "Epoch 307/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0407 - accuracy: 0.9845 - val_loss: 2.1307 - val_accuracy: 0.7653\n",
            "Epoch 308/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0392 - accuracy: 0.9871 - val_loss: 1.0572 - val_accuracy: 0.8245\n",
            "Epoch 309/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0397 - accuracy: 0.9855 - val_loss: 1.2612 - val_accuracy: 0.8120\n",
            "Epoch 310/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0363 - accuracy: 0.9875 - val_loss: 1.0787 - val_accuracy: 0.8320\n",
            "Epoch 311/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0459 - accuracy: 0.9825 - val_loss: 1.7176 - val_accuracy: 0.7825\n",
            "Epoch 312/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0403 - accuracy: 0.9866 - val_loss: 1.0498 - val_accuracy: 0.8311\n",
            "Epoch 313/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0443 - accuracy: 0.9830 - val_loss: 1.1653 - val_accuracy: 0.8347\n",
            "Epoch 314/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0428 - accuracy: 0.9845 - val_loss: 1.6241 - val_accuracy: 0.7903\n",
            "Epoch 315/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0448 - accuracy: 0.9831 - val_loss: 1.7311 - val_accuracy: 0.8152\n",
            "Epoch 316/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0404 - accuracy: 0.9864 - val_loss: 1.3947 - val_accuracy: 0.8238\n",
            "Epoch 317/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0395 - accuracy: 0.9856 - val_loss: 1.1778 - val_accuracy: 0.8328\n",
            "Epoch 318/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0358 - accuracy: 0.9871 - val_loss: 1.3653 - val_accuracy: 0.7911\n",
            "Epoch 319/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0423 - accuracy: 0.9852 - val_loss: 1.1901 - val_accuracy: 0.8350\n",
            "Epoch 320/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0427 - accuracy: 0.9848 - val_loss: 1.2185 - val_accuracy: 0.8291\n",
            "Epoch 321/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0366 - accuracy: 0.9871 - val_loss: 1.1379 - val_accuracy: 0.8311\n",
            "Epoch 322/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 1.5217 - val_accuracy: 0.7797\n",
            "Epoch 323/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0372 - accuracy: 0.9880 - val_loss: 1.4156 - val_accuracy: 0.8114\n",
            "Epoch 324/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0400 - accuracy: 0.9857 - val_loss: 1.4937 - val_accuracy: 0.8073\n",
            "Epoch 325/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0476 - accuracy: 0.9830 - val_loss: 1.1992 - val_accuracy: 0.8227\n",
            "Epoch 326/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0464 - accuracy: 0.9834 - val_loss: 1.4514 - val_accuracy: 0.8184\n",
            "Epoch 327/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0379 - accuracy: 0.9862 - val_loss: 1.3292 - val_accuracy: 0.7933\n",
            "Epoch 328/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0361 - accuracy: 0.9874 - val_loss: 1.1883 - val_accuracy: 0.8320\n",
            "Epoch 329/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0392 - accuracy: 0.9868 - val_loss: 1.1565 - val_accuracy: 0.8466\n",
            "Epoch 330/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0438 - accuracy: 0.9837 - val_loss: 1.1348 - val_accuracy: 0.8466\n",
            "Epoch 331/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0472 - accuracy: 0.9831 - val_loss: 1.7940 - val_accuracy: 0.7723\n",
            "Epoch 332/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0383 - accuracy: 0.9857 - val_loss: 1.1650 - val_accuracy: 0.8325\n",
            "Epoch 333/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0370 - accuracy: 0.9862 - val_loss: 1.0998 - val_accuracy: 0.8384\n",
            "Epoch 334/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0366 - accuracy: 0.9865 - val_loss: 1.3282 - val_accuracy: 0.8086\n",
            "Epoch 335/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9876 - val_loss: 1.1059 - val_accuracy: 0.8388\n",
            "Epoch 336/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0369 - accuracy: 0.9870 - val_loss: 1.7676 - val_accuracy: 0.7639\n",
            "Epoch 337/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0404 - accuracy: 0.9859 - val_loss: 1.4549 - val_accuracy: 0.7952\n",
            "Epoch 338/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0423 - accuracy: 0.9845 - val_loss: 1.0673 - val_accuracy: 0.8458\n",
            "Epoch 339/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0413 - accuracy: 0.9847 - val_loss: 1.2958 - val_accuracy: 0.8361\n",
            "Epoch 340/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0350 - accuracy: 0.9885 - val_loss: 1.2140 - val_accuracy: 0.8550\n",
            "Epoch 341/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0336 - accuracy: 0.9881 - val_loss: 1.0720 - val_accuracy: 0.8512\n",
            "Epoch 342/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0333 - accuracy: 0.9876 - val_loss: 1.0829 - val_accuracy: 0.8320\n",
            "Epoch 343/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0361 - accuracy: 0.9870 - val_loss: 1.3128 - val_accuracy: 0.8492\n",
            "Epoch 344/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 1.3675 - val_accuracy: 0.8275\n",
            "Epoch 345/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0372 - accuracy: 0.9873 - val_loss: 1.2123 - val_accuracy: 0.8316\n",
            "Epoch 346/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0343 - accuracy: 0.9880 - val_loss: 1.9969 - val_accuracy: 0.7706\n",
            "Epoch 347/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0371 - accuracy: 0.9873 - val_loss: 1.3537 - val_accuracy: 0.8275\n",
            "Epoch 348/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0395 - accuracy: 0.9856 - val_loss: 1.3035 - val_accuracy: 0.8372\n",
            "Epoch 349/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0435 - accuracy: 0.9841 - val_loss: 1.2196 - val_accuracy: 0.8445\n",
            "Epoch 350/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0356 - accuracy: 0.9870 - val_loss: 1.0241 - val_accuracy: 0.8498\n",
            "Epoch 351/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9873 - val_loss: 1.3820 - val_accuracy: 0.8317\n",
            "Epoch 352/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0354 - accuracy: 0.9868 - val_loss: 1.4596 - val_accuracy: 0.8330\n",
            "Epoch 353/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0447 - accuracy: 0.9813 - val_loss: 1.3305 - val_accuracy: 0.8269\n",
            "Epoch 354/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0344 - accuracy: 0.9878 - val_loss: 1.1945 - val_accuracy: 0.8439\n",
            "Epoch 355/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0315 - accuracy: 0.9885 - val_loss: 1.3411 - val_accuracy: 0.8119\n",
            "Epoch 356/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 1.2741 - val_accuracy: 0.8134\n",
            "Epoch 357/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0380 - accuracy: 0.9857 - val_loss: 1.5224 - val_accuracy: 0.8195\n",
            "Epoch 358/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0417 - accuracy: 0.9853 - val_loss: 1.2129 - val_accuracy: 0.8377\n",
            "Epoch 359/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0368 - accuracy: 0.9866 - val_loss: 1.7173 - val_accuracy: 0.8044\n",
            "Epoch 360/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 1.3909 - val_accuracy: 0.8297\n",
            "Epoch 361/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9896 - val_loss: 1.2647 - val_accuracy: 0.8348\n",
            "Epoch 362/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0351 - accuracy: 0.9874 - val_loss: 1.6003 - val_accuracy: 0.7731\n",
            "Epoch 363/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0381 - accuracy: 0.9860 - val_loss: 1.4512 - val_accuracy: 0.8216\n",
            "Epoch 364/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0372 - accuracy: 0.9870 - val_loss: 1.0565 - val_accuracy: 0.8580\n",
            "Epoch 365/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 1.2476 - val_accuracy: 0.8395\n",
            "Epoch 366/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0285 - accuracy: 0.9898 - val_loss: 1.2766 - val_accuracy: 0.8338\n",
            "Epoch 367/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0343 - accuracy: 0.9876 - val_loss: 1.5705 - val_accuracy: 0.8109\n",
            "Epoch 368/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0334 - accuracy: 0.9878 - val_loss: 1.2146 - val_accuracy: 0.8406\n",
            "Epoch 369/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 0.9981 - val_accuracy: 0.8477\n",
            "Epoch 370/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0286 - accuracy: 0.9899 - val_loss: 1.2622 - val_accuracy: 0.8270\n",
            "Epoch 371/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0304 - accuracy: 0.9888 - val_loss: 1.6271 - val_accuracy: 0.8145\n",
            "Epoch 372/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0347 - accuracy: 0.9866 - val_loss: 1.4305 - val_accuracy: 0.8138\n",
            "Epoch 373/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 1.2777 - val_accuracy: 0.8289\n",
            "Epoch 374/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 1.4472 - val_accuracy: 0.8220\n",
            "Epoch 375/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0424 - accuracy: 0.9834 - val_loss: 1.4723 - val_accuracy: 0.8303\n",
            "Epoch 376/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9866 - val_loss: 1.3506 - val_accuracy: 0.8438\n",
            "Epoch 377/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0354 - accuracy: 0.9871 - val_loss: 1.1738 - val_accuracy: 0.8431\n",
            "Epoch 378/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 1.4770 - val_accuracy: 0.8419\n",
            "Epoch 379/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 1.2549 - val_accuracy: 0.8413\n",
            "Epoch 380/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 1.6448 - val_accuracy: 0.8178\n",
            "Epoch 381/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9873 - val_loss: 1.3721 - val_accuracy: 0.8470\n",
            "Epoch 382/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 1.7551 - val_accuracy: 0.8205\n",
            "Epoch 383/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0397 - accuracy: 0.9859 - val_loss: 1.4558 - val_accuracy: 0.8180\n",
            "Epoch 384/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0340 - accuracy: 0.9873 - val_loss: 1.3401 - val_accuracy: 0.8197\n",
            "Epoch 385/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0341 - accuracy: 0.9877 - val_loss: 1.2460 - val_accuracy: 0.8366\n",
            "Epoch 386/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9885 - val_loss: 1.2792 - val_accuracy: 0.8438\n",
            "Epoch 387/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0307 - accuracy: 0.9886 - val_loss: 1.2327 - val_accuracy: 0.8403\n",
            "Epoch 388/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 1.3783 - val_accuracy: 0.8378\n",
            "Epoch 389/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 1.3276 - val_accuracy: 0.8316\n",
            "Epoch 390/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0314 - accuracy: 0.9891 - val_loss: 1.2137 - val_accuracy: 0.8364\n",
            "Epoch 391/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 1.6142 - val_accuracy: 0.8284\n",
            "Epoch 392/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 1.4797 - val_accuracy: 0.8405\n",
            "Epoch 393/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0374 - accuracy: 0.9855 - val_loss: 1.2847 - val_accuracy: 0.8323\n",
            "Epoch 394/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9886 - val_loss: 2.5703 - val_accuracy: 0.7184\n",
            "Epoch 395/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9875 - val_loss: 1.6561 - val_accuracy: 0.8092\n",
            "Epoch 396/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0290 - accuracy: 0.9897 - val_loss: 1.3296 - val_accuracy: 0.8383\n",
            "Epoch 397/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 1.1986 - val_accuracy: 0.8284\n",
            "Epoch 398/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0275 - accuracy: 0.9907 - val_loss: 1.3867 - val_accuracy: 0.8109\n",
            "Epoch 399/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 1.3064 - val_accuracy: 0.8144\n",
            "Epoch 400/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0290 - accuracy: 0.9897 - val_loss: 1.3654 - val_accuracy: 0.8314\n",
            "Epoch 401/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0322 - accuracy: 0.9877 - val_loss: 1.4349 - val_accuracy: 0.8284\n",
            "Epoch 402/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 1.3187 - val_accuracy: 0.8370\n",
            "Epoch 403/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 1.4244 - val_accuracy: 0.8163\n",
            "Epoch 404/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0415 - accuracy: 0.9834 - val_loss: 1.6918 - val_accuracy: 0.8247\n",
            "Epoch 405/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0363 - accuracy: 0.9862 - val_loss: 1.5828 - val_accuracy: 0.8277\n",
            "Epoch 406/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 1.2394 - val_accuracy: 0.8456\n",
            "Epoch 407/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0277 - accuracy: 0.9897 - val_loss: 1.2261 - val_accuracy: 0.8484\n",
            "Epoch 408/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0347 - accuracy: 0.9877 - val_loss: 1.3768 - val_accuracy: 0.8348\n",
            "Epoch 409/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0331 - accuracy: 0.9881 - val_loss: 3.1090 - val_accuracy: 0.7272\n",
            "Epoch 410/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 1.4256 - val_accuracy: 0.8213\n",
            "Epoch 411/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0298 - accuracy: 0.9898 - val_loss: 1.2893 - val_accuracy: 0.8228\n",
            "Epoch 412/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 1.7432 - val_accuracy: 0.7980\n",
            "Epoch 413/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0297 - accuracy: 0.9888 - val_loss: 1.6801 - val_accuracy: 0.8053\n",
            "Epoch 414/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0332 - accuracy: 0.9892 - val_loss: 1.3985 - val_accuracy: 0.8470\n",
            "Epoch 415/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0282 - accuracy: 0.9902 - val_loss: 1.3311 - val_accuracy: 0.8280\n",
            "Epoch 416/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0296 - accuracy: 0.9897 - val_loss: 1.5201 - val_accuracy: 0.8045\n",
            "Epoch 417/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0340 - accuracy: 0.9873 - val_loss: 1.4044 - val_accuracy: 0.8163\n",
            "Epoch 418/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 1.3199 - val_accuracy: 0.8333\n",
            "Epoch 419/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9884 - val_loss: 1.5029 - val_accuracy: 0.8145\n",
            "Epoch 420/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0319 - accuracy: 0.9891 - val_loss: 1.4137 - val_accuracy: 0.8369\n",
            "Epoch 421/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9874 - val_loss: 1.4380 - val_accuracy: 0.8270\n",
            "Epoch 422/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0306 - accuracy: 0.9897 - val_loss: 1.7736 - val_accuracy: 0.8091\n",
            "Epoch 423/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 1.4789 - val_accuracy: 0.8400\n",
            "Epoch 424/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0290 - accuracy: 0.9902 - val_loss: 1.6589 - val_accuracy: 0.8319\n",
            "Epoch 425/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 1.6898 - val_accuracy: 0.8141\n",
            "Epoch 426/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 1.8181 - val_accuracy: 0.8138\n",
            "Epoch 427/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0278 - accuracy: 0.9901 - val_loss: 1.9952 - val_accuracy: 0.7970\n",
            "Epoch 428/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 1.3880 - val_accuracy: 0.8313\n",
            "Epoch 429/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0262 - accuracy: 0.9904 - val_loss: 1.5357 - val_accuracy: 0.8198\n",
            "Epoch 430/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0275 - accuracy: 0.9905 - val_loss: 1.3970 - val_accuracy: 0.8111\n",
            "Epoch 431/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 1.1183 - val_accuracy: 0.8383\n",
            "Epoch 432/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0286 - accuracy: 0.9902 - val_loss: 1.4173 - val_accuracy: 0.8225\n",
            "Epoch 433/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0283 - accuracy: 0.9906 - val_loss: 1.4538 - val_accuracy: 0.8202\n",
            "Epoch 434/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0272 - accuracy: 0.9902 - val_loss: 1.5876 - val_accuracy: 0.8192\n",
            "Epoch 435/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0277 - accuracy: 0.9909 - val_loss: 1.5123 - val_accuracy: 0.8339\n",
            "Epoch 436/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0257 - accuracy: 0.9910 - val_loss: 1.6162 - val_accuracy: 0.8309\n",
            "Epoch 437/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0261 - accuracy: 0.9901 - val_loss: 1.5089 - val_accuracy: 0.8403\n",
            "Epoch 438/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 1.7059 - val_accuracy: 0.8163\n",
            "Epoch 439/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0332 - accuracy: 0.9872 - val_loss: 1.8095 - val_accuracy: 0.8034\n",
            "Epoch 440/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0284 - accuracy: 0.9894 - val_loss: 1.6883 - val_accuracy: 0.8261\n",
            "Epoch 441/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0389 - accuracy: 0.9862 - val_loss: 2.6959 - val_accuracy: 0.7602\n",
            "Epoch 442/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0265 - accuracy: 0.9902 - val_loss: 1.8730 - val_accuracy: 0.8139\n",
            "Epoch 443/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 1.3776 - val_accuracy: 0.8434\n",
            "Epoch 444/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0306 - accuracy: 0.9890 - val_loss: 1.7499 - val_accuracy: 0.8097\n",
            "Epoch 445/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0307 - accuracy: 0.9892 - val_loss: 1.5005 - val_accuracy: 0.8270\n",
            "Epoch 446/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0283 - accuracy: 0.9899 - val_loss: 1.4793 - val_accuracy: 0.8452\n",
            "Epoch 447/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0302 - accuracy: 0.9898 - val_loss: 1.5002 - val_accuracy: 0.8375\n",
            "Epoch 448/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 1.2256 - val_accuracy: 0.8552\n",
            "Epoch 449/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0274 - accuracy: 0.9898 - val_loss: 1.7317 - val_accuracy: 0.8216\n",
            "Epoch 450/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0277 - accuracy: 0.9898 - val_loss: 1.5961 - val_accuracy: 0.8414\n",
            "Epoch 451/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 1.7262 - val_accuracy: 0.8267\n",
            "Epoch 452/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0274 - accuracy: 0.9897 - val_loss: 1.3852 - val_accuracy: 0.8166\n",
            "Epoch 453/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0268 - accuracy: 0.9900 - val_loss: 1.4109 - val_accuracy: 0.8266\n",
            "Epoch 454/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 2.2324 - val_accuracy: 0.7819\n",
            "Epoch 455/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 1.9004 - val_accuracy: 0.8022\n",
            "Epoch 456/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9875 - val_loss: 1.7300 - val_accuracy: 0.8139\n",
            "Epoch 457/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0280 - accuracy: 0.9891 - val_loss: 1.7203 - val_accuracy: 0.8097\n",
            "Epoch 458/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 1.4412 - val_accuracy: 0.8222\n",
            "Epoch 459/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 1.7543 - val_accuracy: 0.8019\n",
            "Epoch 460/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0261 - accuracy: 0.9914 - val_loss: 1.8507 - val_accuracy: 0.8153\n",
            "Epoch 461/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0264 - accuracy: 0.9904 - val_loss: 2.1048 - val_accuracy: 0.8058\n",
            "Epoch 462/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0280 - accuracy: 0.9899 - val_loss: 1.7307 - val_accuracy: 0.8028\n",
            "Epoch 463/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0289 - accuracy: 0.9894 - val_loss: 1.4653 - val_accuracy: 0.8231\n",
            "Epoch 464/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0344 - accuracy: 0.9875 - val_loss: 1.5229 - val_accuracy: 0.8448\n",
            "Epoch 465/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0377 - accuracy: 0.9863 - val_loss: 2.0621 - val_accuracy: 0.7611\n",
            "Epoch 466/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 1.6793 - val_accuracy: 0.8281\n",
            "Epoch 467/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 1.4314 - val_accuracy: 0.8423\n",
            "Epoch 468/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 1.4869 - val_accuracy: 0.8483\n",
            "Epoch 469/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 1.4163 - val_accuracy: 0.8428\n",
            "Epoch 470/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 1.6953 - val_accuracy: 0.8173\n",
            "Epoch 471/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 1.3032 - val_accuracy: 0.8378\n",
            "Epoch 472/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 1.6223 - val_accuracy: 0.8273\n",
            "Epoch 473/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 1.3341 - val_accuracy: 0.8288\n",
            "Epoch 474/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 1.4418 - val_accuracy: 0.8406\n",
            "Epoch 475/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 1.3703 - val_accuracy: 0.8363\n",
            "Epoch 476/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 1.7179 - val_accuracy: 0.7894\n",
            "Epoch 477/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 1.3579 - val_accuracy: 0.8467\n",
            "Epoch 478/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 1.9537 - val_accuracy: 0.8062\n",
            "Epoch 479/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0233 - accuracy: 0.9918 - val_loss: 2.0433 - val_accuracy: 0.8138\n",
            "Epoch 480/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 1.6720 - val_accuracy: 0.8267\n",
            "Epoch 481/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0292 - accuracy: 0.9897 - val_loss: 1.5202 - val_accuracy: 0.8244\n",
            "Epoch 482/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 1.6659 - val_accuracy: 0.8041\n",
            "Epoch 483/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 1.3960 - val_accuracy: 0.8481\n",
            "Epoch 484/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 1.3895 - val_accuracy: 0.8522\n",
            "Epoch 485/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0294 - accuracy: 0.9892 - val_loss: 2.4102 - val_accuracy: 0.7284\n",
            "Epoch 486/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0265 - accuracy: 0.9898 - val_loss: 2.8699 - val_accuracy: 0.7294\n",
            "Epoch 487/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0256 - accuracy: 0.9898 - val_loss: 1.2097 - val_accuracy: 0.8409\n",
            "Epoch 488/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 1.7278 - val_accuracy: 0.8159\n",
            "Epoch 489/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0262 - accuracy: 0.9904 - val_loss: 1.4511 - val_accuracy: 0.8322\n",
            "Epoch 490/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0257 - accuracy: 0.9905 - val_loss: 1.6351 - val_accuracy: 0.8198\n",
            "Epoch 491/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 2.5951 - val_accuracy: 0.7794\n",
            "Epoch 492/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0330 - accuracy: 0.9883 - val_loss: 1.7429 - val_accuracy: 0.8122\n",
            "Epoch 493/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0229 - accuracy: 0.9909 - val_loss: 2.1527 - val_accuracy: 0.8130\n",
            "Epoch 494/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 1.7767 - val_accuracy: 0.8086\n",
            "Epoch 495/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 1.2552 - val_accuracy: 0.8541\n",
            "Epoch 496/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 1.2057 - val_accuracy: 0.8653\n",
            "Epoch 497/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 1.4712 - val_accuracy: 0.8348\n",
            "Epoch 498/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0229 - accuracy: 0.9914 - val_loss: 1.6776 - val_accuracy: 0.7995\n",
            "Epoch 499/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 1.6015 - val_accuracy: 0.8336\n",
            "Epoch 500/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0285 - accuracy: 0.9895 - val_loss: 1.4428 - val_accuracy: 0.8423\n",
            "Epoch 501/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0277 - accuracy: 0.9898 - val_loss: 1.5756 - val_accuracy: 0.8253\n",
            "Epoch 502/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0280 - accuracy: 0.9895 - val_loss: 1.3798 - val_accuracy: 0.8537\n",
            "Epoch 503/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 1.7784 - val_accuracy: 0.8044\n",
            "Epoch 504/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0282 - accuracy: 0.9900 - val_loss: 1.2773 - val_accuracy: 0.8336\n",
            "Epoch 505/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0302 - accuracy: 0.9891 - val_loss: 1.4504 - val_accuracy: 0.8353\n",
            "Epoch 506/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 1.6115 - val_accuracy: 0.8373\n",
            "Epoch 507/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0248 - accuracy: 0.9910 - val_loss: 1.9356 - val_accuracy: 0.8289\n",
            "Epoch 508/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0232 - accuracy: 0.9916 - val_loss: 1.4507 - val_accuracy: 0.8447\n",
            "Epoch 509/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 1.1568 - val_accuracy: 0.8633\n",
            "Epoch 510/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 1.2371 - val_accuracy: 0.8597\n",
            "Epoch 511/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 2.0644 - val_accuracy: 0.7931\n",
            "Epoch 512/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 1.3955 - val_accuracy: 0.8413\n",
            "Epoch 513/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0252 - accuracy: 0.9905 - val_loss: 1.7400 - val_accuracy: 0.8103\n",
            "Epoch 514/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0243 - accuracy: 0.9912 - val_loss: 1.2837 - val_accuracy: 0.8427\n",
            "Epoch 515/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 1.2485 - val_accuracy: 0.8522\n",
            "Epoch 516/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0305 - accuracy: 0.9896 - val_loss: 1.5734 - val_accuracy: 0.8258\n",
            "Epoch 517/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 1.7336 - val_accuracy: 0.8288\n",
            "Epoch 518/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0252 - accuracy: 0.9907 - val_loss: 1.6421 - val_accuracy: 0.8302\n",
            "Epoch 519/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 1.8086 - val_accuracy: 0.8200\n",
            "Epoch 520/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0206 - accuracy: 0.9930 - val_loss: 1.3485 - val_accuracy: 0.8550\n",
            "Epoch 521/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 1.3864 - val_accuracy: 0.8534\n",
            "Epoch 522/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 1.7761 - val_accuracy: 0.8214\n",
            "Epoch 523/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 2.1880 - val_accuracy: 0.7738\n",
            "Epoch 524/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0218 - accuracy: 0.9924 - val_loss: 1.4029 - val_accuracy: 0.8475\n",
            "Epoch 525/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0252 - accuracy: 0.9910 - val_loss: 1.8651 - val_accuracy: 0.8236\n",
            "Epoch 526/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0219 - accuracy: 0.9918 - val_loss: 1.5101 - val_accuracy: 0.8433\n",
            "Epoch 527/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 1.5959 - val_accuracy: 0.8238\n",
            "Epoch 528/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 1.3187 - val_accuracy: 0.8462\n",
            "Epoch 529/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0274 - accuracy: 0.9902 - val_loss: 2.1064 - val_accuracy: 0.8192\n",
            "Epoch 530/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0291 - accuracy: 0.9900 - val_loss: 1.5952 - val_accuracy: 0.8236\n",
            "Epoch 531/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 1.9799 - val_accuracy: 0.7927\n",
            "Epoch 532/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 1.4350 - val_accuracy: 0.8281\n",
            "Epoch 533/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0192 - accuracy: 0.9930 - val_loss: 2.0556 - val_accuracy: 0.7984\n",
            "Epoch 534/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 1.4461 - val_accuracy: 0.8347\n",
            "Epoch 535/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 1.4515 - val_accuracy: 0.8462\n",
            "Epoch 536/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 1.8763 - val_accuracy: 0.8202\n",
            "Epoch 537/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 1.7121 - val_accuracy: 0.8373\n",
            "Epoch 538/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 1.4772 - val_accuracy: 0.8392\n",
            "Epoch 539/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 1.8424 - val_accuracy: 0.8062\n",
            "Epoch 540/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 1.9751 - val_accuracy: 0.8261\n",
            "Epoch 541/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0291 - accuracy: 0.9901 - val_loss: 1.7171 - val_accuracy: 0.8244\n",
            "Epoch 542/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0341 - accuracy: 0.9875 - val_loss: 1.3780 - val_accuracy: 0.8428\n",
            "Epoch 543/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0298 - accuracy: 0.9889 - val_loss: 2.9888 - val_accuracy: 0.7659\n",
            "Epoch 544/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0338 - accuracy: 0.9877 - val_loss: 1.6751 - val_accuracy: 0.8219\n",
            "Epoch 545/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 2.2924 - val_accuracy: 0.7720\n",
            "Epoch 546/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0223 - accuracy: 0.9912 - val_loss: 1.6704 - val_accuracy: 0.8070\n",
            "Epoch 547/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0232 - accuracy: 0.9916 - val_loss: 1.4090 - val_accuracy: 0.8425\n",
            "Epoch 548/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 1.2807 - val_accuracy: 0.8448\n",
            "Epoch 549/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 1.3610 - val_accuracy: 0.8509\n",
            "Epoch 550/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0228 - accuracy: 0.9918 - val_loss: 1.5640 - val_accuracy: 0.8328\n",
            "Epoch 551/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0213 - accuracy: 0.9923 - val_loss: 1.7045 - val_accuracy: 0.8214\n",
            "Epoch 552/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 1.3708 - val_accuracy: 0.8327\n",
            "Epoch 553/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 1.5264 - val_accuracy: 0.8333\n",
            "Epoch 554/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 1.3229 - val_accuracy: 0.8555\n",
            "Epoch 555/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 1.4376 - val_accuracy: 0.8330\n",
            "Epoch 556/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0193 - accuracy: 0.9927 - val_loss: 1.4567 - val_accuracy: 0.8413\n",
            "Epoch 557/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 1.8043 - val_accuracy: 0.8298\n",
            "Epoch 558/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 2.0797 - val_accuracy: 0.7880\n",
            "Epoch 559/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 1.4569 - val_accuracy: 0.8389\n",
            "Epoch 560/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0205 - accuracy: 0.9925 - val_loss: 1.4238 - val_accuracy: 0.8452\n",
            "Epoch 561/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0271 - accuracy: 0.9889 - val_loss: 1.4970 - val_accuracy: 0.8447\n",
            "Epoch 562/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 1.3413 - val_accuracy: 0.8436\n",
            "Epoch 563/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 1.6444 - val_accuracy: 0.8280\n",
            "Epoch 564/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0184 - accuracy: 0.9928 - val_loss: 1.7596 - val_accuracy: 0.8238\n",
            "Epoch 565/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0222 - accuracy: 0.9934 - val_loss: 1.6810 - val_accuracy: 0.8327\n",
            "Epoch 566/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0214 - accuracy: 0.9920 - val_loss: 1.1952 - val_accuracy: 0.8548\n",
            "Epoch 567/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 1.4053 - val_accuracy: 0.8423\n",
            "Epoch 568/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0183 - accuracy: 0.9935 - val_loss: 1.6998 - val_accuracy: 0.8356\n",
            "Epoch 569/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 1.4218 - val_accuracy: 0.8478\n",
            "Epoch 570/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 1.6707 - val_accuracy: 0.8292\n",
            "Epoch 571/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 1.6651 - val_accuracy: 0.8439\n",
            "Epoch 572/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 1.4683 - val_accuracy: 0.8475\n",
            "Epoch 573/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0214 - accuracy: 0.9917 - val_loss: 1.7234 - val_accuracy: 0.8347\n",
            "Epoch 574/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 1.8646 - val_accuracy: 0.7998\n",
            "Epoch 575/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 1.6307 - val_accuracy: 0.8216\n",
            "Epoch 576/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 1.5832 - val_accuracy: 0.8275\n",
            "Epoch 577/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 1.6744 - val_accuracy: 0.8195\n",
            "Epoch 578/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 1.6847 - val_accuracy: 0.8067\n",
            "Epoch 579/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 1.3469 - val_accuracy: 0.8406\n",
            "Epoch 580/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0202 - accuracy: 0.9927 - val_loss: 1.5329 - val_accuracy: 0.8358\n",
            "Epoch 581/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 1.5141 - val_accuracy: 0.8281\n",
            "Epoch 582/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9912 - val_loss: 1.5895 - val_accuracy: 0.8427\n",
            "Epoch 583/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 1.5349 - val_accuracy: 0.8400\n",
            "Epoch 584/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 1.4180 - val_accuracy: 0.8548\n",
            "Epoch 585/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0231 - accuracy: 0.9919 - val_loss: 1.7127 - val_accuracy: 0.8452\n",
            "Epoch 586/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0197 - accuracy: 0.9922 - val_loss: 1.3432 - val_accuracy: 0.8464\n",
            "Epoch 587/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0197 - accuracy: 0.9922 - val_loss: 1.3014 - val_accuracy: 0.8530\n",
            "Epoch 588/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 1.7884 - val_accuracy: 0.8234\n",
            "Epoch 589/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.5065 - val_accuracy: 0.8197\n",
            "Epoch 590/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 1.3528 - val_accuracy: 0.8514\n",
            "Epoch 591/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 1.5631 - val_accuracy: 0.8244\n",
            "Epoch 592/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0187 - accuracy: 0.9930 - val_loss: 1.9056 - val_accuracy: 0.8175\n",
            "Epoch 593/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0275 - accuracy: 0.9898 - val_loss: 2.0277 - val_accuracy: 0.8077\n",
            "Epoch 594/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 1.9066 - val_accuracy: 0.8191\n",
            "Epoch 595/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0193 - accuracy: 0.9930 - val_loss: 1.4973 - val_accuracy: 0.8347\n",
            "Epoch 596/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0202 - accuracy: 0.9921 - val_loss: 1.5187 - val_accuracy: 0.8403\n",
            "Epoch 597/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0229 - accuracy: 0.9914 - val_loss: 1.4480 - val_accuracy: 0.8431\n",
            "Epoch 598/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 1.6593 - val_accuracy: 0.8453\n",
            "Epoch 599/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 1.6125 - val_accuracy: 0.8458\n",
            "Epoch 600/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0226 - accuracy: 0.9919 - val_loss: 1.6539 - val_accuracy: 0.8466\n",
            "Epoch 601/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0268 - accuracy: 0.9894 - val_loss: 1.5467 - val_accuracy: 0.8281\n",
            "Epoch 602/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 1.7192 - val_accuracy: 0.8322\n",
            "Epoch 603/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 1.6592 - val_accuracy: 0.8289\n",
            "Epoch 604/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9937 - val_loss: 1.7117 - val_accuracy: 0.8358\n",
            "Epoch 605/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0197 - accuracy: 0.9925 - val_loss: 1.6424 - val_accuracy: 0.8327\n",
            "Epoch 606/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0207 - accuracy: 0.9920 - val_loss: 1.5835 - val_accuracy: 0.8342\n",
            "Epoch 607/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 1.5308 - val_accuracy: 0.8378\n",
            "Epoch 608/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 1.8979 - val_accuracy: 0.8248\n",
            "Epoch 609/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 2.3008 - val_accuracy: 0.7891\n",
            "Epoch 610/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 2.0000 - val_accuracy: 0.8131\n",
            "Epoch 611/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 1.7936 - val_accuracy: 0.8161\n",
            "Epoch 612/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0253 - accuracy: 0.9910 - val_loss: 1.8816 - val_accuracy: 0.8016\n",
            "Epoch 613/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0161 - accuracy: 0.9937 - val_loss: 2.1319 - val_accuracy: 0.8027\n",
            "Epoch 614/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0189 - accuracy: 0.9935 - val_loss: 2.4919 - val_accuracy: 0.7800\n",
            "Epoch 615/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0280 - accuracy: 0.9898 - val_loss: 2.2480 - val_accuracy: 0.7795\n",
            "Epoch 616/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 1.5953 - val_accuracy: 0.8166\n",
            "Epoch 617/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0234 - accuracy: 0.9914 - val_loss: 1.6271 - val_accuracy: 0.8300\n",
            "Epoch 618/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 1.5638 - val_accuracy: 0.8317\n",
            "Epoch 619/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 1.8949 - val_accuracy: 0.8208\n",
            "Epoch 620/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.9924 - val_loss: 2.0674 - val_accuracy: 0.8250\n",
            "Epoch 621/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 1.4509 - val_accuracy: 0.8459\n",
            "Epoch 622/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0167 - accuracy: 0.9941 - val_loss: 1.6403 - val_accuracy: 0.8170\n",
            "Epoch 623/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 1.5286 - val_accuracy: 0.8219\n",
            "Epoch 624/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 1.6760 - val_accuracy: 0.8320\n",
            "Epoch 625/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 1.4697 - val_accuracy: 0.8417\n",
            "Epoch 626/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 1.8282 - val_accuracy: 0.8281\n",
            "Epoch 627/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0198 - accuracy: 0.9926 - val_loss: 1.9753 - val_accuracy: 0.8014\n",
            "Epoch 628/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 1.7950 - val_accuracy: 0.8152\n",
            "Epoch 629/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0283 - accuracy: 0.9892 - val_loss: 2.6080 - val_accuracy: 0.7994\n",
            "Epoch 630/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0283 - accuracy: 0.9899 - val_loss: 1.5073 - val_accuracy: 0.8411\n",
            "Epoch 631/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 2.1828 - val_accuracy: 0.8070\n",
            "Epoch 632/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 2.0695 - val_accuracy: 0.8045\n",
            "Epoch 633/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 1.8789 - val_accuracy: 0.8203\n",
            "Epoch 634/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0231 - accuracy: 0.9912 - val_loss: 1.5854 - val_accuracy: 0.8447\n",
            "Epoch 635/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 1.8818 - val_accuracy: 0.8370\n",
            "Epoch 636/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 1.4009 - val_accuracy: 0.8536\n",
            "Epoch 637/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 1.9174 - val_accuracy: 0.8264\n",
            "Epoch 638/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 1.8697 - val_accuracy: 0.8236\n",
            "Epoch 639/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 1.8303 - val_accuracy: 0.8073\n",
            "Epoch 640/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 1.6662 - val_accuracy: 0.8350\n",
            "Epoch 641/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0201 - accuracy: 0.9915 - val_loss: 1.5519 - val_accuracy: 0.8303\n",
            "Epoch 642/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 2.0971 - val_accuracy: 0.8122\n",
            "Epoch 643/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 1.6818 - val_accuracy: 0.8531\n",
            "Epoch 644/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0119 - accuracy: 0.9952 - val_loss: 1.5338 - val_accuracy: 0.8356\n",
            "Epoch 645/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 1.8977 - val_accuracy: 0.8223\n",
            "Epoch 646/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 1.9895 - val_accuracy: 0.8123\n",
            "Epoch 647/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 1.8726 - val_accuracy: 0.8223\n",
            "Epoch 648/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0217 - accuracy: 0.9917 - val_loss: 2.0980 - val_accuracy: 0.8227\n",
            "Epoch 649/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0199 - accuracy: 0.9926 - val_loss: 1.6440 - val_accuracy: 0.8369\n",
            "Epoch 650/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 1.5474 - val_accuracy: 0.8431\n",
            "Epoch 651/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 1.6416 - val_accuracy: 0.8420\n",
            "Epoch 652/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 2.2668 - val_accuracy: 0.8231\n",
            "Epoch 653/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0215 - accuracy: 0.9916 - val_loss: 1.8932 - val_accuracy: 0.8381\n",
            "Epoch 654/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 1.7666 - val_accuracy: 0.8319\n",
            "Epoch 655/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 2.2286 - val_accuracy: 0.8142\n",
            "Epoch 656/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 1.8378 - val_accuracy: 0.8420\n",
            "Epoch 657/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 1.8060 - val_accuracy: 0.8455\n",
            "Epoch 658/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 1.8332 - val_accuracy: 0.8388\n",
            "Epoch 659/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0207 - accuracy: 0.9920 - val_loss: 2.2131 - val_accuracy: 0.8125\n",
            "Epoch 660/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0265 - accuracy: 0.9903 - val_loss: 2.2910 - val_accuracy: 0.8028\n",
            "Epoch 661/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 1.9318 - val_accuracy: 0.8161\n",
            "Epoch 662/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 2.8396 - val_accuracy: 0.7603\n",
            "Epoch 663/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 1.5787 - val_accuracy: 0.8377\n",
            "Epoch 664/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 1.6005 - val_accuracy: 0.8195\n",
            "Epoch 665/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 1.6591 - val_accuracy: 0.8077\n",
            "Epoch 666/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 1.4718 - val_accuracy: 0.8414\n",
            "Epoch 667/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 1.8869 - val_accuracy: 0.8278\n",
            "Epoch 668/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 1.6466 - val_accuracy: 0.8086\n",
            "Epoch 669/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 2.2246 - val_accuracy: 0.8042\n",
            "Epoch 670/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0210 - accuracy: 0.9935 - val_loss: 1.5663 - val_accuracy: 0.8209\n",
            "Epoch 671/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 1.8329 - val_accuracy: 0.8269\n",
            "Epoch 672/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0199 - accuracy: 0.9923 - val_loss: 1.6092 - val_accuracy: 0.8342\n",
            "Epoch 673/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 2.4882 - val_accuracy: 0.7841\n",
            "Epoch 674/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0195 - accuracy: 0.9929 - val_loss: 1.6189 - val_accuracy: 0.8363\n",
            "Epoch 675/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 1.8548 - val_accuracy: 0.8425\n",
            "Epoch 676/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9936 - val_loss: 1.8435 - val_accuracy: 0.8333\n",
            "Epoch 677/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 1.8723 - val_accuracy: 0.8345\n",
            "Epoch 678/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 1.6993 - val_accuracy: 0.8250\n",
            "Epoch 679/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 2.0314 - val_accuracy: 0.7991\n",
            "Epoch 680/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 1.8697 - val_accuracy: 0.8294\n",
            "Epoch 681/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 2.0535 - val_accuracy: 0.7936\n",
            "Epoch 682/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0234 - accuracy: 0.9919 - val_loss: 1.5897 - val_accuracy: 0.8300\n",
            "Epoch 683/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0214 - accuracy: 0.9915 - val_loss: 1.6246 - val_accuracy: 0.8052\n",
            "Epoch 684/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 1.7009 - val_accuracy: 0.8148\n",
            "Epoch 685/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 1.5968 - val_accuracy: 0.8555\n",
            "Epoch 686/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 1.8004 - val_accuracy: 0.8414\n",
            "Epoch 687/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 1.6542 - val_accuracy: 0.8527\n",
            "Epoch 688/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 2.7374 - val_accuracy: 0.8081\n",
            "Epoch 689/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0193 - accuracy: 0.9931 - val_loss: 1.8974 - val_accuracy: 0.8514\n",
            "Epoch 690/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0144 - accuracy: 0.9943 - val_loss: 2.4010 - val_accuracy: 0.7936\n",
            "Epoch 691/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 1.6914 - val_accuracy: 0.8380\n",
            "Epoch 692/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 1.7755 - val_accuracy: 0.8431\n",
            "Epoch 693/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 1.7199 - val_accuracy: 0.8025\n",
            "Epoch 694/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0243 - accuracy: 0.9912 - val_loss: 2.0568 - val_accuracy: 0.8102\n",
            "Epoch 695/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 1.9754 - val_accuracy: 0.8158\n",
            "Epoch 696/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0178 - accuracy: 0.9934 - val_loss: 1.5545 - val_accuracy: 0.8339\n",
            "Epoch 697/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 2.0034 - val_accuracy: 0.8134\n",
            "Epoch 698/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 1.6812 - val_accuracy: 0.8333\n",
            "Epoch 699/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 1.6943 - val_accuracy: 0.8420\n",
            "Epoch 700/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 2.0346 - val_accuracy: 0.8383\n",
            "Epoch 701/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 1.4796 - val_accuracy: 0.8509\n",
            "Epoch 702/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 1.8702 - val_accuracy: 0.8252\n",
            "Epoch 703/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 1.7739 - val_accuracy: 0.8438\n",
            "Epoch 704/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 2.4479 - val_accuracy: 0.7709\n",
            "Epoch 705/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 1.6141 - val_accuracy: 0.8298\n",
            "Epoch 706/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0133 - accuracy: 0.9948 - val_loss: 1.6437 - val_accuracy: 0.8245\n",
            "Epoch 707/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 2.2309 - val_accuracy: 0.8138\n",
            "Epoch 708/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 2.5304 - val_accuracy: 0.7809\n",
            "Epoch 709/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0285 - accuracy: 0.9902 - val_loss: 2.4437 - val_accuracy: 0.7866\n",
            "Epoch 710/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0293 - accuracy: 0.9890 - val_loss: 2.4991 - val_accuracy: 0.8095\n",
            "Epoch 711/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 1.8794 - val_accuracy: 0.8480\n",
            "Epoch 712/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 2.3167 - val_accuracy: 0.7948\n",
            "Epoch 713/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 3.0573 - val_accuracy: 0.7862\n",
            "Epoch 714/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 1.9502 - val_accuracy: 0.8367\n",
            "Epoch 715/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 2.6857 - val_accuracy: 0.8012\n",
            "Epoch 716/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 2.0180 - val_accuracy: 0.8444\n",
            "Epoch 717/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 1.6650 - val_accuracy: 0.8481\n",
            "Epoch 718/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 2.1317 - val_accuracy: 0.8081\n",
            "Epoch 719/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 1.5111 - val_accuracy: 0.8547\n",
            "Epoch 720/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 1.5675 - val_accuracy: 0.8364\n",
            "Epoch 721/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 1.7739 - val_accuracy: 0.8377\n",
            "Epoch 722/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 1.7123 - val_accuracy: 0.8406\n",
            "Epoch 723/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 1.5230 - val_accuracy: 0.8230\n",
            "Epoch 724/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 1.6730 - val_accuracy: 0.8236\n",
            "Epoch 725/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 1.3416 - val_accuracy: 0.8523\n",
            "Epoch 726/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9948 - val_loss: 1.7532 - val_accuracy: 0.8347\n",
            "Epoch 727/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 2.2610 - val_accuracy: 0.8244\n",
            "Epoch 728/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 2.0148 - val_accuracy: 0.8384\n",
            "Epoch 729/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 1.7570 - val_accuracy: 0.8467\n",
            "Epoch 730/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 1.7878 - val_accuracy: 0.8364\n",
            "Epoch 731/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 2.0832 - val_accuracy: 0.8191\n",
            "Epoch 732/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0278 - accuracy: 0.9895 - val_loss: 2.6920 - val_accuracy: 0.7744\n",
            "Epoch 733/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0296 - accuracy: 0.9899 - val_loss: 2.2699 - val_accuracy: 0.8037\n",
            "Epoch 734/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0189 - accuracy: 0.9932 - val_loss: 2.1432 - val_accuracy: 0.8159\n",
            "Epoch 735/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 2.0775 - val_accuracy: 0.8200\n",
            "Epoch 736/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 1.8264 - val_accuracy: 0.8341\n",
            "Epoch 737/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 1.6163 - val_accuracy: 0.8341\n",
            "Epoch 738/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 1.5488 - val_accuracy: 0.8544\n",
            "Epoch 739/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 1.5219 - val_accuracy: 0.8547\n",
            "Epoch 740/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 2.2246 - val_accuracy: 0.8042\n",
            "Epoch 741/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 2.2804 - val_accuracy: 0.8056\n",
            "Epoch 742/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0254 - accuracy: 0.9922 - val_loss: 2.6003 - val_accuracy: 0.7848\n",
            "Epoch 743/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 2.0228 - val_accuracy: 0.8120\n",
            "Epoch 744/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0262 - accuracy: 0.9899 - val_loss: 1.6903 - val_accuracy: 0.8177\n",
            "Epoch 745/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 1.7235 - val_accuracy: 0.8197\n",
            "Epoch 746/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0198 - accuracy: 0.9921 - val_loss: 1.7303 - val_accuracy: 0.8430\n",
            "Epoch 747/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0186 - accuracy: 0.9934 - val_loss: 2.6421 - val_accuracy: 0.8142\n",
            "Epoch 748/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 1.9286 - val_accuracy: 0.8178\n",
            "Epoch 749/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 1.8370 - val_accuracy: 0.8336\n",
            "Epoch 750/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 2.0831 - val_accuracy: 0.8283\n",
            "Epoch 751/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0162 - accuracy: 0.9937 - val_loss: 1.7327 - val_accuracy: 0.8436\n",
            "Epoch 752/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 1.7886 - val_accuracy: 0.8464\n",
            "Epoch 753/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 1.7517 - val_accuracy: 0.8467\n",
            "Epoch 754/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.4114 - val_accuracy: 0.8478\n",
            "Epoch 755/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.7536 - val_accuracy: 0.8348\n",
            "Epoch 756/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 1.7648 - val_accuracy: 0.8336\n",
            "Epoch 757/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 1.7375 - val_accuracy: 0.8414\n",
            "Epoch 758/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 1.7237 - val_accuracy: 0.8514\n",
            "Epoch 759/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 1.9743 - val_accuracy: 0.8328\n",
            "Epoch 760/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 2.1086 - val_accuracy: 0.8227\n",
            "Epoch 761/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0212 - accuracy: 0.9925 - val_loss: 2.4654 - val_accuracy: 0.8028\n",
            "Epoch 762/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0285 - accuracy: 0.9903 - val_loss: 1.9308 - val_accuracy: 0.8300\n",
            "Epoch 763/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9936 - val_loss: 2.0906 - val_accuracy: 0.8308\n",
            "Epoch 764/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 1.5678 - val_accuracy: 0.8448\n",
            "Epoch 765/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9950 - val_loss: 1.4909 - val_accuracy: 0.8509\n",
            "Epoch 766/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 3.0998 - val_accuracy: 0.7264\n",
            "Epoch 767/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0256 - accuracy: 0.9904 - val_loss: 2.1193 - val_accuracy: 0.8070\n",
            "Epoch 768/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 1.6760 - val_accuracy: 0.8348\n",
            "Epoch 769/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0167 - accuracy: 0.9941 - val_loss: 1.5865 - val_accuracy: 0.8445\n",
            "Epoch 770/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 1.8810 - val_accuracy: 0.8241\n",
            "Epoch 771/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 2.1598 - val_accuracy: 0.8105\n",
            "Epoch 772/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 1.5484 - val_accuracy: 0.8586\n",
            "Epoch 773/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 1.6575 - val_accuracy: 0.8388\n",
            "Epoch 774/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.6400 - val_accuracy: 0.8509\n",
            "Epoch 775/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 1.9671 - val_accuracy: 0.8300\n",
            "Epoch 776/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 1.5291 - val_accuracy: 0.8456\n",
            "Epoch 777/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 1.7628 - val_accuracy: 0.8363\n",
            "Epoch 778/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 1.5627 - val_accuracy: 0.8487\n",
            "Epoch 779/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 2.0223 - val_accuracy: 0.8142\n",
            "Epoch 780/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 1.7726 - val_accuracy: 0.8186\n",
            "Epoch 781/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 3.8598 - val_accuracy: 0.7462\n",
            "Epoch 782/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 1.6521 - val_accuracy: 0.8386\n",
            "Epoch 783/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 2.5275 - val_accuracy: 0.7998\n",
            "Epoch 784/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 2.0437 - val_accuracy: 0.8058\n",
            "Epoch 785/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 1.7562 - val_accuracy: 0.8288\n",
            "Epoch 786/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 1.5900 - val_accuracy: 0.8358\n",
            "Epoch 787/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 2.1554 - val_accuracy: 0.8125\n",
            "Epoch 788/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0186 - accuracy: 0.9930 - val_loss: 2.3637 - val_accuracy: 0.8270\n",
            "Epoch 789/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0206 - accuracy: 0.9923 - val_loss: 2.0798 - val_accuracy: 0.8222\n",
            "Epoch 790/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0194 - accuracy: 0.9927 - val_loss: 2.0418 - val_accuracy: 0.8178\n",
            "Epoch 791/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 1.8288 - val_accuracy: 0.8370\n",
            "Epoch 792/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0166 - accuracy: 0.9941 - val_loss: 1.4871 - val_accuracy: 0.8370\n",
            "Epoch 793/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 1.3979 - val_accuracy: 0.8453\n",
            "Epoch 794/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 1.8940 - val_accuracy: 0.8366\n",
            "Epoch 795/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 1.6567 - val_accuracy: 0.8328\n",
            "Epoch 796/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 1.9565 - val_accuracy: 0.8258\n",
            "Epoch 797/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 1.8801 - val_accuracy: 0.8392\n",
            "Epoch 798/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 1.9100 - val_accuracy: 0.8292\n",
            "Epoch 799/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 2.0094 - val_accuracy: 0.8305\n",
            "Epoch 800/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 2.2348 - val_accuracy: 0.8164\n",
            "Epoch 801/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 1.6823 - val_accuracy: 0.8517\n",
            "Epoch 802/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 1.5220 - val_accuracy: 0.8534\n",
            "Epoch 803/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 1.7434 - val_accuracy: 0.8397\n",
            "Epoch 804/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.4660 - val_accuracy: 0.8617\n",
            "Epoch 805/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 1.3917 - val_accuracy: 0.8527\n",
            "Epoch 806/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 1.6007 - val_accuracy: 0.8327\n",
            "Epoch 807/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 2.1726 - val_accuracy: 0.7870\n",
            "Epoch 808/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 2.7322 - val_accuracy: 0.7842\n",
            "Epoch 809/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0215 - accuracy: 0.9923 - val_loss: 2.7342 - val_accuracy: 0.8095\n",
            "Epoch 810/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0188 - accuracy: 0.9932 - val_loss: 2.3916 - val_accuracy: 0.7973\n",
            "Epoch 811/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 2.1937 - val_accuracy: 0.7994\n",
            "Epoch 812/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 1.9101 - val_accuracy: 0.8186\n",
            "Epoch 813/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 1.6878 - val_accuracy: 0.8395\n",
            "Epoch 814/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 0.9948 - val_loss: 1.4355 - val_accuracy: 0.8600\n",
            "Epoch 815/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 1.5605 - val_accuracy: 0.8550\n",
            "Epoch 816/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0139 - accuracy: 0.9948 - val_loss: 1.9860 - val_accuracy: 0.8459\n",
            "Epoch 817/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 1.8406 - val_accuracy: 0.8441\n",
            "Epoch 818/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 1.8373 - val_accuracy: 0.8419\n",
            "Epoch 819/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 1.9456 - val_accuracy: 0.8433\n",
            "Epoch 820/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 2.0675 - val_accuracy: 0.8400\n",
            "Epoch 821/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 2.0900 - val_accuracy: 0.8303\n",
            "Epoch 822/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.7683 - val_accuracy: 0.8456\n",
            "Epoch 823/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 1.6702 - val_accuracy: 0.8464\n",
            "Epoch 824/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 1.5604 - val_accuracy: 0.8480\n",
            "Epoch 825/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 1.9923 - val_accuracy: 0.8164\n",
            "Epoch 826/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 1.6520 - val_accuracy: 0.8486\n",
            "Epoch 827/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 1.8587 - val_accuracy: 0.8370\n",
            "Epoch 828/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 1.5144 - val_accuracy: 0.8584\n",
            "Epoch 829/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.6240 - val_accuracy: 0.8314\n",
            "Epoch 830/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 1.9674 - val_accuracy: 0.8172\n",
            "Epoch 831/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 2.2298 - val_accuracy: 0.8311\n",
            "Epoch 832/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 2.3153 - val_accuracy: 0.8195\n",
            "Epoch 833/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 2.0680 - val_accuracy: 0.7959\n",
            "Epoch 834/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 1.4089 - val_accuracy: 0.8514\n",
            "Epoch 835/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 1.4760 - val_accuracy: 0.8587\n",
            "Epoch 836/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 1.6021 - val_accuracy: 0.8520\n",
            "Epoch 837/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.7754 - val_accuracy: 0.8314\n",
            "Epoch 838/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 1.4974 - val_accuracy: 0.8472\n",
            "Epoch 839/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 1.7685 - val_accuracy: 0.8403\n",
            "Epoch 840/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 1.5412 - val_accuracy: 0.8458\n",
            "Epoch 841/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 1.6533 - val_accuracy: 0.8458\n",
            "Epoch 842/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 1.7788 - val_accuracy: 0.8316\n",
            "Epoch 843/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0233 - accuracy: 0.9916 - val_loss: 4.9244 - val_accuracy: 0.6848\n",
            "Epoch 844/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 3.4099 - val_accuracy: 0.7647\n",
            "Epoch 845/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0221 - accuracy: 0.9916 - val_loss: 3.1883 - val_accuracy: 0.7809\n",
            "Epoch 846/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 2.2407 - val_accuracy: 0.8306\n",
            "Epoch 847/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 2.1152 - val_accuracy: 0.8403\n",
            "Epoch 848/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0183 - accuracy: 0.9935 - val_loss: 1.5396 - val_accuracy: 0.8480\n",
            "Epoch 849/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 1.9621 - val_accuracy: 0.8289\n",
            "Epoch 850/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0168 - accuracy: 0.9941 - val_loss: 1.7509 - val_accuracy: 0.8464\n",
            "Epoch 851/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 2.0155 - val_accuracy: 0.8236\n",
            "Epoch 852/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 1.6670 - val_accuracy: 0.8594\n",
            "Epoch 853/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 1.5559 - val_accuracy: 0.8625\n",
            "Epoch 854/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 1.4038 - val_accuracy: 0.8528\n",
            "Epoch 855/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.7111 - val_accuracy: 0.8353\n",
            "Epoch 856/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 1.7828 - val_accuracy: 0.8258\n",
            "Epoch 857/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 1.8641 - val_accuracy: 0.8206\n",
            "Epoch 858/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 1.9005 - val_accuracy: 0.8428\n",
            "Epoch 859/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 1.7691 - val_accuracy: 0.8308\n",
            "Epoch 860/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 1.7620 - val_accuracy: 0.8395\n",
            "Epoch 861/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 1.9233 - val_accuracy: 0.8377\n",
            "Epoch 862/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 1.4963 - val_accuracy: 0.8541\n",
            "Epoch 863/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 2.0354 - val_accuracy: 0.8206\n",
            "Epoch 864/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 1.8206 - val_accuracy: 0.8258\n",
            "Epoch 865/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 1.7170 - val_accuracy: 0.8344\n",
            "Epoch 866/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 2.8869 - val_accuracy: 0.8052\n",
            "Epoch 867/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 1.8239 - val_accuracy: 0.8391\n",
            "Epoch 868/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 2.3785 - val_accuracy: 0.8005\n",
            "Epoch 869/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.7728 - val_accuracy: 0.8467\n",
            "Epoch 870/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 1.8273 - val_accuracy: 0.8406\n",
            "Epoch 871/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 1.8673 - val_accuracy: 0.8188\n",
            "Epoch 872/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 1.9023 - val_accuracy: 0.8338\n",
            "Epoch 873/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 1.8779 - val_accuracy: 0.8373\n",
            "Epoch 874/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 1.7406 - val_accuracy: 0.8366\n",
            "Epoch 875/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 1.8914 - val_accuracy: 0.8470\n",
            "Epoch 876/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 2.4852 - val_accuracy: 0.7980\n",
            "Epoch 877/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 3.1686 - val_accuracy: 0.7859\n",
            "Epoch 878/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 2.3709 - val_accuracy: 0.8092\n",
            "Epoch 879/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0170 - accuracy: 0.9935 - val_loss: 2.0096 - val_accuracy: 0.8336\n",
            "Epoch 880/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9937 - val_loss: 2.3675 - val_accuracy: 0.7881\n",
            "Epoch 881/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 2.2313 - val_accuracy: 0.8194\n",
            "Epoch 882/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 1.9929 - val_accuracy: 0.8448\n",
            "Epoch 883/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 1.7901 - val_accuracy: 0.8453\n",
            "Epoch 884/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 2.2182 - val_accuracy: 0.8095\n",
            "Epoch 885/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 1.7100 - val_accuracy: 0.8413\n",
            "Epoch 886/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 1.5077 - val_accuracy: 0.8500\n",
            "Epoch 887/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.7240 - val_accuracy: 0.8416\n",
            "Epoch 888/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 1.7358 - val_accuracy: 0.8525\n",
            "Epoch 889/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 1.6791 - val_accuracy: 0.8445\n",
            "Epoch 890/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.5506 - val_accuracy: 0.8575\n",
            "Epoch 891/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 1.5722 - val_accuracy: 0.8623\n",
            "Epoch 892/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 1.6324 - val_accuracy: 0.8537\n",
            "Epoch 893/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 1.5769 - val_accuracy: 0.8520\n",
            "Epoch 894/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 1.8213 - val_accuracy: 0.8366\n",
            "Epoch 895/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 1.6879 - val_accuracy: 0.8261\n",
            "Epoch 896/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 1.8246 - val_accuracy: 0.8338\n",
            "Epoch 897/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 2.2631 - val_accuracy: 0.8155\n",
            "Epoch 898/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 1.6919 - val_accuracy: 0.8467\n",
            "Epoch 899/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0176 - accuracy: 0.9935 - val_loss: 2.6355 - val_accuracy: 0.7505\n",
            "Epoch 900/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 1.7879 - val_accuracy: 0.8347\n",
            "Epoch 901/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0130 - accuracy: 0.9952 - val_loss: 1.6310 - val_accuracy: 0.8547\n",
            "Epoch 902/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 1.7118 - val_accuracy: 0.8494\n",
            "Epoch 903/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.8762 - val_accuracy: 0.8491\n",
            "Epoch 904/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 1.6335 - val_accuracy: 0.8447\n",
            "Epoch 905/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0119 - accuracy: 0.9949 - val_loss: 1.6351 - val_accuracy: 0.8413\n",
            "Epoch 906/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 2.1625 - val_accuracy: 0.8347\n",
            "Epoch 907/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 2.2718 - val_accuracy: 0.8148\n",
            "Epoch 908/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 1.9755 - val_accuracy: 0.8481\n",
            "Epoch 909/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 1.8042 - val_accuracy: 0.8462\n",
            "Epoch 910/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 1.6901 - val_accuracy: 0.8606\n",
            "Epoch 911/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 2.0063 - val_accuracy: 0.8452\n",
            "Epoch 912/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 1.6920 - val_accuracy: 0.8520\n",
            "Epoch 913/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 1.9569 - val_accuracy: 0.8272\n",
            "Epoch 914/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 2.0682 - val_accuracy: 0.8358\n",
            "Epoch 915/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 2.1302 - val_accuracy: 0.8314\n",
            "Epoch 916/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 2.2639 - val_accuracy: 0.8286\n",
            "Epoch 917/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 1.7739 - val_accuracy: 0.8498\n",
            "Epoch 918/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 2.1589 - val_accuracy: 0.8086\n",
            "Epoch 919/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 1.8337 - val_accuracy: 0.8436\n",
            "Epoch 920/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 2.2851 - val_accuracy: 0.8181\n",
            "Epoch 921/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 1.7407 - val_accuracy: 0.8478\n",
            "Epoch 922/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 1.9120 - val_accuracy: 0.8284\n",
            "Epoch 923/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 2.2735 - val_accuracy: 0.8334\n",
            "Epoch 924/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 2.7154 - val_accuracy: 0.8028\n",
            "Epoch 925/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 2.3266 - val_accuracy: 0.8125\n",
            "Epoch 926/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9938 - val_loss: 1.7088 - val_accuracy: 0.8461\n",
            "Epoch 927/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 2.0159 - val_accuracy: 0.8361\n",
            "Epoch 928/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 1.8512 - val_accuracy: 0.8455\n",
            "Epoch 929/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.9934 - val_accuracy: 0.8353\n",
            "Epoch 930/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 1.6937 - val_accuracy: 0.8416\n",
            "Epoch 931/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 1.5550 - val_accuracy: 0.8500\n",
            "Epoch 932/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.7364 - val_accuracy: 0.8428\n",
            "Epoch 933/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 1.7213 - val_accuracy: 0.8614\n",
            "Epoch 934/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 1.5891 - val_accuracy: 0.8466\n",
            "Epoch 935/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 1.6743 - val_accuracy: 0.8534\n",
            "Epoch 936/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9945 - val_loss: 2.3710 - val_accuracy: 0.8136\n",
            "Epoch 937/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 2.0840 - val_accuracy: 0.8300\n",
            "Epoch 938/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.9262 - val_accuracy: 0.8386\n",
            "Epoch 939/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 2.1142 - val_accuracy: 0.8269\n",
            "Epoch 940/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 1.7395 - val_accuracy: 0.8409\n",
            "Epoch 941/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.7864 - val_accuracy: 0.8350\n",
            "Epoch 942/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 2.0049 - val_accuracy: 0.8052\n",
            "Epoch 943/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 1.7839 - val_accuracy: 0.8395\n",
            "Epoch 944/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 1.8866 - val_accuracy: 0.8383\n",
            "Epoch 945/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 1.8259 - val_accuracy: 0.8236\n",
            "Epoch 946/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 1.6629 - val_accuracy: 0.8402\n",
            "Epoch 947/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 1.8291 - val_accuracy: 0.8431\n",
            "Epoch 948/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 2.2111 - val_accuracy: 0.8397\n",
            "Epoch 949/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9948 - val_loss: 1.9447 - val_accuracy: 0.8355\n",
            "Epoch 950/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0190 - accuracy: 0.9930 - val_loss: 1.6534 - val_accuracy: 0.8466\n",
            "Epoch 951/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 1.6046 - val_accuracy: 0.8500\n",
            "Epoch 952/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 1.6260 - val_accuracy: 0.8436\n",
            "Epoch 953/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.5896 - val_accuracy: 0.8458\n",
            "Epoch 954/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 1.4829 - val_accuracy: 0.8381\n",
            "Epoch 955/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 1.7446 - val_accuracy: 0.8255\n",
            "Epoch 956/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 2.0313 - val_accuracy: 0.8155\n",
            "Epoch 957/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 1.9352 - val_accuracy: 0.8220\n",
            "Epoch 958/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 1.6931 - val_accuracy: 0.8359\n",
            "Epoch 959/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 1.9385 - val_accuracy: 0.8131\n",
            "Epoch 960/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 1.9794 - val_accuracy: 0.8155\n",
            "Epoch 961/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 1.6916 - val_accuracy: 0.8470\n",
            "Epoch 962/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 1.7313 - val_accuracy: 0.8350\n",
            "Epoch 963/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.5037 - val_accuracy: 0.8573\n",
            "Epoch 964/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 1.6704 - val_accuracy: 0.8542\n",
            "Epoch 965/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 1.8612 - val_accuracy: 0.8348\n",
            "Epoch 966/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 1.7785 - val_accuracy: 0.8523\n",
            "Epoch 967/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 2.2651 - val_accuracy: 0.8369\n",
            "Epoch 968/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 1.5051 - val_accuracy: 0.8594\n",
            "Epoch 969/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 1.7870 - val_accuracy: 0.8458\n",
            "Epoch 970/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 1.6550 - val_accuracy: 0.8473\n",
            "Epoch 971/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0237 - accuracy: 0.9918 - val_loss: 1.7774 - val_accuracy: 0.8316\n",
            "Epoch 972/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 1.6168 - val_accuracy: 0.8339\n",
            "Epoch 973/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 2.0388 - val_accuracy: 0.8102\n",
            "Epoch 974/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9950 - val_loss: 1.8084 - val_accuracy: 0.8286\n",
            "Epoch 975/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 2.6568 - val_accuracy: 0.8034\n",
            "Epoch 976/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 2.1370 - val_accuracy: 0.8431\n",
            "Epoch 977/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.9854 - val_accuracy: 0.8377\n",
            "Epoch 978/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 1.8449 - val_accuracy: 0.8397\n",
            "Epoch 979/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 1.9690 - val_accuracy: 0.8456\n",
            "Epoch 980/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 1.8677 - val_accuracy: 0.8438\n",
            "Epoch 981/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 1.7535 - val_accuracy: 0.8405\n",
            "Epoch 982/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 1.9641 - val_accuracy: 0.8364\n",
            "Epoch 983/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 2.0362 - val_accuracy: 0.8483\n",
            "Epoch 984/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 1.5250 - val_accuracy: 0.8523\n",
            "Epoch 985/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 1.6334 - val_accuracy: 0.8523\n",
            "Epoch 986/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.7156 - val_accuracy: 0.8536\n",
            "Epoch 987/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 1.7824 - val_accuracy: 0.8434\n",
            "Epoch 988/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 1.7127 - val_accuracy: 0.8383\n",
            "Epoch 989/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 2.0213 - val_accuracy: 0.8403\n",
            "Epoch 990/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 1.8669 - val_accuracy: 0.8320\n",
            "Epoch 991/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 2.2891 - val_accuracy: 0.8230\n",
            "Epoch 992/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0226 - accuracy: 0.9922 - val_loss: 2.2713 - val_accuracy: 0.8308\n",
            "Epoch 993/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 1.8751 - val_accuracy: 0.8467\n",
            "Epoch 994/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 2.3154 - val_accuracy: 0.8303\n",
            "Epoch 995/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 1.9611 - val_accuracy: 0.8431\n",
            "Epoch 996/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0138 - accuracy: 0.9948 - val_loss: 1.6038 - val_accuracy: 0.8525\n",
            "Epoch 997/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 1.7813 - val_accuracy: 0.8587\n",
            "Epoch 998/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 1.6636 - val_accuracy: 0.8508\n",
            "Epoch 999/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 1.7446 - val_accuracy: 0.8630\n",
            "Epoch 1000/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 1.7072 - val_accuracy: 0.8405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEyOzfd7ov_v",
        "outputId": "5b3c6524-238d-4c7b-cfa4-67f5da4b282c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "batch_loss,batch_acc=batch_model.evaluate(test_dataset,steps=50)\n",
        "print(\"Accuracy with batch normalization is \",batch_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 0s 8ms/step - loss: 1.7072 - accuracy: 0.8405\n",
            "Accuracy with batch normalization is  0.8404687643051147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XPMGnt7qWbN"
      },
      "source": [
        "initial_learning_rate = 0.01\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "adam_lr = keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3VdPtzyqnXZ"
      },
      "source": [
        "model.compile(optimizer=adam_lr,loss=\"categorical_crossentropy\",metrics=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be2x5Mj3q5dr",
        "outputId": "f916d110-c73f-459b-b597-e189d28c268f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_lr=model.fit(train_dataset,epochs=EPOCHS,steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,validation_data=test_dataset,batch_size=BATCH_SIZE,verbose = 1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0891 - accuracy: 0.9709 - val_loss: 1.0970 - val_accuracy: 0.8737\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0590 - accuracy: 0.9764 - val_loss: 1.2035 - val_accuracy: 0.8728\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0658 - accuracy: 0.9756 - val_loss: 1.1103 - val_accuracy: 0.8747\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9717 - val_loss: 1.1951 - val_accuracy: 0.8664\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0606 - accuracy: 0.9773 - val_loss: 1.1611 - val_accuracy: 0.8686\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0579 - accuracy: 0.9756 - val_loss: 1.1680 - val_accuracy: 0.8669\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0531 - accuracy: 0.9798 - val_loss: 1.2504 - val_accuracy: 0.8714\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0763 - accuracy: 0.9708 - val_loss: 1.1705 - val_accuracy: 0.8686\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0599 - accuracy: 0.9766 - val_loss: 1.2201 - val_accuracy: 0.8677\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0660 - accuracy: 0.9744 - val_loss: 1.1812 - val_accuracy: 0.8761\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0657 - accuracy: 0.9750 - val_loss: 1.0956 - val_accuracy: 0.8734\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0542 - accuracy: 0.9789 - val_loss: 1.2506 - val_accuracy: 0.8677\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0770 - accuracy: 0.9718 - val_loss: 1.1765 - val_accuracy: 0.8619\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0724 - accuracy: 0.9728 - val_loss: 1.1132 - val_accuracy: 0.8717\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0750 - accuracy: 0.9710 - val_loss: 1.1549 - val_accuracy: 0.8669\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0520 - accuracy: 0.9797 - val_loss: 1.1461 - val_accuracy: 0.8763\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0569 - accuracy: 0.9791 - val_loss: 1.1206 - val_accuracy: 0.8734\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0627 - accuracy: 0.9741 - val_loss: 1.2183 - val_accuracy: 0.8764\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0583 - accuracy: 0.9768 - val_loss: 1.2043 - val_accuracy: 0.8730\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0666 - accuracy: 0.9747 - val_loss: 1.1146 - val_accuracy: 0.8778\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0722 - accuracy: 0.9764 - val_loss: 1.2243 - val_accuracy: 0.8709\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0709 - accuracy: 0.9741 - val_loss: 1.2023 - val_accuracy: 0.8620\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0597 - accuracy: 0.9775 - val_loss: 1.1952 - val_accuracy: 0.8764\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0588 - accuracy: 0.9770 - val_loss: 1.1870 - val_accuracy: 0.8722\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0606 - accuracy: 0.9759 - val_loss: 1.1813 - val_accuracy: 0.8698\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0687 - accuracy: 0.9737 - val_loss: 1.2312 - val_accuracy: 0.8655\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0700 - accuracy: 0.9737 - val_loss: 1.1486 - val_accuracy: 0.8684\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0717 - accuracy: 0.9723 - val_loss: 1.1198 - val_accuracy: 0.8711\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0653 - accuracy: 0.9752 - val_loss: 1.1849 - val_accuracy: 0.8678\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0586 - accuracy: 0.9785 - val_loss: 1.1989 - val_accuracy: 0.8728\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0568 - accuracy: 0.9785 - val_loss: 1.1298 - val_accuracy: 0.8695\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0777 - accuracy: 0.9699 - val_loss: 1.1541 - val_accuracy: 0.8731\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0564 - accuracy: 0.9782 - val_loss: 1.1734 - val_accuracy: 0.8712\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0670 - accuracy: 0.9745 - val_loss: 1.1372 - val_accuracy: 0.8734\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0625 - accuracy: 0.9765 - val_loss: 1.2871 - val_accuracy: 0.8711\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0660 - accuracy: 0.9749 - val_loss: 1.2014 - val_accuracy: 0.8662\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0686 - accuracy: 0.9737 - val_loss: 1.1144 - val_accuracy: 0.8731\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0641 - accuracy: 0.9752 - val_loss: 1.1391 - val_accuracy: 0.8763\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0722 - accuracy: 0.9733 - val_loss: 1.1290 - val_accuracy: 0.8725\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0525 - accuracy: 0.9799 - val_loss: 1.2600 - val_accuracy: 0.8737\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0787 - accuracy: 0.9711 - val_loss: 1.1458 - val_accuracy: 0.8734\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0690 - accuracy: 0.9751 - val_loss: 1.1917 - val_accuracy: 0.8667\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0639 - accuracy: 0.9759 - val_loss: 1.1751 - val_accuracy: 0.8692\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0666 - accuracy: 0.9739 - val_loss: 1.1902 - val_accuracy: 0.8712\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0557 - accuracy: 0.9794 - val_loss: 1.2247 - val_accuracy: 0.8700\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0620 - accuracy: 0.9737 - val_loss: 1.2046 - val_accuracy: 0.8755\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0601 - accuracy: 0.9774 - val_loss: 1.3590 - val_accuracy: 0.8630\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9697 - val_loss: 1.1548 - val_accuracy: 0.8764\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0589 - accuracy: 0.9770 - val_loss: 1.2672 - val_accuracy: 0.8687\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0720 - accuracy: 0.9731 - val_loss: 1.2601 - val_accuracy: 0.8647\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0707 - accuracy: 0.9744 - val_loss: 1.2048 - val_accuracy: 0.8747\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0595 - accuracy: 0.9768 - val_loss: 1.2395 - val_accuracy: 0.8669\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0666 - accuracy: 0.9739 - val_loss: 1.1515 - val_accuracy: 0.8714\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0414 - accuracy: 0.9842 - val_loss: 1.2797 - val_accuracy: 0.8691\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0594 - accuracy: 0.9773 - val_loss: 1.1952 - val_accuracy: 0.8734\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0605 - accuracy: 0.9785 - val_loss: 1.2042 - val_accuracy: 0.8684\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0677 - accuracy: 0.9740 - val_loss: 1.1513 - val_accuracy: 0.8728\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0574 - accuracy: 0.9783 - val_loss: 1.1918 - val_accuracy: 0.8677\n",
            "Epoch 59/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0581 - accuracy: 0.9781 - val_loss: 1.2324 - val_accuracy: 0.8719\n",
            "Epoch 60/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0694 - accuracy: 0.9729 - val_loss: 1.2113 - val_accuracy: 0.8677\n",
            "Epoch 61/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0573 - accuracy: 0.9784 - val_loss: 1.2140 - val_accuracy: 0.8697\n",
            "Epoch 62/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0617 - accuracy: 0.9766 - val_loss: 1.1667 - val_accuracy: 0.8717\n",
            "Epoch 63/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0712 - accuracy: 0.9748 - val_loss: 1.3870 - val_accuracy: 0.8695\n",
            "Epoch 64/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0656 - accuracy: 0.9744 - val_loss: 1.2221 - val_accuracy: 0.8675\n",
            "Epoch 65/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0724 - accuracy: 0.9723 - val_loss: 1.1575 - val_accuracy: 0.8712\n",
            "Epoch 66/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0610 - accuracy: 0.9761 - val_loss: 1.1563 - val_accuracy: 0.8706\n",
            "Epoch 67/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0699 - accuracy: 0.9737 - val_loss: 1.1699 - val_accuracy: 0.8753\n",
            "Epoch 68/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0562 - accuracy: 0.9778 - val_loss: 1.2077 - val_accuracy: 0.8716\n",
            "Epoch 69/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0698 - accuracy: 0.9745 - val_loss: 1.1309 - val_accuracy: 0.8737\n",
            "Epoch 70/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0599 - accuracy: 0.9774 - val_loss: 1.2424 - val_accuracy: 0.8712\n",
            "Epoch 71/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0527 - accuracy: 0.9789 - val_loss: 1.1972 - val_accuracy: 0.8722\n",
            "Epoch 72/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0670 - accuracy: 0.9747 - val_loss: 1.1612 - val_accuracy: 0.8709\n",
            "Epoch 73/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0520 - accuracy: 0.9798 - val_loss: 1.1482 - val_accuracy: 0.8731\n",
            "Epoch 74/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0729 - accuracy: 0.9708 - val_loss: 1.2133 - val_accuracy: 0.8697\n",
            "Epoch 75/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0615 - accuracy: 0.9759 - val_loss: 1.1471 - val_accuracy: 0.8731\n",
            "Epoch 76/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0540 - accuracy: 0.9804 - val_loss: 1.2361 - val_accuracy: 0.8655\n",
            "Epoch 77/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0520 - accuracy: 0.9799 - val_loss: 1.3008 - val_accuracy: 0.8672\n",
            "Epoch 78/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0587 - accuracy: 0.9782 - val_loss: 1.1906 - val_accuracy: 0.8719\n",
            "Epoch 79/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0708 - accuracy: 0.9734 - val_loss: 1.2410 - val_accuracy: 0.8661\n",
            "Epoch 80/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0714 - accuracy: 0.9734 - val_loss: 1.1528 - val_accuracy: 0.8759\n",
            "Epoch 81/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0664 - accuracy: 0.9731 - val_loss: 1.2569 - val_accuracy: 0.8653\n",
            "Epoch 82/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0548 - accuracy: 0.9800 - val_loss: 1.2467 - val_accuracy: 0.8745\n",
            "Epoch 83/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0578 - accuracy: 0.9775 - val_loss: 1.2438 - val_accuracy: 0.8706\n",
            "Epoch 84/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0578 - accuracy: 0.9784 - val_loss: 1.2794 - val_accuracy: 0.8656\n",
            "Epoch 85/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0535 - accuracy: 0.9786 - val_loss: 1.1717 - val_accuracy: 0.8744\n",
            "Epoch 86/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9811 - val_loss: 1.1604 - val_accuracy: 0.8692\n",
            "Epoch 87/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0545 - accuracy: 0.9810 - val_loss: 1.3269 - val_accuracy: 0.8641\n",
            "Epoch 88/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0551 - accuracy: 0.9788 - val_loss: 1.1943 - val_accuracy: 0.8720\n",
            "Epoch 89/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0612 - accuracy: 0.9776 - val_loss: 1.1864 - val_accuracy: 0.8667\n",
            "Epoch 90/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0565 - accuracy: 0.9797 - val_loss: 1.2426 - val_accuracy: 0.8728\n",
            "Epoch 91/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0584 - accuracy: 0.9769 - val_loss: 1.2477 - val_accuracy: 0.8694\n",
            "Epoch 92/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0643 - accuracy: 0.9763 - val_loss: 1.2323 - val_accuracy: 0.8712\n",
            "Epoch 93/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0778 - accuracy: 0.9728 - val_loss: 1.2208 - val_accuracy: 0.8727\n",
            "Epoch 94/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0581 - accuracy: 0.9781 - val_loss: 1.2413 - val_accuracy: 0.8702\n",
            "Epoch 95/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0604 - accuracy: 0.9788 - val_loss: 1.2090 - val_accuracy: 0.8703\n",
            "Epoch 96/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0719 - accuracy: 0.9752 - val_loss: 1.2703 - val_accuracy: 0.8717\n",
            "Epoch 97/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0656 - accuracy: 0.9752 - val_loss: 1.2602 - val_accuracy: 0.8636\n",
            "Epoch 98/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0685 - accuracy: 0.9760 - val_loss: 1.2395 - val_accuracy: 0.8687\n",
            "Epoch 99/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0554 - accuracy: 0.9794 - val_loss: 1.2433 - val_accuracy: 0.8702\n",
            "Epoch 100/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0487 - accuracy: 0.9810 - val_loss: 1.1737 - val_accuracy: 0.8694\n",
            "Epoch 101/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0510 - accuracy: 0.9817 - val_loss: 1.2404 - val_accuracy: 0.8656\n",
            "Epoch 102/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0592 - accuracy: 0.9766 - val_loss: 1.2108 - val_accuracy: 0.8689\n",
            "Epoch 103/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0580 - accuracy: 0.9783 - val_loss: 1.1579 - val_accuracy: 0.8673\n",
            "Epoch 104/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0563 - accuracy: 0.9782 - val_loss: 1.2183 - val_accuracy: 0.8652\n",
            "Epoch 105/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0729 - accuracy: 0.9748 - val_loss: 1.2406 - val_accuracy: 0.8761\n",
            "Epoch 106/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0799 - accuracy: 0.9727 - val_loss: 1.1999 - val_accuracy: 0.8677\n",
            "Epoch 107/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0665 - accuracy: 0.9759 - val_loss: 1.1996 - val_accuracy: 0.8708\n",
            "Epoch 108/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0566 - accuracy: 0.9784 - val_loss: 1.1905 - val_accuracy: 0.8742\n",
            "Epoch 109/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0644 - accuracy: 0.9756 - val_loss: 1.2168 - val_accuracy: 0.8716\n",
            "Epoch 110/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0539 - accuracy: 0.9804 - val_loss: 1.2512 - val_accuracy: 0.8756\n",
            "Epoch 111/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0590 - accuracy: 0.9766 - val_loss: 1.2387 - val_accuracy: 0.8712\n",
            "Epoch 112/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0564 - accuracy: 0.9777 - val_loss: 1.2350 - val_accuracy: 0.8683\n",
            "Epoch 113/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0567 - accuracy: 0.9797 - val_loss: 1.2376 - val_accuracy: 0.8759\n",
            "Epoch 114/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0494 - accuracy: 0.9807 - val_loss: 1.1293 - val_accuracy: 0.8716\n",
            "Epoch 115/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0530 - accuracy: 0.9802 - val_loss: 1.3239 - val_accuracy: 0.8711\n",
            "Epoch 116/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0561 - accuracy: 0.9777 - val_loss: 1.2497 - val_accuracy: 0.8695\n",
            "Epoch 117/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0471 - accuracy: 0.9820 - val_loss: 1.1724 - val_accuracy: 0.8711\n",
            "Epoch 118/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0513 - accuracy: 0.9805 - val_loss: 1.2105 - val_accuracy: 0.8711\n",
            "Epoch 119/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0607 - accuracy: 0.9777 - val_loss: 1.2996 - val_accuracy: 0.8694\n",
            "Epoch 120/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0555 - accuracy: 0.9781 - val_loss: 1.2325 - val_accuracy: 0.8692\n",
            "Epoch 121/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0904 - accuracy: 0.9678 - val_loss: 1.2325 - val_accuracy: 0.8755\n",
            "Epoch 122/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0586 - accuracy: 0.9775 - val_loss: 1.2563 - val_accuracy: 0.8722\n",
            "Epoch 123/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0624 - accuracy: 0.9778 - val_loss: 1.1849 - val_accuracy: 0.8742\n",
            "Epoch 124/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0525 - accuracy: 0.9804 - val_loss: 1.3503 - val_accuracy: 0.8686\n",
            "Epoch 125/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0585 - accuracy: 0.9770 - val_loss: 1.3006 - val_accuracy: 0.8675\n",
            "Epoch 126/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0528 - accuracy: 0.9799 - val_loss: 1.2428 - val_accuracy: 0.8633\n",
            "Epoch 127/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0556 - accuracy: 0.9791 - val_loss: 1.2429 - val_accuracy: 0.8763\n",
            "Epoch 128/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0628 - accuracy: 0.9775 - val_loss: 1.1584 - val_accuracy: 0.8653\n",
            "Epoch 129/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0605 - accuracy: 0.9768 - val_loss: 1.3086 - val_accuracy: 0.8631\n",
            "Epoch 130/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0603 - accuracy: 0.9757 - val_loss: 1.2956 - val_accuracy: 0.8642\n",
            "Epoch 131/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0608 - accuracy: 0.9773 - val_loss: 1.2262 - val_accuracy: 0.8716\n",
            "Epoch 132/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0519 - accuracy: 0.9795 - val_loss: 1.2230 - val_accuracy: 0.8683\n",
            "Epoch 133/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0608 - accuracy: 0.9784 - val_loss: 1.3082 - val_accuracy: 0.8698\n",
            "Epoch 134/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0527 - accuracy: 0.9805 - val_loss: 1.2748 - val_accuracy: 0.8711\n",
            "Epoch 135/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0577 - accuracy: 0.9772 - val_loss: 1.2433 - val_accuracy: 0.8727\n",
            "Epoch 136/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0498 - accuracy: 0.9805 - val_loss: 1.3000 - val_accuracy: 0.8673\n",
            "Epoch 137/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0510 - accuracy: 0.9801 - val_loss: 1.2281 - val_accuracy: 0.8694\n",
            "Epoch 138/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0497 - accuracy: 0.9823 - val_loss: 1.3481 - val_accuracy: 0.8734\n",
            "Epoch 139/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0661 - accuracy: 0.9756 - val_loss: 1.3517 - val_accuracy: 0.8653\n",
            "Epoch 140/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0814 - accuracy: 0.9722 - val_loss: 1.3267 - val_accuracy: 0.8641\n",
            "Epoch 141/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0678 - accuracy: 0.9756 - val_loss: 1.2669 - val_accuracy: 0.8667\n",
            "Epoch 142/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0498 - accuracy: 0.9799 - val_loss: 1.2378 - val_accuracy: 0.8714\n",
            "Epoch 143/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0504 - accuracy: 0.9803 - val_loss: 1.2900 - val_accuracy: 0.8711\n",
            "Epoch 144/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0626 - accuracy: 0.9768 - val_loss: 1.3032 - val_accuracy: 0.8672\n",
            "Epoch 145/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0691 - accuracy: 0.9752 - val_loss: 1.3353 - val_accuracy: 0.8670\n",
            "Epoch 146/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0616 - accuracy: 0.9772 - val_loss: 1.2038 - val_accuracy: 0.8700\n",
            "Epoch 147/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0520 - accuracy: 0.9798 - val_loss: 1.3411 - val_accuracy: 0.8689\n",
            "Epoch 148/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0617 - accuracy: 0.9772 - val_loss: 1.2643 - val_accuracy: 0.8667\n",
            "Epoch 149/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0632 - accuracy: 0.9758 - val_loss: 1.3272 - val_accuracy: 0.8719\n",
            "Epoch 150/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0556 - accuracy: 0.9795 - val_loss: 1.2797 - val_accuracy: 0.8750\n",
            "Epoch 151/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0543 - accuracy: 0.9790 - val_loss: 1.2399 - val_accuracy: 0.8742\n",
            "Epoch 152/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0458 - accuracy: 0.9816 - val_loss: 1.3260 - val_accuracy: 0.8741\n",
            "Epoch 153/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0510 - accuracy: 0.9808 - val_loss: 1.2219 - val_accuracy: 0.8720\n",
            "Epoch 154/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0485 - accuracy: 0.9794 - val_loss: 1.2017 - val_accuracy: 0.8694\n",
            "Epoch 155/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0609 - accuracy: 0.9768 - val_loss: 1.2264 - val_accuracy: 0.8742\n",
            "Epoch 156/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0497 - accuracy: 0.9797 - val_loss: 1.2713 - val_accuracy: 0.8706\n",
            "Epoch 157/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0492 - accuracy: 0.9815 - val_loss: 1.2867 - val_accuracy: 0.8698\n",
            "Epoch 158/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0572 - accuracy: 0.9783 - val_loss: 1.3199 - val_accuracy: 0.8716\n",
            "Epoch 159/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0524 - accuracy: 0.9801 - val_loss: 1.3489 - val_accuracy: 0.8608\n",
            "Epoch 160/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0832 - accuracy: 0.9729 - val_loss: 1.1997 - val_accuracy: 0.8739\n",
            "Epoch 161/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0574 - accuracy: 0.9788 - val_loss: 1.2572 - val_accuracy: 0.8716\n",
            "Epoch 162/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0538 - accuracy: 0.9791 - val_loss: 1.2986 - val_accuracy: 0.8669\n",
            "Epoch 163/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0628 - accuracy: 0.9759 - val_loss: 1.2318 - val_accuracy: 0.8756\n",
            "Epoch 164/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0497 - accuracy: 0.9820 - val_loss: 1.2804 - val_accuracy: 0.8745\n",
            "Epoch 165/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0518 - accuracy: 0.9799 - val_loss: 1.2300 - val_accuracy: 0.8731\n",
            "Epoch 166/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0519 - accuracy: 0.9805 - val_loss: 1.4186 - val_accuracy: 0.8662\n",
            "Epoch 167/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0587 - accuracy: 0.9770 - val_loss: 1.3221 - val_accuracy: 0.8644\n",
            "Epoch 168/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0590 - accuracy: 0.9771 - val_loss: 1.2335 - val_accuracy: 0.8744\n",
            "Epoch 169/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0527 - accuracy: 0.9798 - val_loss: 1.2488 - val_accuracy: 0.8727\n",
            "Epoch 170/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0547 - accuracy: 0.9806 - val_loss: 1.2793 - val_accuracy: 0.8741\n",
            "Epoch 171/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0738 - accuracy: 0.9738 - val_loss: 1.3504 - val_accuracy: 0.8661\n",
            "Epoch 172/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0725 - accuracy: 0.9734 - val_loss: 1.2615 - val_accuracy: 0.8758\n",
            "Epoch 173/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9802 - val_loss: 1.2727 - val_accuracy: 0.8656\n",
            "Epoch 174/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0661 - accuracy: 0.9759 - val_loss: 1.2344 - val_accuracy: 0.8736\n",
            "Epoch 175/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0669 - accuracy: 0.9764 - val_loss: 1.1889 - val_accuracy: 0.8716\n",
            "Epoch 176/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0508 - accuracy: 0.9810 - val_loss: 1.2527 - val_accuracy: 0.8709\n",
            "Epoch 177/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0454 - accuracy: 0.9830 - val_loss: 1.2560 - val_accuracy: 0.8744\n",
            "Epoch 178/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0499 - accuracy: 0.9813 - val_loss: 1.2992 - val_accuracy: 0.8694\n",
            "Epoch 179/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0556 - accuracy: 0.9788 - val_loss: 1.2077 - val_accuracy: 0.8689\n",
            "Epoch 180/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0538 - accuracy: 0.9799 - val_loss: 1.3730 - val_accuracy: 0.8717\n",
            "Epoch 181/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0528 - accuracy: 0.9799 - val_loss: 1.2759 - val_accuracy: 0.8689\n",
            "Epoch 182/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9799 - val_loss: 1.3263 - val_accuracy: 0.8656\n",
            "Epoch 183/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9723 - val_loss: 1.2511 - val_accuracy: 0.8737\n",
            "Epoch 184/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0575 - accuracy: 0.9790 - val_loss: 1.3087 - val_accuracy: 0.8719\n",
            "Epoch 185/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0573 - accuracy: 0.9795 - val_loss: 1.2957 - val_accuracy: 0.8714\n",
            "Epoch 186/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0609 - accuracy: 0.9775 - val_loss: 1.2957 - val_accuracy: 0.8650\n",
            "Epoch 187/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0468 - accuracy: 0.9812 - val_loss: 1.2904 - val_accuracy: 0.8664\n",
            "Epoch 188/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9813 - val_loss: 1.2830 - val_accuracy: 0.8730\n",
            "Epoch 189/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0536 - accuracy: 0.9804 - val_loss: 1.2632 - val_accuracy: 0.8700\n",
            "Epoch 190/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0444 - accuracy: 0.9826 - val_loss: 1.3004 - val_accuracy: 0.8695\n",
            "Epoch 191/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0597 - accuracy: 0.9785 - val_loss: 1.2718 - val_accuracy: 0.8684\n",
            "Epoch 192/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0524 - accuracy: 0.9809 - val_loss: 1.2415 - val_accuracy: 0.8719\n",
            "Epoch 193/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0488 - accuracy: 0.9809 - val_loss: 1.2960 - val_accuracy: 0.8680\n",
            "Epoch 194/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0543 - accuracy: 0.9800 - val_loss: 1.4264 - val_accuracy: 0.8628\n",
            "Epoch 195/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0792 - accuracy: 0.9700 - val_loss: 1.3211 - val_accuracy: 0.8730\n",
            "Epoch 196/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0810 - accuracy: 0.9720 - val_loss: 1.3140 - val_accuracy: 0.8717\n",
            "Epoch 197/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0531 - accuracy: 0.9791 - val_loss: 1.3017 - val_accuracy: 0.8716\n",
            "Epoch 198/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0612 - accuracy: 0.9777 - val_loss: 1.3473 - val_accuracy: 0.8680\n",
            "Epoch 199/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0711 - accuracy: 0.9765 - val_loss: 1.3212 - val_accuracy: 0.8675\n",
            "Epoch 200/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0568 - accuracy: 0.9784 - val_loss: 1.3222 - val_accuracy: 0.8686\n",
            "Epoch 201/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0594 - accuracy: 0.9787 - val_loss: 1.3166 - val_accuracy: 0.8708\n",
            "Epoch 202/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0776 - accuracy: 0.9725 - val_loss: 1.2538 - val_accuracy: 0.8723\n",
            "Epoch 203/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0509 - accuracy: 0.9808 - val_loss: 1.1892 - val_accuracy: 0.8722\n",
            "Epoch 204/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0504 - accuracy: 0.9807 - val_loss: 1.3186 - val_accuracy: 0.8645\n",
            "Epoch 205/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0422 - accuracy: 0.9831 - val_loss: 1.2829 - val_accuracy: 0.8700\n",
            "Epoch 206/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9845 - val_loss: 1.2544 - val_accuracy: 0.8697\n",
            "Epoch 207/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0409 - accuracy: 0.9852 - val_loss: 1.3244 - val_accuracy: 0.8711\n",
            "Epoch 208/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0521 - accuracy: 0.9811 - val_loss: 1.3508 - val_accuracy: 0.8767\n",
            "Epoch 209/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0512 - accuracy: 0.9813 - val_loss: 1.2838 - val_accuracy: 0.8742\n",
            "Epoch 210/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0559 - accuracy: 0.9783 - val_loss: 1.2710 - val_accuracy: 0.8733\n",
            "Epoch 211/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0652 - accuracy: 0.9773 - val_loss: 1.2965 - val_accuracy: 0.8722\n",
            "Epoch 212/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0630 - accuracy: 0.9759 - val_loss: 1.2156 - val_accuracy: 0.8730\n",
            "Epoch 213/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0459 - accuracy: 0.9828 - val_loss: 1.2955 - val_accuracy: 0.8744\n",
            "Epoch 214/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0569 - accuracy: 0.9795 - val_loss: 1.3327 - val_accuracy: 0.8661\n",
            "Epoch 215/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9808 - val_loss: 1.3549 - val_accuracy: 0.8650\n",
            "Epoch 216/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0673 - accuracy: 0.9762 - val_loss: 1.2530 - val_accuracy: 0.8728\n",
            "Epoch 217/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0431 - accuracy: 0.9841 - val_loss: 1.2900 - val_accuracy: 0.8730\n",
            "Epoch 218/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0483 - accuracy: 0.9822 - val_loss: 1.3677 - val_accuracy: 0.8680\n",
            "Epoch 219/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0457 - accuracy: 0.9798 - val_loss: 1.2986 - val_accuracy: 0.8700\n",
            "Epoch 220/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0440 - accuracy: 0.9836 - val_loss: 1.2215 - val_accuracy: 0.8722\n",
            "Epoch 221/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0416 - accuracy: 0.9841 - val_loss: 1.2771 - val_accuracy: 0.8706\n",
            "Epoch 222/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0435 - accuracy: 0.9838 - val_loss: 1.3972 - val_accuracy: 0.8697\n",
            "Epoch 223/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0475 - accuracy: 0.9812 - val_loss: 1.3229 - val_accuracy: 0.8687\n",
            "Epoch 224/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0448 - accuracy: 0.9821 - val_loss: 1.3302 - val_accuracy: 0.8719\n",
            "Epoch 225/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0553 - accuracy: 0.9787 - val_loss: 1.3023 - val_accuracy: 0.8711\n",
            "Epoch 226/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0527 - accuracy: 0.9805 - val_loss: 1.3268 - val_accuracy: 0.8655\n",
            "Epoch 227/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0495 - accuracy: 0.9817 - val_loss: 1.3598 - val_accuracy: 0.8708\n",
            "Epoch 228/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0661 - accuracy: 0.9762 - val_loss: 1.3448 - val_accuracy: 0.8706\n",
            "Epoch 229/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0559 - accuracy: 0.9792 - val_loss: 1.3981 - val_accuracy: 0.8661\n",
            "Epoch 230/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0531 - accuracy: 0.9784 - val_loss: 1.3641 - val_accuracy: 0.8714\n",
            "Epoch 231/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0487 - accuracy: 0.9821 - val_loss: 1.2703 - val_accuracy: 0.8719\n",
            "Epoch 232/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0449 - accuracy: 0.9836 - val_loss: 1.3595 - val_accuracy: 0.8664\n",
            "Epoch 233/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9791 - val_loss: 1.3457 - val_accuracy: 0.8716\n",
            "Epoch 234/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0795 - accuracy: 0.9729 - val_loss: 1.3205 - val_accuracy: 0.8673\n",
            "Epoch 235/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0538 - accuracy: 0.9795 - val_loss: 1.3186 - val_accuracy: 0.8658\n",
            "Epoch 236/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0704 - accuracy: 0.9757 - val_loss: 1.3710 - val_accuracy: 0.8727\n",
            "Epoch 237/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0606 - accuracy: 0.9774 - val_loss: 1.3403 - val_accuracy: 0.8689\n",
            "Epoch 238/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0593 - accuracy: 0.9798 - val_loss: 1.3703 - val_accuracy: 0.8667\n",
            "Epoch 239/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0489 - accuracy: 0.9812 - val_loss: 1.3708 - val_accuracy: 0.8700\n",
            "Epoch 240/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0449 - accuracy: 0.9836 - val_loss: 1.2688 - val_accuracy: 0.8694\n",
            "Epoch 241/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0524 - accuracy: 0.9817 - val_loss: 1.4593 - val_accuracy: 0.8687\n",
            "Epoch 242/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0560 - accuracy: 0.9790 - val_loss: 1.3645 - val_accuracy: 0.8680\n",
            "Epoch 243/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0497 - accuracy: 0.9805 - val_loss: 1.3480 - val_accuracy: 0.8642\n",
            "Epoch 244/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0440 - accuracy: 0.9823 - val_loss: 1.3714 - val_accuracy: 0.8712\n",
            "Epoch 245/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0625 - accuracy: 0.9777 - val_loss: 1.3192 - val_accuracy: 0.8666\n",
            "Epoch 246/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0504 - accuracy: 0.9807 - val_loss: 1.4028 - val_accuracy: 0.8656\n",
            "Epoch 247/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0539 - accuracy: 0.9796 - val_loss: 1.3967 - val_accuracy: 0.8623\n",
            "Epoch 248/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0480 - accuracy: 0.9809 - val_loss: 1.3110 - val_accuracy: 0.8705\n",
            "Epoch 249/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0466 - accuracy: 0.9813 - val_loss: 1.3612 - val_accuracy: 0.8634\n",
            "Epoch 250/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0782 - accuracy: 0.9744 - val_loss: 1.4089 - val_accuracy: 0.8705\n",
            "Epoch 251/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0653 - accuracy: 0.9770 - val_loss: 1.3002 - val_accuracy: 0.8703\n",
            "Epoch 252/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0569 - accuracy: 0.9787 - val_loss: 1.3825 - val_accuracy: 0.8706\n",
            "Epoch 253/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0517 - accuracy: 0.9815 - val_loss: 1.2801 - val_accuracy: 0.8678\n",
            "Epoch 254/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0684 - accuracy: 0.9750 - val_loss: 1.2434 - val_accuracy: 0.8698\n",
            "Epoch 255/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0535 - accuracy: 0.9797 - val_loss: 1.5018 - val_accuracy: 0.8675\n",
            "Epoch 256/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0430 - accuracy: 0.9834 - val_loss: 1.3177 - val_accuracy: 0.8678\n",
            "Epoch 257/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0569 - accuracy: 0.9785 - val_loss: 1.3894 - val_accuracy: 0.8641\n",
            "Epoch 258/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0643 - accuracy: 0.9762 - val_loss: 1.3680 - val_accuracy: 0.8708\n",
            "Epoch 259/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0698 - accuracy: 0.9762 - val_loss: 1.2813 - val_accuracy: 0.8683\n",
            "Epoch 260/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0595 - accuracy: 0.9795 - val_loss: 1.3986 - val_accuracy: 0.8680\n",
            "Epoch 261/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0494 - accuracy: 0.9809 - val_loss: 1.3070 - val_accuracy: 0.8730\n",
            "Epoch 262/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0463 - accuracy: 0.9828 - val_loss: 1.3304 - val_accuracy: 0.8691\n",
            "Epoch 263/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0458 - accuracy: 0.9834 - val_loss: 1.3803 - val_accuracy: 0.8725\n",
            "Epoch 264/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0471 - accuracy: 0.9816 - val_loss: 1.3471 - val_accuracy: 0.8720\n",
            "Epoch 265/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0517 - accuracy: 0.9819 - val_loss: 1.3800 - val_accuracy: 0.8692\n",
            "Epoch 266/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0471 - accuracy: 0.9816 - val_loss: 1.4072 - val_accuracy: 0.8653\n",
            "Epoch 267/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0467 - accuracy: 0.9831 - val_loss: 1.3466 - val_accuracy: 0.8711\n",
            "Epoch 268/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0513 - accuracy: 0.9806 - val_loss: 1.2978 - val_accuracy: 0.8717\n",
            "Epoch 269/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0585 - accuracy: 0.9798 - val_loss: 1.4682 - val_accuracy: 0.8697\n",
            "Epoch 270/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0661 - accuracy: 0.9758 - val_loss: 1.4511 - val_accuracy: 0.8597\n",
            "Epoch 271/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9803 - val_loss: 1.3735 - val_accuracy: 0.8730\n",
            "Epoch 272/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0546 - accuracy: 0.9801 - val_loss: 1.3062 - val_accuracy: 0.8717\n",
            "Epoch 273/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0458 - accuracy: 0.9830 - val_loss: 1.3122 - val_accuracy: 0.8711\n",
            "Epoch 274/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0459 - accuracy: 0.9812 - val_loss: 1.4216 - val_accuracy: 0.8723\n",
            "Epoch 275/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0460 - accuracy: 0.9812 - val_loss: 1.2854 - val_accuracy: 0.8684\n",
            "Epoch 276/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9840 - val_loss: 1.3568 - val_accuracy: 0.8675\n",
            "Epoch 277/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0416 - accuracy: 0.9827 - val_loss: 1.3634 - val_accuracy: 0.8692\n",
            "Epoch 278/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0624 - accuracy: 0.9793 - val_loss: 1.4009 - val_accuracy: 0.8720\n",
            "Epoch 279/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0584 - accuracy: 0.9802 - val_loss: 1.2887 - val_accuracy: 0.8727\n",
            "Epoch 280/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0596 - accuracy: 0.9774 - val_loss: 1.3291 - val_accuracy: 0.8730\n",
            "Epoch 281/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0475 - accuracy: 0.9816 - val_loss: 1.3610 - val_accuracy: 0.8716\n",
            "Epoch 282/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0556 - accuracy: 0.9787 - val_loss: 1.3864 - val_accuracy: 0.8716\n",
            "Epoch 283/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0565 - accuracy: 0.9798 - val_loss: 1.4744 - val_accuracy: 0.8756\n",
            "Epoch 284/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0715 - accuracy: 0.9768 - val_loss: 1.3881 - val_accuracy: 0.8656\n",
            "Epoch 285/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0495 - accuracy: 0.9808 - val_loss: 1.3392 - val_accuracy: 0.8695\n",
            "Epoch 286/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0545 - accuracy: 0.9791 - val_loss: 1.3076 - val_accuracy: 0.8670\n",
            "Epoch 287/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0524 - accuracy: 0.9797 - val_loss: 1.2887 - val_accuracy: 0.8719\n",
            "Epoch 288/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0513 - accuracy: 0.9809 - val_loss: 1.4283 - val_accuracy: 0.8697\n",
            "Epoch 289/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0622 - accuracy: 0.9781 - val_loss: 1.3112 - val_accuracy: 0.8681\n",
            "Epoch 290/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0482 - accuracy: 0.9818 - val_loss: 1.3327 - val_accuracy: 0.8677\n",
            "Epoch 291/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0395 - accuracy: 0.9839 - val_loss: 1.3503 - val_accuracy: 0.8698\n",
            "Epoch 292/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0506 - accuracy: 0.9804 - val_loss: 1.3040 - val_accuracy: 0.8706\n",
            "Epoch 293/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0508 - accuracy: 0.9809 - val_loss: 1.3586 - val_accuracy: 0.8706\n",
            "Epoch 294/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9812 - val_loss: 1.3959 - val_accuracy: 0.8705\n",
            "Epoch 295/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9817 - val_loss: 1.4316 - val_accuracy: 0.8678\n",
            "Epoch 296/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0587 - accuracy: 0.9789 - val_loss: 1.3241 - val_accuracy: 0.8658\n",
            "Epoch 297/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0418 - accuracy: 0.9837 - val_loss: 1.4840 - val_accuracy: 0.8698\n",
            "Epoch 298/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9838 - val_loss: 1.3553 - val_accuracy: 0.8695\n",
            "Epoch 299/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0454 - accuracy: 0.9833 - val_loss: 1.3234 - val_accuracy: 0.8723\n",
            "Epoch 300/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0640 - accuracy: 0.9772 - val_loss: 1.3755 - val_accuracy: 0.8680\n",
            "Epoch 301/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0723 - accuracy: 0.9770 - val_loss: 1.3662 - val_accuracy: 0.8692\n",
            "Epoch 302/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0453 - accuracy: 0.9833 - val_loss: 1.3806 - val_accuracy: 0.8736\n",
            "Epoch 303/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0488 - accuracy: 0.9822 - val_loss: 1.4217 - val_accuracy: 0.8614\n",
            "Epoch 304/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0529 - accuracy: 0.9801 - val_loss: 1.4399 - val_accuracy: 0.8645\n",
            "Epoch 305/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0613 - accuracy: 0.9790 - val_loss: 1.3862 - val_accuracy: 0.8716\n",
            "Epoch 306/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0587 - accuracy: 0.9786 - val_loss: 1.2950 - val_accuracy: 0.8675\n",
            "Epoch 307/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0608 - accuracy: 0.9791 - val_loss: 1.3973 - val_accuracy: 0.8673\n",
            "Epoch 308/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0472 - accuracy: 0.9817 - val_loss: 1.4158 - val_accuracy: 0.8708\n",
            "Epoch 309/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0449 - accuracy: 0.9831 - val_loss: 1.3113 - val_accuracy: 0.8644\n",
            "Epoch 310/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0623 - accuracy: 0.9788 - val_loss: 1.3678 - val_accuracy: 0.8683\n",
            "Epoch 311/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0744 - accuracy: 0.9752 - val_loss: 1.5131 - val_accuracy: 0.8661\n",
            "Epoch 312/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0545 - accuracy: 0.9807 - val_loss: 1.3627 - val_accuracy: 0.8694\n",
            "Epoch 313/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0545 - accuracy: 0.9793 - val_loss: 1.4148 - val_accuracy: 0.8672\n",
            "Epoch 314/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0544 - accuracy: 0.9792 - val_loss: 1.2929 - val_accuracy: 0.8723\n",
            "Epoch 315/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0447 - accuracy: 0.9833 - val_loss: 1.3967 - val_accuracy: 0.8734\n",
            "Epoch 316/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0652 - accuracy: 0.9787 - val_loss: 1.4283 - val_accuracy: 0.8714\n",
            "Epoch 317/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0533 - accuracy: 0.9803 - val_loss: 1.4038 - val_accuracy: 0.8653\n",
            "Epoch 318/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0534 - accuracy: 0.9802 - val_loss: 1.4944 - val_accuracy: 0.8702\n",
            "Epoch 319/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0626 - accuracy: 0.9766 - val_loss: 1.3937 - val_accuracy: 0.8712\n",
            "Epoch 320/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0614 - accuracy: 0.9785 - val_loss: 1.2649 - val_accuracy: 0.8706\n",
            "Epoch 321/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0430 - accuracy: 0.9853 - val_loss: 1.4157 - val_accuracy: 0.8675\n",
            "Epoch 322/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0445 - accuracy: 0.9816 - val_loss: 1.3451 - val_accuracy: 0.8739\n",
            "Epoch 323/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0409 - accuracy: 0.9834 - val_loss: 1.2833 - val_accuracy: 0.8703\n",
            "Epoch 324/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0549 - accuracy: 0.9798 - val_loss: 1.4341 - val_accuracy: 0.8658\n",
            "Epoch 325/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0684 - accuracy: 0.9759 - val_loss: 1.4482 - val_accuracy: 0.8755\n",
            "Epoch 326/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0379 - accuracy: 0.9852 - val_loss: 1.4049 - val_accuracy: 0.8700\n",
            "Epoch 327/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0435 - accuracy: 0.9825 - val_loss: 1.4254 - val_accuracy: 0.8700\n",
            "Epoch 328/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0658 - accuracy: 0.9772 - val_loss: 1.3860 - val_accuracy: 0.8739\n",
            "Epoch 329/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0689 - accuracy: 0.9755 - val_loss: 1.4773 - val_accuracy: 0.8662\n",
            "Epoch 330/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0744 - accuracy: 0.9739 - val_loss: 1.4026 - val_accuracy: 0.8727\n",
            "Epoch 331/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0490 - accuracy: 0.9814 - val_loss: 1.4169 - val_accuracy: 0.8630\n",
            "Epoch 332/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0535 - accuracy: 0.9805 - val_loss: 1.3992 - val_accuracy: 0.8683\n",
            "Epoch 333/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0543 - accuracy: 0.9802 - val_loss: 1.3461 - val_accuracy: 0.8730\n",
            "Epoch 334/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0486 - accuracy: 0.9827 - val_loss: 1.3004 - val_accuracy: 0.8739\n",
            "Epoch 335/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0417 - accuracy: 0.9841 - val_loss: 1.4392 - val_accuracy: 0.8627\n",
            "Epoch 336/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0473 - accuracy: 0.9815 - val_loss: 1.4278 - val_accuracy: 0.8686\n",
            "Epoch 337/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0488 - accuracy: 0.9827 - val_loss: 1.3644 - val_accuracy: 0.8700\n",
            "Epoch 338/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0451 - accuracy: 0.9820 - val_loss: 1.3868 - val_accuracy: 0.8692\n",
            "Epoch 339/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0436 - accuracy: 0.9837 - val_loss: 1.4002 - val_accuracy: 0.8694\n",
            "Epoch 340/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0493 - accuracy: 0.9814 - val_loss: 1.3617 - val_accuracy: 0.8695\n",
            "Epoch 341/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0446 - accuracy: 0.9837 - val_loss: 1.4166 - val_accuracy: 0.8691\n",
            "Epoch 342/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0491 - accuracy: 0.9830 - val_loss: 1.3648 - val_accuracy: 0.8689\n",
            "Epoch 343/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0419 - accuracy: 0.9830 - val_loss: 1.4020 - val_accuracy: 0.8669\n",
            "Epoch 344/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0512 - accuracy: 0.9823 - val_loss: 1.4541 - val_accuracy: 0.8741\n",
            "Epoch 345/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0467 - accuracy: 0.9819 - val_loss: 1.3499 - val_accuracy: 0.8720\n",
            "Epoch 346/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0493 - accuracy: 0.9814 - val_loss: 1.3502 - val_accuracy: 0.8720\n",
            "Epoch 347/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0447 - accuracy: 0.9824 - val_loss: 1.4148 - val_accuracy: 0.8720\n",
            "Epoch 348/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0522 - accuracy: 0.9819 - val_loss: 1.4066 - val_accuracy: 0.8666\n",
            "Epoch 349/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0606 - accuracy: 0.9795 - val_loss: 1.4731 - val_accuracy: 0.8677\n",
            "Epoch 350/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0555 - accuracy: 0.9780 - val_loss: 1.3588 - val_accuracy: 0.8691\n",
            "Epoch 351/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0509 - accuracy: 0.9805 - val_loss: 1.2822 - val_accuracy: 0.8667\n",
            "Epoch 352/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0604 - accuracy: 0.9767 - val_loss: 1.3966 - val_accuracy: 0.8725\n",
            "Epoch 353/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0661 - accuracy: 0.9765 - val_loss: 1.3859 - val_accuracy: 0.8694\n",
            "Epoch 354/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0507 - accuracy: 0.9821 - val_loss: 1.4300 - val_accuracy: 0.8662\n",
            "Epoch 355/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0570 - accuracy: 0.9798 - val_loss: 1.3634 - val_accuracy: 0.8741\n",
            "Epoch 356/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0442 - accuracy: 0.9834 - val_loss: 1.4227 - val_accuracy: 0.8705\n",
            "Epoch 357/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0372 - accuracy: 0.9864 - val_loss: 1.3722 - val_accuracy: 0.8694\n",
            "Epoch 358/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0464 - accuracy: 0.9827 - val_loss: 1.4925 - val_accuracy: 0.8703\n",
            "Epoch 359/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0470 - accuracy: 0.9818 - val_loss: 1.4348 - val_accuracy: 0.8662\n",
            "Epoch 360/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0741 - accuracy: 0.9744 - val_loss: 1.4898 - val_accuracy: 0.8683\n",
            "Epoch 361/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0585 - accuracy: 0.9790 - val_loss: 1.3773 - val_accuracy: 0.8708\n",
            "Epoch 362/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0495 - accuracy: 0.9802 - val_loss: 1.3467 - val_accuracy: 0.8714\n",
            "Epoch 363/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0475 - accuracy: 0.9835 - val_loss: 1.4353 - val_accuracy: 0.8675\n",
            "Epoch 364/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0425 - accuracy: 0.9827 - val_loss: 1.3764 - val_accuracy: 0.8681\n",
            "Epoch 365/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0472 - accuracy: 0.9819 - val_loss: 1.2777 - val_accuracy: 0.8752\n",
            "Epoch 366/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0411 - accuracy: 0.9833 - val_loss: 1.3902 - val_accuracy: 0.8716\n",
            "Epoch 367/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0645 - accuracy: 0.9772 - val_loss: 1.4362 - val_accuracy: 0.8656\n",
            "Epoch 368/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0858 - accuracy: 0.9706 - val_loss: 1.4281 - val_accuracy: 0.8723\n",
            "Epoch 369/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0482 - accuracy: 0.9823 - val_loss: 1.4744 - val_accuracy: 0.8700\n",
            "Epoch 370/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0429 - accuracy: 0.9830 - val_loss: 1.4364 - val_accuracy: 0.8727\n",
            "Epoch 371/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0389 - accuracy: 0.9856 - val_loss: 1.4156 - val_accuracy: 0.8769\n",
            "Epoch 372/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9826 - val_loss: 1.5588 - val_accuracy: 0.8723\n",
            "Epoch 373/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9849 - val_loss: 1.4316 - val_accuracy: 0.8698\n",
            "Epoch 374/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0395 - accuracy: 0.9839 - val_loss: 1.5743 - val_accuracy: 0.8647\n",
            "Epoch 375/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0519 - accuracy: 0.9808 - val_loss: 1.4833 - val_accuracy: 0.8703\n",
            "Epoch 376/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0438 - accuracy: 0.9834 - val_loss: 1.5688 - val_accuracy: 0.8672\n",
            "Epoch 377/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0638 - accuracy: 0.9770 - val_loss: 1.5713 - val_accuracy: 0.8705\n",
            "Epoch 378/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0649 - accuracy: 0.9780 - val_loss: 1.4561 - val_accuracy: 0.8669\n",
            "Epoch 379/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0543 - accuracy: 0.9791 - val_loss: 1.4491 - val_accuracy: 0.8683\n",
            "Epoch 380/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0526 - accuracy: 0.9829 - val_loss: 1.3743 - val_accuracy: 0.8722\n",
            "Epoch 381/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0555 - accuracy: 0.9786 - val_loss: 1.3462 - val_accuracy: 0.8759\n",
            "Epoch 382/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0420 - accuracy: 0.9848 - val_loss: 1.3479 - val_accuracy: 0.8697\n",
            "Epoch 383/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0628 - accuracy: 0.9773 - val_loss: 1.4986 - val_accuracy: 0.8678\n",
            "Epoch 384/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0483 - accuracy: 0.9812 - val_loss: 1.3418 - val_accuracy: 0.8698\n",
            "Epoch 385/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9831 - val_loss: 1.4193 - val_accuracy: 0.8698\n",
            "Epoch 386/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0432 - accuracy: 0.9841 - val_loss: 1.5296 - val_accuracy: 0.8705\n",
            "Epoch 387/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0713 - accuracy: 0.9757 - val_loss: 1.4837 - val_accuracy: 0.8622\n",
            "Epoch 388/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0875 - accuracy: 0.9723 - val_loss: 1.3888 - val_accuracy: 0.8750\n",
            "Epoch 389/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0566 - accuracy: 0.9784 - val_loss: 1.4185 - val_accuracy: 0.8728\n",
            "Epoch 390/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0544 - accuracy: 0.9793 - val_loss: 1.4116 - val_accuracy: 0.8722\n",
            "Epoch 391/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0456 - accuracy: 0.9835 - val_loss: 1.4133 - val_accuracy: 0.8716\n",
            "Epoch 392/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0427 - accuracy: 0.9838 - val_loss: 1.3874 - val_accuracy: 0.8712\n",
            "Epoch 393/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0400 - accuracy: 0.9845 - val_loss: 1.4204 - val_accuracy: 0.8727\n",
            "Epoch 394/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0493 - accuracy: 0.9806 - val_loss: 1.3952 - val_accuracy: 0.8712\n",
            "Epoch 395/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0486 - accuracy: 0.9812 - val_loss: 1.3834 - val_accuracy: 0.8695\n",
            "Epoch 396/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0408 - accuracy: 0.9848 - val_loss: 1.4788 - val_accuracy: 0.8652\n",
            "Epoch 397/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0504 - accuracy: 0.9818 - val_loss: 1.3664 - val_accuracy: 0.8733\n",
            "Epoch 398/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0366 - accuracy: 0.9859 - val_loss: 1.4085 - val_accuracy: 0.8728\n",
            "Epoch 399/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0367 - accuracy: 0.9853 - val_loss: 1.4428 - val_accuracy: 0.8723\n",
            "Epoch 400/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0439 - accuracy: 0.9839 - val_loss: 1.5451 - val_accuracy: 0.8705\n",
            "Epoch 401/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0390 - accuracy: 0.9848 - val_loss: 1.4232 - val_accuracy: 0.8669\n",
            "Epoch 402/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0441 - accuracy: 0.9830 - val_loss: 1.4666 - val_accuracy: 0.8669\n",
            "Epoch 403/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0493 - accuracy: 0.9818 - val_loss: 1.3938 - val_accuracy: 0.8747\n",
            "Epoch 404/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9809 - val_loss: 1.4565 - val_accuracy: 0.8698\n",
            "Epoch 405/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0431 - accuracy: 0.9831 - val_loss: 1.5442 - val_accuracy: 0.8731\n",
            "Epoch 406/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0425 - accuracy: 0.9838 - val_loss: 1.4645 - val_accuracy: 0.8728\n",
            "Epoch 407/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0631 - accuracy: 0.9783 - val_loss: 1.4401 - val_accuracy: 0.8692\n",
            "Epoch 408/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 1.4199 - val_accuracy: 0.8686\n",
            "Epoch 409/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0513 - accuracy: 0.9810 - val_loss: 1.3549 - val_accuracy: 0.8698\n",
            "Epoch 410/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0477 - accuracy: 0.9824 - val_loss: 1.4174 - val_accuracy: 0.8763\n",
            "Epoch 411/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0493 - accuracy: 0.9805 - val_loss: 1.3635 - val_accuracy: 0.8758\n",
            "Epoch 412/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9841 - val_loss: 1.5011 - val_accuracy: 0.8686\n",
            "Epoch 413/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0525 - accuracy: 0.9805 - val_loss: 1.3526 - val_accuracy: 0.8736\n",
            "Epoch 414/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0603 - accuracy: 0.9777 - val_loss: 1.5921 - val_accuracy: 0.8672\n",
            "Epoch 415/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0623 - accuracy: 0.9779 - val_loss: 1.3737 - val_accuracy: 0.8720\n",
            "Epoch 416/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0462 - accuracy: 0.9826 - val_loss: 1.4519 - val_accuracy: 0.8683\n",
            "Epoch 417/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0537 - accuracy: 0.9809 - val_loss: 1.3072 - val_accuracy: 0.8755\n",
            "Epoch 418/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0399 - accuracy: 0.9841 - val_loss: 1.5361 - val_accuracy: 0.8698\n",
            "Epoch 419/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0467 - accuracy: 0.9837 - val_loss: 1.4437 - val_accuracy: 0.8714\n",
            "Epoch 420/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0499 - accuracy: 0.9815 - val_loss: 1.4375 - val_accuracy: 0.8666\n",
            "Epoch 421/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0520 - accuracy: 0.9810 - val_loss: 1.5262 - val_accuracy: 0.8670\n",
            "Epoch 422/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0603 - accuracy: 0.9797 - val_loss: 1.3669 - val_accuracy: 0.8702\n",
            "Epoch 423/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9837 - val_loss: 1.4109 - val_accuracy: 0.8658\n",
            "Epoch 424/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0463 - accuracy: 0.9832 - val_loss: 1.5249 - val_accuracy: 0.8711\n",
            "Epoch 425/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0530 - accuracy: 0.9791 - val_loss: 1.4440 - val_accuracy: 0.8691\n",
            "Epoch 426/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0497 - accuracy: 0.9826 - val_loss: 1.4120 - val_accuracy: 0.8698\n",
            "Epoch 427/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9834 - val_loss: 1.4031 - val_accuracy: 0.8753\n",
            "Epoch 428/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0373 - accuracy: 0.9852 - val_loss: 1.4825 - val_accuracy: 0.8734\n",
            "Epoch 429/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0557 - accuracy: 0.9816 - val_loss: 1.4612 - val_accuracy: 0.8706\n",
            "Epoch 430/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0599 - accuracy: 0.9786 - val_loss: 1.4480 - val_accuracy: 0.8742\n",
            "Epoch 431/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0436 - accuracy: 0.9837 - val_loss: 1.3679 - val_accuracy: 0.8708\n",
            "Epoch 432/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0453 - accuracy: 0.9828 - val_loss: 1.4675 - val_accuracy: 0.8725\n",
            "Epoch 433/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0456 - accuracy: 0.9835 - val_loss: 1.4455 - val_accuracy: 0.8689\n",
            "Epoch 434/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0529 - accuracy: 0.9809 - val_loss: 1.4338 - val_accuracy: 0.8687\n",
            "Epoch 435/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0485 - accuracy: 0.9810 - val_loss: 1.5446 - val_accuracy: 0.8664\n",
            "Epoch 436/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0438 - accuracy: 0.9834 - val_loss: 1.4944 - val_accuracy: 0.8728\n",
            "Epoch 437/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0484 - accuracy: 0.9809 - val_loss: 1.3574 - val_accuracy: 0.8736\n",
            "Epoch 438/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9863 - val_loss: 1.5239 - val_accuracy: 0.8677\n",
            "Epoch 439/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0442 - accuracy: 0.9829 - val_loss: 1.5057 - val_accuracy: 0.8691\n",
            "Epoch 440/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0422 - accuracy: 0.9841 - val_loss: 1.4216 - val_accuracy: 0.8681\n",
            "Epoch 441/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0397 - accuracy: 0.9845 - val_loss: 1.3979 - val_accuracy: 0.8669\n",
            "Epoch 442/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 1.5866 - val_accuracy: 0.8645\n",
            "Epoch 443/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0666 - accuracy: 0.9770 - val_loss: 1.4583 - val_accuracy: 0.8686\n",
            "Epoch 444/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0436 - accuracy: 0.9830 - val_loss: 1.4340 - val_accuracy: 0.8695\n",
            "Epoch 445/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0491 - accuracy: 0.9833 - val_loss: 1.4073 - val_accuracy: 0.8723\n",
            "Epoch 446/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0405 - accuracy: 0.9840 - val_loss: 1.4091 - val_accuracy: 0.8695\n",
            "Epoch 447/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0413 - accuracy: 0.9846 - val_loss: 1.5135 - val_accuracy: 0.8702\n",
            "Epoch 448/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0430 - accuracy: 0.9827 - val_loss: 1.4584 - val_accuracy: 0.8731\n",
            "Epoch 449/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0356 - accuracy: 0.9870 - val_loss: 1.4602 - val_accuracy: 0.8641\n",
            "Epoch 450/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0477 - accuracy: 0.9832 - val_loss: 1.4097 - val_accuracy: 0.8719\n",
            "Epoch 451/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0410 - accuracy: 0.9842 - val_loss: 1.4879 - val_accuracy: 0.8670\n",
            "Epoch 452/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0547 - accuracy: 0.9809 - val_loss: 1.4869 - val_accuracy: 0.8691\n",
            "Epoch 453/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0549 - accuracy: 0.9807 - val_loss: 1.5639 - val_accuracy: 0.8691\n",
            "Epoch 454/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0706 - accuracy: 0.9760 - val_loss: 1.5048 - val_accuracy: 0.8655\n",
            "Epoch 455/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0663 - accuracy: 0.9774 - val_loss: 1.5884 - val_accuracy: 0.8680\n",
            "Epoch 456/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0658 - accuracy: 0.9771 - val_loss: 1.5126 - val_accuracy: 0.8678\n",
            "Epoch 457/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0503 - accuracy: 0.9830 - val_loss: 1.4714 - val_accuracy: 0.8687\n",
            "Epoch 458/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0577 - accuracy: 0.9794 - val_loss: 1.5258 - val_accuracy: 0.8755\n",
            "Epoch 459/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9837 - val_loss: 1.4234 - val_accuracy: 0.8741\n",
            "Epoch 460/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0485 - accuracy: 0.9823 - val_loss: 1.4474 - val_accuracy: 0.8703\n",
            "Epoch 461/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0552 - accuracy: 0.9816 - val_loss: 1.5591 - val_accuracy: 0.8673\n",
            "Epoch 462/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0407 - accuracy: 0.9845 - val_loss: 1.4718 - val_accuracy: 0.8728\n",
            "Epoch 463/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0459 - accuracy: 0.9819 - val_loss: 1.4915 - val_accuracy: 0.8681\n",
            "Epoch 464/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0548 - accuracy: 0.9802 - val_loss: 1.4434 - val_accuracy: 0.8727\n",
            "Epoch 465/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0466 - accuracy: 0.9825 - val_loss: 1.4843 - val_accuracy: 0.8708\n",
            "Epoch 466/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0420 - accuracy: 0.9846 - val_loss: 1.5252 - val_accuracy: 0.8680\n",
            "Epoch 467/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0626 - accuracy: 0.9772 - val_loss: 1.4636 - val_accuracy: 0.8695\n",
            "Epoch 468/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 1.4345 - val_accuracy: 0.8728\n",
            "Epoch 469/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0399 - accuracy: 0.9848 - val_loss: 1.4595 - val_accuracy: 0.8706\n",
            "Epoch 470/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0475 - accuracy: 0.9823 - val_loss: 1.5828 - val_accuracy: 0.8673\n",
            "Epoch 471/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0457 - accuracy: 0.9841 - val_loss: 1.5167 - val_accuracy: 0.8692\n",
            "Epoch 472/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0500 - accuracy: 0.9824 - val_loss: 1.5370 - val_accuracy: 0.8728\n",
            "Epoch 473/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0536 - accuracy: 0.9802 - val_loss: 1.5294 - val_accuracy: 0.8697\n",
            "Epoch 474/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0423 - accuracy: 0.9848 - val_loss: 1.4615 - val_accuracy: 0.8756\n",
            "Epoch 475/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0449 - accuracy: 0.9824 - val_loss: 1.5863 - val_accuracy: 0.8719\n",
            "Epoch 476/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0435 - accuracy: 0.9852 - val_loss: 1.4881 - val_accuracy: 0.8698\n",
            "Epoch 477/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0520 - accuracy: 0.9826 - val_loss: 1.5656 - val_accuracy: 0.8697\n",
            "Epoch 478/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0478 - accuracy: 0.9816 - val_loss: 1.4487 - val_accuracy: 0.8748\n",
            "Epoch 479/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0595 - accuracy: 0.9810 - val_loss: 1.4763 - val_accuracy: 0.8723\n",
            "Epoch 480/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0416 - accuracy: 0.9834 - val_loss: 1.5429 - val_accuracy: 0.8692\n",
            "Epoch 481/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0359 - accuracy: 0.9871 - val_loss: 1.5276 - val_accuracy: 0.8672\n",
            "Epoch 482/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9876 - val_loss: 1.4772 - val_accuracy: 0.8717\n",
            "Epoch 483/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9877 - val_loss: 1.4516 - val_accuracy: 0.8703\n",
            "Epoch 484/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0442 - accuracy: 0.9830 - val_loss: 1.4512 - val_accuracy: 0.8708\n",
            "Epoch 485/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0483 - accuracy: 0.9834 - val_loss: 1.5440 - val_accuracy: 0.8636\n",
            "Epoch 486/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 1.5046 - val_accuracy: 0.8725\n",
            "Epoch 487/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0371 - accuracy: 0.9853 - val_loss: 1.5333 - val_accuracy: 0.8686\n",
            "Epoch 488/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9853 - val_loss: 1.4776 - val_accuracy: 0.8745\n",
            "Epoch 489/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0391 - accuracy: 0.9858 - val_loss: 1.6773 - val_accuracy: 0.8702\n",
            "Epoch 490/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0366 - accuracy: 0.9869 - val_loss: 1.5324 - val_accuracy: 0.8692\n",
            "Epoch 491/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0550 - accuracy: 0.9805 - val_loss: 1.5028 - val_accuracy: 0.8683\n",
            "Epoch 492/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0651 - accuracy: 0.9777 - val_loss: 1.4532 - val_accuracy: 0.8712\n",
            "Epoch 493/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0452 - accuracy: 0.9834 - val_loss: 1.5195 - val_accuracy: 0.8702\n",
            "Epoch 494/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0442 - accuracy: 0.9841 - val_loss: 1.5775 - val_accuracy: 0.8669\n",
            "Epoch 495/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0470 - accuracy: 0.9836 - val_loss: 1.5527 - val_accuracy: 0.8711\n",
            "Epoch 496/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0678 - accuracy: 0.9776 - val_loss: 1.5524 - val_accuracy: 0.8734\n",
            "Epoch 497/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0518 - accuracy: 0.9805 - val_loss: 1.4621 - val_accuracy: 0.8737\n",
            "Epoch 498/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0436 - accuracy: 0.9841 - val_loss: 1.3391 - val_accuracy: 0.8664\n",
            "Epoch 499/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0405 - accuracy: 0.9841 - val_loss: 1.5518 - val_accuracy: 0.8700\n",
            "Epoch 500/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0335 - accuracy: 0.9866 - val_loss: 1.4741 - val_accuracy: 0.8730\n",
            "Epoch 501/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9871 - val_loss: 1.5578 - val_accuracy: 0.8698\n",
            "Epoch 502/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0364 - accuracy: 0.9852 - val_loss: 1.5760 - val_accuracy: 0.8728\n",
            "Epoch 503/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0378 - accuracy: 0.9859 - val_loss: 1.6131 - val_accuracy: 0.8705\n",
            "Epoch 504/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0434 - accuracy: 0.9836 - val_loss: 1.4770 - val_accuracy: 0.8727\n",
            "Epoch 505/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9874 - val_loss: 1.5163 - val_accuracy: 0.8684\n",
            "Epoch 506/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0483 - accuracy: 0.9835 - val_loss: 1.5083 - val_accuracy: 0.8714\n",
            "Epoch 507/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9825 - val_loss: 1.5558 - val_accuracy: 0.8702\n",
            "Epoch 508/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0424 - accuracy: 0.9846 - val_loss: 1.5929 - val_accuracy: 0.8719\n",
            "Epoch 509/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9862 - val_loss: 1.5180 - val_accuracy: 0.8748\n",
            "Epoch 510/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0504 - accuracy: 0.9822 - val_loss: 1.4637 - val_accuracy: 0.8711\n",
            "Epoch 511/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0373 - accuracy: 0.9843 - val_loss: 1.5566 - val_accuracy: 0.8692\n",
            "Epoch 512/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0367 - accuracy: 0.9856 - val_loss: 1.3821 - val_accuracy: 0.8694\n",
            "Epoch 513/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9866 - val_loss: 1.5933 - val_accuracy: 0.8633\n",
            "Epoch 514/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0536 - accuracy: 0.9797 - val_loss: 1.4648 - val_accuracy: 0.8712\n",
            "Epoch 515/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0433 - accuracy: 0.9836 - val_loss: 1.4766 - val_accuracy: 0.8705\n",
            "Epoch 516/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0502 - accuracy: 0.9808 - val_loss: 1.4877 - val_accuracy: 0.8737\n",
            "Epoch 517/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0608 - accuracy: 0.9782 - val_loss: 1.6093 - val_accuracy: 0.8691\n",
            "Epoch 518/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0595 - accuracy: 0.9790 - val_loss: 1.4733 - val_accuracy: 0.8683\n",
            "Epoch 519/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0514 - accuracy: 0.9823 - val_loss: 1.4686 - val_accuracy: 0.8714\n",
            "Epoch 520/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0525 - accuracy: 0.9812 - val_loss: 1.4675 - val_accuracy: 0.8723\n",
            "Epoch 521/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0469 - accuracy: 0.9811 - val_loss: 1.5180 - val_accuracy: 0.8687\n",
            "Epoch 522/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0484 - accuracy: 0.9820 - val_loss: 1.4881 - val_accuracy: 0.8687\n",
            "Epoch 523/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0503 - accuracy: 0.9826 - val_loss: 1.5798 - val_accuracy: 0.8700\n",
            "Epoch 524/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0655 - accuracy: 0.9789 - val_loss: 1.5767 - val_accuracy: 0.8689\n",
            "Epoch 525/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0438 - accuracy: 0.9842 - val_loss: 1.5148 - val_accuracy: 0.8681\n",
            "Epoch 526/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0416 - accuracy: 0.9851 - val_loss: 1.4721 - val_accuracy: 0.8698\n",
            "Epoch 527/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0489 - accuracy: 0.9819 - val_loss: 1.6089 - val_accuracy: 0.8683\n",
            "Epoch 528/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0414 - accuracy: 0.9846 - val_loss: 1.4820 - val_accuracy: 0.8680\n",
            "Epoch 529/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0386 - accuracy: 0.9848 - val_loss: 1.4722 - val_accuracy: 0.8706\n",
            "Epoch 530/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0453 - accuracy: 0.9842 - val_loss: 1.5286 - val_accuracy: 0.8766\n",
            "Epoch 531/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0369 - accuracy: 0.9859 - val_loss: 1.6446 - val_accuracy: 0.8698\n",
            "Epoch 532/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0406 - accuracy: 0.9864 - val_loss: 1.5320 - val_accuracy: 0.8683\n",
            "Epoch 533/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9852 - val_loss: 1.5317 - val_accuracy: 0.8727\n",
            "Epoch 534/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0557 - accuracy: 0.9811 - val_loss: 1.5476 - val_accuracy: 0.8689\n",
            "Epoch 535/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0571 - accuracy: 0.9801 - val_loss: 1.5026 - val_accuracy: 0.8744\n",
            "Epoch 536/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0625 - accuracy: 0.9805 - val_loss: 1.5847 - val_accuracy: 0.8672\n",
            "Epoch 537/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0439 - accuracy: 0.9852 - val_loss: 1.6190 - val_accuracy: 0.8650\n",
            "Epoch 538/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0396 - accuracy: 0.9855 - val_loss: 1.5822 - val_accuracy: 0.8702\n",
            "Epoch 539/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0529 - accuracy: 0.9818 - val_loss: 1.5405 - val_accuracy: 0.8703\n",
            "Epoch 540/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0446 - accuracy: 0.9845 - val_loss: 1.4443 - val_accuracy: 0.8659\n",
            "Epoch 541/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0416 - accuracy: 0.9841 - val_loss: 1.5793 - val_accuracy: 0.8702\n",
            "Epoch 542/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0335 - accuracy: 0.9868 - val_loss: 1.5254 - val_accuracy: 0.8677\n",
            "Epoch 543/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0478 - accuracy: 0.9835 - val_loss: 1.5018 - val_accuracy: 0.8687\n",
            "Epoch 544/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0545 - accuracy: 0.9802 - val_loss: 1.4868 - val_accuracy: 0.8727\n",
            "Epoch 545/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0568 - accuracy: 0.9809 - val_loss: 1.6573 - val_accuracy: 0.8716\n",
            "Epoch 546/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0597 - accuracy: 0.9818 - val_loss: 1.5582 - val_accuracy: 0.8739\n",
            "Epoch 547/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0370 - accuracy: 0.9855 - val_loss: 1.6241 - val_accuracy: 0.8759\n",
            "Epoch 548/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0403 - accuracy: 0.9863 - val_loss: 1.5014 - val_accuracy: 0.8727\n",
            "Epoch 549/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9872 - val_loss: 1.5143 - val_accuracy: 0.8758\n",
            "Epoch 550/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0457 - accuracy: 0.9839 - val_loss: 1.5734 - val_accuracy: 0.8698\n",
            "Epoch 551/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9855 - val_loss: 1.5403 - val_accuracy: 0.8734\n",
            "Epoch 552/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0390 - accuracy: 0.9859 - val_loss: 1.5447 - val_accuracy: 0.8677\n",
            "Epoch 553/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0447 - accuracy: 0.9826 - val_loss: 1.5156 - val_accuracy: 0.8700\n",
            "Epoch 554/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0440 - accuracy: 0.9836 - val_loss: 1.4773 - val_accuracy: 0.8653\n",
            "Epoch 555/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0396 - accuracy: 0.9864 - val_loss: 1.6413 - val_accuracy: 0.8702\n",
            "Epoch 556/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0745 - accuracy: 0.9777 - val_loss: 1.5439 - val_accuracy: 0.8703\n",
            "Epoch 557/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0420 - accuracy: 0.9853 - val_loss: 1.4898 - val_accuracy: 0.8753\n",
            "Epoch 558/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0355 - accuracy: 0.9863 - val_loss: 1.5173 - val_accuracy: 0.8730\n",
            "Epoch 559/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0498 - accuracy: 0.9827 - val_loss: 1.4774 - val_accuracy: 0.8733\n",
            "Epoch 560/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0449 - accuracy: 0.9834 - val_loss: 1.5264 - val_accuracy: 0.8750\n",
            "Epoch 561/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9870 - val_loss: 1.6044 - val_accuracy: 0.8737\n",
            "Epoch 562/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0497 - accuracy: 0.9823 - val_loss: 1.6090 - val_accuracy: 0.8723\n",
            "Epoch 563/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9824 - val_loss: 1.5039 - val_accuracy: 0.8717\n",
            "Epoch 564/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0390 - accuracy: 0.9852 - val_loss: 1.5855 - val_accuracy: 0.8737\n",
            "Epoch 565/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9859 - val_loss: 1.6310 - val_accuracy: 0.8686\n",
            "Epoch 566/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0672 - accuracy: 0.9778 - val_loss: 1.6290 - val_accuracy: 0.8611\n",
            "Epoch 567/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9822 - val_loss: 1.4478 - val_accuracy: 0.8687\n",
            "Epoch 568/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0420 - accuracy: 0.9833 - val_loss: 1.5091 - val_accuracy: 0.8689\n",
            "Epoch 569/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0548 - accuracy: 0.9812 - val_loss: 1.6838 - val_accuracy: 0.8708\n",
            "Epoch 570/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0381 - accuracy: 0.9859 - val_loss: 1.5848 - val_accuracy: 0.8730\n",
            "Epoch 571/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0378 - accuracy: 0.9873 - val_loss: 1.4933 - val_accuracy: 0.8734\n",
            "Epoch 572/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9874 - val_loss: 1.5423 - val_accuracy: 0.8723\n",
            "Epoch 573/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 1.5066 - val_accuracy: 0.8694\n",
            "Epoch 574/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0431 - accuracy: 0.9856 - val_loss: 1.5617 - val_accuracy: 0.8705\n",
            "Epoch 575/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9849 - val_loss: 1.5700 - val_accuracy: 0.8759\n",
            "Epoch 576/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0375 - accuracy: 0.9850 - val_loss: 1.6197 - val_accuracy: 0.8683\n",
            "Epoch 577/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9855 - val_loss: 1.6421 - val_accuracy: 0.8709\n",
            "Epoch 578/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0543 - accuracy: 0.9818 - val_loss: 1.6154 - val_accuracy: 0.8755\n",
            "Epoch 579/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 1.6108 - val_accuracy: 0.8764\n",
            "Epoch 580/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9859 - val_loss: 1.6478 - val_accuracy: 0.8658\n",
            "Epoch 581/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0358 - accuracy: 0.9854 - val_loss: 1.5180 - val_accuracy: 0.8669\n",
            "Epoch 582/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0471 - accuracy: 0.9822 - val_loss: 1.5126 - val_accuracy: 0.8725\n",
            "Epoch 583/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0539 - accuracy: 0.9817 - val_loss: 1.6433 - val_accuracy: 0.8725\n",
            "Epoch 584/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0559 - accuracy: 0.9795 - val_loss: 1.5735 - val_accuracy: 0.8727\n",
            "Epoch 585/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0438 - accuracy: 0.9836 - val_loss: 1.5436 - val_accuracy: 0.8748\n",
            "Epoch 586/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9848 - val_loss: 1.5368 - val_accuracy: 0.8781\n",
            "Epoch 587/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0655 - accuracy: 0.9791 - val_loss: 1.4724 - val_accuracy: 0.8764\n",
            "Epoch 588/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9852 - val_loss: 1.5534 - val_accuracy: 0.8673\n",
            "Epoch 589/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0452 - accuracy: 0.9831 - val_loss: 1.7452 - val_accuracy: 0.8703\n",
            "Epoch 590/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0404 - accuracy: 0.9841 - val_loss: 1.4876 - val_accuracy: 0.8675\n",
            "Epoch 591/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0420 - accuracy: 0.9849 - val_loss: 1.5807 - val_accuracy: 0.8730\n",
            "Epoch 592/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0366 - accuracy: 0.9879 - val_loss: 1.6251 - val_accuracy: 0.8731\n",
            "Epoch 593/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0302 - accuracy: 0.9888 - val_loss: 1.5354 - val_accuracy: 0.8695\n",
            "Epoch 594/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9835 - val_loss: 1.6635 - val_accuracy: 0.8647\n",
            "Epoch 595/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0396 - accuracy: 0.9856 - val_loss: 1.5690 - val_accuracy: 0.8711\n",
            "Epoch 596/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0415 - accuracy: 0.9845 - val_loss: 1.5778 - val_accuracy: 0.8689\n",
            "Epoch 597/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0335 - accuracy: 0.9869 - val_loss: 1.6334 - val_accuracy: 0.8681\n",
            "Epoch 598/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0527 - accuracy: 0.9807 - val_loss: 1.6366 - val_accuracy: 0.8653\n",
            "Epoch 599/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0713 - accuracy: 0.9750 - val_loss: 1.4575 - val_accuracy: 0.8711\n",
            "Epoch 600/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0547 - accuracy: 0.9809 - val_loss: 1.4576 - val_accuracy: 0.8725\n",
            "Epoch 601/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0462 - accuracy: 0.9830 - val_loss: 1.5962 - val_accuracy: 0.8720\n",
            "Epoch 602/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0503 - accuracy: 0.9814 - val_loss: 1.7092 - val_accuracy: 0.8697\n",
            "Epoch 603/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0447 - accuracy: 0.9830 - val_loss: 1.5361 - val_accuracy: 0.8692\n",
            "Epoch 604/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9849 - val_loss: 1.5575 - val_accuracy: 0.8728\n",
            "Epoch 605/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9825 - val_loss: 1.5539 - val_accuracy: 0.8728\n",
            "Epoch 606/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0464 - accuracy: 0.9832 - val_loss: 1.6867 - val_accuracy: 0.8716\n",
            "Epoch 607/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 1.5598 - val_accuracy: 0.8716\n",
            "Epoch 608/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0496 - accuracy: 0.9817 - val_loss: 1.6594 - val_accuracy: 0.8709\n",
            "Epoch 609/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9815 - val_loss: 1.4964 - val_accuracy: 0.8728\n",
            "Epoch 610/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9861 - val_loss: 1.5613 - val_accuracy: 0.8730\n",
            "Epoch 611/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0433 - accuracy: 0.9851 - val_loss: 1.5798 - val_accuracy: 0.8727\n",
            "Epoch 612/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0509 - accuracy: 0.9830 - val_loss: 1.5959 - val_accuracy: 0.8720\n",
            "Epoch 613/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0434 - accuracy: 0.9841 - val_loss: 1.6030 - val_accuracy: 0.8675\n",
            "Epoch 614/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9859 - val_loss: 1.5438 - val_accuracy: 0.8755\n",
            "Epoch 615/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0333 - accuracy: 0.9870 - val_loss: 1.6086 - val_accuracy: 0.8655\n",
            "Epoch 616/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9859 - val_loss: 1.6685 - val_accuracy: 0.8717\n",
            "Epoch 617/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9866 - val_loss: 1.5764 - val_accuracy: 0.8716\n",
            "Epoch 618/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9872 - val_loss: 1.6968 - val_accuracy: 0.8670\n",
            "Epoch 619/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9829 - val_loss: 1.7370 - val_accuracy: 0.8666\n",
            "Epoch 620/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0504 - accuracy: 0.9823 - val_loss: 1.6436 - val_accuracy: 0.8692\n",
            "Epoch 621/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0389 - accuracy: 0.9856 - val_loss: 1.6461 - val_accuracy: 0.8731\n",
            "Epoch 622/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0380 - accuracy: 0.9855 - val_loss: 1.5800 - val_accuracy: 0.8687\n",
            "Epoch 623/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0334 - accuracy: 0.9874 - val_loss: 1.5636 - val_accuracy: 0.8720\n",
            "Epoch 624/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0334 - accuracy: 0.9870 - val_loss: 1.5580 - val_accuracy: 0.8772\n",
            "Epoch 625/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9872 - val_loss: 1.6270 - val_accuracy: 0.8730\n",
            "Epoch 626/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0404 - accuracy: 0.9850 - val_loss: 1.6282 - val_accuracy: 0.8748\n",
            "Epoch 627/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9864 - val_loss: 1.6323 - val_accuracy: 0.8694\n",
            "Epoch 628/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0604 - accuracy: 0.9773 - val_loss: 1.5218 - val_accuracy: 0.8730\n",
            "Epoch 629/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0439 - accuracy: 0.9845 - val_loss: 1.5298 - val_accuracy: 0.8706\n",
            "Epoch 630/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0444 - accuracy: 0.9845 - val_loss: 1.7180 - val_accuracy: 0.8656\n",
            "Epoch 631/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0404 - accuracy: 0.9847 - val_loss: 1.6560 - val_accuracy: 0.8711\n",
            "Epoch 632/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0506 - accuracy: 0.9821 - val_loss: 1.6006 - val_accuracy: 0.8694\n",
            "Epoch 633/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0440 - accuracy: 0.9846 - val_loss: 1.6613 - val_accuracy: 0.8702\n",
            "Epoch 634/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0477 - accuracy: 0.9834 - val_loss: 1.7039 - val_accuracy: 0.8698\n",
            "Epoch 635/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0379 - accuracy: 0.9864 - val_loss: 1.6484 - val_accuracy: 0.8703\n",
            "Epoch 636/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0480 - accuracy: 0.9828 - val_loss: 1.6691 - val_accuracy: 0.8712\n",
            "Epoch 637/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0480 - accuracy: 0.9827 - val_loss: 1.6775 - val_accuracy: 0.8717\n",
            "Epoch 638/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0478 - accuracy: 0.9822 - val_loss: 1.5717 - val_accuracy: 0.8694\n",
            "Epoch 639/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0437 - accuracy: 0.9845 - val_loss: 1.6434 - val_accuracy: 0.8723\n",
            "Epoch 640/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0399 - accuracy: 0.9858 - val_loss: 1.6259 - val_accuracy: 0.8714\n",
            "Epoch 641/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0340 - accuracy: 0.9871 - val_loss: 1.7827 - val_accuracy: 0.8692\n",
            "Epoch 642/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0387 - accuracy: 0.9841 - val_loss: 1.6004 - val_accuracy: 0.8694\n",
            "Epoch 643/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 1.5990 - val_accuracy: 0.8673\n",
            "Epoch 644/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0445 - accuracy: 0.9850 - val_loss: 1.7476 - val_accuracy: 0.8708\n",
            "Epoch 645/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9865 - val_loss: 1.5907 - val_accuracy: 0.8723\n",
            "Epoch 646/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 1.7800 - val_accuracy: 0.8670\n",
            "Epoch 647/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0533 - accuracy: 0.9815 - val_loss: 1.6619 - val_accuracy: 0.8697\n",
            "Epoch 648/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0543 - accuracy: 0.9820 - val_loss: 1.6447 - val_accuracy: 0.8684\n",
            "Epoch 649/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0507 - accuracy: 0.9825 - val_loss: 1.6816 - val_accuracy: 0.8748\n",
            "Epoch 650/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0389 - accuracy: 0.9854 - val_loss: 1.6201 - val_accuracy: 0.8747\n",
            "Epoch 651/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0424 - accuracy: 0.9833 - val_loss: 1.6247 - val_accuracy: 0.8758\n",
            "Epoch 652/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0433 - accuracy: 0.9848 - val_loss: 1.6216 - val_accuracy: 0.8727\n",
            "Epoch 653/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0429 - accuracy: 0.9844 - val_loss: 1.6493 - val_accuracy: 0.8711\n",
            "Epoch 654/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0405 - accuracy: 0.9855 - val_loss: 1.5633 - val_accuracy: 0.8728\n",
            "Epoch 655/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0550 - accuracy: 0.9807 - val_loss: 1.6846 - val_accuracy: 0.8669\n",
            "Epoch 656/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9857 - val_loss: 1.6049 - val_accuracy: 0.8736\n",
            "Epoch 657/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0475 - accuracy: 0.9824 - val_loss: 1.6257 - val_accuracy: 0.8737\n",
            "Epoch 658/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0737 - accuracy: 0.9766 - val_loss: 1.8194 - val_accuracy: 0.8622\n",
            "Epoch 659/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 1.5689 - val_accuracy: 0.8722\n",
            "Epoch 660/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0459 - accuracy: 0.9845 - val_loss: 1.5462 - val_accuracy: 0.8730\n",
            "Epoch 661/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0359 - accuracy: 0.9858 - val_loss: 1.6700 - val_accuracy: 0.8730\n",
            "Epoch 662/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9855 - val_loss: 1.6389 - val_accuracy: 0.8697\n",
            "Epoch 663/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9772 - val_loss: 1.6788 - val_accuracy: 0.8658\n",
            "Epoch 664/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0791 - accuracy: 0.9738 - val_loss: 1.5812 - val_accuracy: 0.8672\n",
            "Epoch 665/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0449 - accuracy: 0.9843 - val_loss: 1.5932 - val_accuracy: 0.8711\n",
            "Epoch 666/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0365 - accuracy: 0.9860 - val_loss: 1.5504 - val_accuracy: 0.8755\n",
            "Epoch 667/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0466 - accuracy: 0.9845 - val_loss: 1.7238 - val_accuracy: 0.8641\n",
            "Epoch 668/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 1.6176 - val_accuracy: 0.8736\n",
            "Epoch 669/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0381 - accuracy: 0.9856 - val_loss: 1.6269 - val_accuracy: 0.8675\n",
            "Epoch 670/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0435 - accuracy: 0.9848 - val_loss: 1.6386 - val_accuracy: 0.8686\n",
            "Epoch 671/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0387 - accuracy: 0.9855 - val_loss: 1.5428 - val_accuracy: 0.8753\n",
            "Epoch 672/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 1.6027 - val_accuracy: 0.8722\n",
            "Epoch 673/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0299 - accuracy: 0.9888 - val_loss: 1.6013 - val_accuracy: 0.8744\n",
            "Epoch 674/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0438 - accuracy: 0.9841 - val_loss: 1.8447 - val_accuracy: 0.8702\n",
            "Epoch 675/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 1.6070 - val_accuracy: 0.8737\n",
            "Epoch 676/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9864 - val_loss: 1.5631 - val_accuracy: 0.8737\n",
            "Epoch 677/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0372 - accuracy: 0.9872 - val_loss: 1.6667 - val_accuracy: 0.8723\n",
            "Epoch 678/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0492 - accuracy: 0.9828 - val_loss: 1.6056 - val_accuracy: 0.8748\n",
            "Epoch 679/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0537 - accuracy: 0.9816 - val_loss: 1.5272 - val_accuracy: 0.8730\n",
            "Epoch 680/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0513 - accuracy: 0.9830 - val_loss: 1.5835 - val_accuracy: 0.8681\n",
            "Epoch 681/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0690 - accuracy: 0.9781 - val_loss: 1.5666 - val_accuracy: 0.8730\n",
            "Epoch 682/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0435 - accuracy: 0.9843 - val_loss: 1.6344 - val_accuracy: 0.8745\n",
            "Epoch 683/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0351 - accuracy: 0.9866 - val_loss: 1.6728 - val_accuracy: 0.8709\n",
            "Epoch 684/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0358 - accuracy: 0.9868 - val_loss: 1.5678 - val_accuracy: 0.8745\n",
            "Epoch 685/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0375 - accuracy: 0.9866 - val_loss: 1.5796 - val_accuracy: 0.8753\n",
            "Epoch 686/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0299 - accuracy: 0.9892 - val_loss: 1.7245 - val_accuracy: 0.8709\n",
            "Epoch 687/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0425 - accuracy: 0.9852 - val_loss: 1.6241 - val_accuracy: 0.8691\n",
            "Epoch 688/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0362 - accuracy: 0.9860 - val_loss: 1.6096 - val_accuracy: 0.8714\n",
            "Epoch 689/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0404 - accuracy: 0.9847 - val_loss: 1.5967 - val_accuracy: 0.8744\n",
            "Epoch 690/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0359 - accuracy: 0.9865 - val_loss: 1.6064 - val_accuracy: 0.8734\n",
            "Epoch 691/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9882 - val_loss: 1.5929 - val_accuracy: 0.8705\n",
            "Epoch 692/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9853 - val_loss: 1.8374 - val_accuracy: 0.8641\n",
            "Epoch 693/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0360 - accuracy: 0.9870 - val_loss: 1.6680 - val_accuracy: 0.8716\n",
            "Epoch 694/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0652 - accuracy: 0.9787 - val_loss: 1.6033 - val_accuracy: 0.8697\n",
            "Epoch 695/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0470 - accuracy: 0.9833 - val_loss: 1.7679 - val_accuracy: 0.8697\n",
            "Epoch 696/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0356 - accuracy: 0.9871 - val_loss: 1.7562 - val_accuracy: 0.8709\n",
            "Epoch 697/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0463 - accuracy: 0.9833 - val_loss: 1.7985 - val_accuracy: 0.8642\n",
            "Epoch 698/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0481 - accuracy: 0.9826 - val_loss: 1.6468 - val_accuracy: 0.8700\n",
            "Epoch 699/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0496 - accuracy: 0.9824 - val_loss: 1.6280 - val_accuracy: 0.8752\n",
            "Epoch 700/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0506 - accuracy: 0.9825 - val_loss: 1.6804 - val_accuracy: 0.8722\n",
            "Epoch 701/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9846 - val_loss: 1.6375 - val_accuracy: 0.8691\n",
            "Epoch 702/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0417 - accuracy: 0.9845 - val_loss: 1.6288 - val_accuracy: 0.8719\n",
            "Epoch 703/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0378 - accuracy: 0.9864 - val_loss: 1.5864 - val_accuracy: 0.8747\n",
            "Epoch 704/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0398 - accuracy: 0.9866 - val_loss: 1.6568 - val_accuracy: 0.8709\n",
            "Epoch 705/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9881 - val_loss: 1.7840 - val_accuracy: 0.8667\n",
            "Epoch 706/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 1.6835 - val_accuracy: 0.8673\n",
            "Epoch 707/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0507 - accuracy: 0.9830 - val_loss: 1.6351 - val_accuracy: 0.8694\n",
            "Epoch 708/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0390 - accuracy: 0.9848 - val_loss: 1.6717 - val_accuracy: 0.8739\n",
            "Epoch 709/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 1.7022 - val_accuracy: 0.8714\n",
            "Epoch 710/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0439 - accuracy: 0.9842 - val_loss: 1.7884 - val_accuracy: 0.8708\n",
            "Epoch 711/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0471 - accuracy: 0.9831 - val_loss: 1.7122 - val_accuracy: 0.8700\n",
            "Epoch 712/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0520 - accuracy: 0.9829 - val_loss: 1.5567 - val_accuracy: 0.8722\n",
            "Epoch 713/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0544 - accuracy: 0.9817 - val_loss: 1.5309 - val_accuracy: 0.8784\n",
            "Epoch 714/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 1.7398 - val_accuracy: 0.8686\n",
            "Epoch 715/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0431 - accuracy: 0.9839 - val_loss: 1.6261 - val_accuracy: 0.8730\n",
            "Epoch 716/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0434 - accuracy: 0.9842 - val_loss: 1.6535 - val_accuracy: 0.8655\n",
            "Epoch 717/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0447 - accuracy: 0.9829 - val_loss: 1.6166 - val_accuracy: 0.8722\n",
            "Epoch 718/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0410 - accuracy: 0.9852 - val_loss: 1.5800 - val_accuracy: 0.8742\n",
            "Epoch 719/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9873 - val_loss: 1.6984 - val_accuracy: 0.8695\n",
            "Epoch 720/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9870 - val_loss: 1.6344 - val_accuracy: 0.8748\n",
            "Epoch 721/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0290 - accuracy: 0.9890 - val_loss: 1.5988 - val_accuracy: 0.8672\n",
            "Epoch 722/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9868 - val_loss: 1.7917 - val_accuracy: 0.8694\n",
            "Epoch 723/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0432 - accuracy: 0.9858 - val_loss: 1.7472 - val_accuracy: 0.8719\n",
            "Epoch 724/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9861 - val_loss: 1.6041 - val_accuracy: 0.8750\n",
            "Epoch 725/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0433 - accuracy: 0.9845 - val_loss: 1.7263 - val_accuracy: 0.8733\n",
            "Epoch 726/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0600 - accuracy: 0.9812 - val_loss: 1.5952 - val_accuracy: 0.8739\n",
            "Epoch 727/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0533 - accuracy: 0.9820 - val_loss: 1.6369 - val_accuracy: 0.8736\n",
            "Epoch 728/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0404 - accuracy: 0.9862 - val_loss: 1.7227 - val_accuracy: 0.8702\n",
            "Epoch 729/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0400 - accuracy: 0.9841 - val_loss: 1.6397 - val_accuracy: 0.8678\n",
            "Epoch 730/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0471 - accuracy: 0.9820 - val_loss: 1.7101 - val_accuracy: 0.8686\n",
            "Epoch 731/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0353 - accuracy: 0.9864 - val_loss: 1.6280 - val_accuracy: 0.8697\n",
            "Epoch 732/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9859 - val_loss: 1.5609 - val_accuracy: 0.8737\n",
            "Epoch 733/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0403 - accuracy: 0.9854 - val_loss: 1.7374 - val_accuracy: 0.8709\n",
            "Epoch 734/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0333 - accuracy: 0.9874 - val_loss: 1.6106 - val_accuracy: 0.8697\n",
            "Epoch 735/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9875 - val_loss: 1.7291 - val_accuracy: 0.8675\n",
            "Epoch 736/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0401 - accuracy: 0.9859 - val_loss: 1.5822 - val_accuracy: 0.8750\n",
            "Epoch 737/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0273 - accuracy: 0.9885 - val_loss: 1.7173 - val_accuracy: 0.8719\n",
            "Epoch 738/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 1.6332 - val_accuracy: 0.8692\n",
            "Epoch 739/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0294 - accuracy: 0.9890 - val_loss: 1.6139 - val_accuracy: 0.8709\n",
            "Epoch 740/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0376 - accuracy: 0.9866 - val_loss: 1.4880 - val_accuracy: 0.8761\n",
            "Epoch 741/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0424 - accuracy: 0.9845 - val_loss: 1.6155 - val_accuracy: 0.8742\n",
            "Epoch 742/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0486 - accuracy: 0.9830 - val_loss: 1.7431 - val_accuracy: 0.8722\n",
            "Epoch 743/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0385 - accuracy: 0.9855 - val_loss: 1.6399 - val_accuracy: 0.8733\n",
            "Epoch 744/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0445 - accuracy: 0.9854 - val_loss: 1.6724 - val_accuracy: 0.8686\n",
            "Epoch 745/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0593 - accuracy: 0.9805 - val_loss: 1.7347 - val_accuracy: 0.8720\n",
            "Epoch 746/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0528 - accuracy: 0.9814 - val_loss: 1.7197 - val_accuracy: 0.8631\n",
            "Epoch 747/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 1.8304 - val_accuracy: 0.8627\n",
            "Epoch 748/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0469 - accuracy: 0.9823 - val_loss: 1.6834 - val_accuracy: 0.8683\n",
            "Epoch 749/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9884 - val_loss: 1.6756 - val_accuracy: 0.8703\n",
            "Epoch 750/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 1.6785 - val_accuracy: 0.8725\n",
            "Epoch 751/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0399 - accuracy: 0.9855 - val_loss: 1.6900 - val_accuracy: 0.8753\n",
            "Epoch 752/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9876 - val_loss: 1.8045 - val_accuracy: 0.8686\n",
            "Epoch 753/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0619 - accuracy: 0.9800 - val_loss: 1.6962 - val_accuracy: 0.8647\n",
            "Epoch 754/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0456 - accuracy: 0.9828 - val_loss: 1.7110 - val_accuracy: 0.8714\n",
            "Epoch 755/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0429 - accuracy: 0.9854 - val_loss: 1.6819 - val_accuracy: 0.8736\n",
            "Epoch 756/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0441 - accuracy: 0.9834 - val_loss: 1.7405 - val_accuracy: 0.8719\n",
            "Epoch 757/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0305 - accuracy: 0.9889 - val_loss: 1.7850 - val_accuracy: 0.8703\n",
            "Epoch 758/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 1.7534 - val_accuracy: 0.8670\n",
            "Epoch 759/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0354 - accuracy: 0.9871 - val_loss: 1.6492 - val_accuracy: 0.8773\n",
            "Epoch 760/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9859 - val_loss: 1.6147 - val_accuracy: 0.8692\n",
            "Epoch 761/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0405 - accuracy: 0.9859 - val_loss: 1.6793 - val_accuracy: 0.8737\n",
            "Epoch 762/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9885 - val_loss: 1.6122 - val_accuracy: 0.8748\n",
            "Epoch 763/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0481 - accuracy: 0.9839 - val_loss: 1.7031 - val_accuracy: 0.8695\n",
            "Epoch 764/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0366 - accuracy: 0.9863 - val_loss: 1.7289 - val_accuracy: 0.8744\n",
            "Epoch 765/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0432 - accuracy: 0.9852 - val_loss: 1.6800 - val_accuracy: 0.8716\n",
            "Epoch 766/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9872 - val_loss: 1.6865 - val_accuracy: 0.8741\n",
            "Epoch 767/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0287 - accuracy: 0.9890 - val_loss: 1.6888 - val_accuracy: 0.8716\n",
            "Epoch 768/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0398 - accuracy: 0.9859 - val_loss: 1.6053 - val_accuracy: 0.8789\n",
            "Epoch 769/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0493 - accuracy: 0.9831 - val_loss: 1.6958 - val_accuracy: 0.8719\n",
            "Epoch 770/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0441 - accuracy: 0.9846 - val_loss: 1.8162 - val_accuracy: 0.8677\n",
            "Epoch 771/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0536 - accuracy: 0.9829 - val_loss: 1.7523 - val_accuracy: 0.8711\n",
            "Epoch 772/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9862 - val_loss: 1.7249 - val_accuracy: 0.8678\n",
            "Epoch 773/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 1.7556 - val_accuracy: 0.8716\n",
            "Epoch 774/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - accuracy: 0.9895 - val_loss: 1.7483 - val_accuracy: 0.8744\n",
            "Epoch 775/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 1.7720 - val_accuracy: 0.8692\n",
            "Epoch 776/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0291 - accuracy: 0.9889 - val_loss: 1.6854 - val_accuracy: 0.8712\n",
            "Epoch 777/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0407 - accuracy: 0.9863 - val_loss: 1.7320 - val_accuracy: 0.8759\n",
            "Epoch 778/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0433 - accuracy: 0.9845 - val_loss: 1.7153 - val_accuracy: 0.8745\n",
            "Epoch 779/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0361 - accuracy: 0.9868 - val_loss: 1.6667 - val_accuracy: 0.8731\n",
            "Epoch 780/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0414 - accuracy: 0.9862 - val_loss: 1.7412 - val_accuracy: 0.8698\n",
            "Epoch 781/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0711 - accuracy: 0.9784 - val_loss: 1.7066 - val_accuracy: 0.8728\n",
            "Epoch 782/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0392 - accuracy: 0.9858 - val_loss: 1.6326 - val_accuracy: 0.8716\n",
            "Epoch 783/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0467 - accuracy: 0.9829 - val_loss: 1.6683 - val_accuracy: 0.8753\n",
            "Epoch 784/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 1.7445 - val_accuracy: 0.8730\n",
            "Epoch 785/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 1.7267 - val_accuracy: 0.8719\n",
            "Epoch 786/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0411 - accuracy: 0.9859 - val_loss: 1.7635 - val_accuracy: 0.8727\n",
            "Epoch 787/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0471 - accuracy: 0.9834 - val_loss: 1.5491 - val_accuracy: 0.8706\n",
            "Epoch 788/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0354 - accuracy: 0.9867 - val_loss: 1.6663 - val_accuracy: 0.8734\n",
            "Epoch 789/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0422 - accuracy: 0.9855 - val_loss: 1.7731 - val_accuracy: 0.8714\n",
            "Epoch 790/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0302 - accuracy: 0.9895 - val_loss: 1.6756 - val_accuracy: 0.8733\n",
            "Epoch 791/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0536 - accuracy: 0.9825 - val_loss: 1.6290 - val_accuracy: 0.8684\n",
            "Epoch 792/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0399 - accuracy: 0.9854 - val_loss: 1.7166 - val_accuracy: 0.8678\n",
            "Epoch 793/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0541 - accuracy: 0.9823 - val_loss: 1.7781 - val_accuracy: 0.8673\n",
            "Epoch 794/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0489 - accuracy: 0.9844 - val_loss: 1.8083 - val_accuracy: 0.8658\n",
            "Epoch 795/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0486 - accuracy: 0.9834 - val_loss: 1.7103 - val_accuracy: 0.8714\n",
            "Epoch 796/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9874 - val_loss: 1.6688 - val_accuracy: 0.8706\n",
            "Epoch 797/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0345 - accuracy: 0.9873 - val_loss: 1.8093 - val_accuracy: 0.8694\n",
            "Epoch 798/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0702 - accuracy: 0.9780 - val_loss: 1.7844 - val_accuracy: 0.8723\n",
            "Epoch 799/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9845 - val_loss: 1.6825 - val_accuracy: 0.8725\n",
            "Epoch 800/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0328 - accuracy: 0.9874 - val_loss: 1.6992 - val_accuracy: 0.8723\n",
            "Epoch 801/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 1.5522 - val_accuracy: 0.8742\n",
            "Epoch 802/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9880 - val_loss: 1.5942 - val_accuracy: 0.8741\n",
            "Epoch 803/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9886 - val_loss: 1.7207 - val_accuracy: 0.8733\n",
            "Epoch 804/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9870 - val_loss: 1.7846 - val_accuracy: 0.8755\n",
            "Epoch 805/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9875 - val_loss: 1.6842 - val_accuracy: 0.8719\n",
            "Epoch 806/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0297 - accuracy: 0.9880 - val_loss: 1.6730 - val_accuracy: 0.8763\n",
            "Epoch 807/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 1.6271 - val_accuracy: 0.8695\n",
            "Epoch 808/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0262 - accuracy: 0.9902 - val_loss: 1.7533 - val_accuracy: 0.8730\n",
            "Epoch 809/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0300 - accuracy: 0.9890 - val_loss: 1.7513 - val_accuracy: 0.8736\n",
            "Epoch 810/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0418 - accuracy: 0.9839 - val_loss: 1.7800 - val_accuracy: 0.8700\n",
            "Epoch 811/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9860 - val_loss: 1.8291 - val_accuracy: 0.8763\n",
            "Epoch 812/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9887 - val_loss: 1.7624 - val_accuracy: 0.8681\n",
            "Epoch 813/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9877 - val_loss: 1.7136 - val_accuracy: 0.8733\n",
            "Epoch 814/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0451 - accuracy: 0.9839 - val_loss: 1.7906 - val_accuracy: 0.8675\n",
            "Epoch 815/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0473 - accuracy: 0.9832 - val_loss: 1.7199 - val_accuracy: 0.8714\n",
            "Epoch 816/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0489 - accuracy: 0.9831 - val_loss: 1.7129 - val_accuracy: 0.8737\n",
            "Epoch 817/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0443 - accuracy: 0.9837 - val_loss: 1.8414 - val_accuracy: 0.8695\n",
            "Epoch 818/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9834 - val_loss: 1.7208 - val_accuracy: 0.8716\n",
            "Epoch 819/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0556 - accuracy: 0.9819 - val_loss: 1.6923 - val_accuracy: 0.8727\n",
            "Epoch 820/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0547 - accuracy: 0.9820 - val_loss: 1.9003 - val_accuracy: 0.8706\n",
            "Epoch 821/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0399 - accuracy: 0.9858 - val_loss: 1.7224 - val_accuracy: 0.8709\n",
            "Epoch 822/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0351 - accuracy: 0.9879 - val_loss: 1.7816 - val_accuracy: 0.8737\n",
            "Epoch 823/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9886 - val_loss: 1.6800 - val_accuracy: 0.8731\n",
            "Epoch 824/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 1.7187 - val_accuracy: 0.8689\n",
            "Epoch 825/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9851 - val_loss: 1.7565 - val_accuracy: 0.8747\n",
            "Epoch 826/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0512 - accuracy: 0.9835 - val_loss: 1.8283 - val_accuracy: 0.8725\n",
            "Epoch 827/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9868 - val_loss: 1.7134 - val_accuracy: 0.8759\n",
            "Epoch 828/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0263 - accuracy: 0.9904 - val_loss: 1.7820 - val_accuracy: 0.8739\n",
            "Epoch 829/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - accuracy: 0.9891 - val_loss: 1.6904 - val_accuracy: 0.8700\n",
            "Epoch 830/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0266 - accuracy: 0.9903 - val_loss: 1.7541 - val_accuracy: 0.8717\n",
            "Epoch 831/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0356 - accuracy: 0.9868 - val_loss: 1.8827 - val_accuracy: 0.8731\n",
            "Epoch 832/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0590 - accuracy: 0.9811 - val_loss: 1.8002 - val_accuracy: 0.8662\n",
            "Epoch 833/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0481 - accuracy: 0.9855 - val_loss: 1.7481 - val_accuracy: 0.8689\n",
            "Epoch 834/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9826 - val_loss: 1.8585 - val_accuracy: 0.8739\n",
            "Epoch 835/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0727 - accuracy: 0.9785 - val_loss: 1.7229 - val_accuracy: 0.8722\n",
            "Epoch 836/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9883 - val_loss: 1.7108 - val_accuracy: 0.8759\n",
            "Epoch 837/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0332 - accuracy: 0.9880 - val_loss: 1.6815 - val_accuracy: 0.8711\n",
            "Epoch 838/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9872 - val_loss: 1.7518 - val_accuracy: 0.8706\n",
            "Epoch 839/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0244 - accuracy: 0.9907 - val_loss: 1.7120 - val_accuracy: 0.8734\n",
            "Epoch 840/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0303 - accuracy: 0.9885 - val_loss: 1.8259 - val_accuracy: 0.8727\n",
            "Epoch 841/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0383 - accuracy: 0.9860 - val_loss: 1.8001 - val_accuracy: 0.8730\n",
            "Epoch 842/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0336 - accuracy: 0.9884 - val_loss: 1.7757 - val_accuracy: 0.8727\n",
            "Epoch 843/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9870 - val_loss: 1.7386 - val_accuracy: 0.8745\n",
            "Epoch 844/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0295 - accuracy: 0.9894 - val_loss: 1.6667 - val_accuracy: 0.8747\n",
            "Epoch 845/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9841 - val_loss: 1.7535 - val_accuracy: 0.8722\n",
            "Epoch 846/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0465 - accuracy: 0.9845 - val_loss: 1.7406 - val_accuracy: 0.8697\n",
            "Epoch 847/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0530 - accuracy: 0.9842 - val_loss: 1.7689 - val_accuracy: 0.8683\n",
            "Epoch 848/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0470 - accuracy: 0.9839 - val_loss: 1.7547 - val_accuracy: 0.8742\n",
            "Epoch 849/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0406 - accuracy: 0.9854 - val_loss: 1.6951 - val_accuracy: 0.8737\n",
            "Epoch 850/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 1.8437 - val_accuracy: 0.8652\n",
            "Epoch 851/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 1.8005 - val_accuracy: 0.8664\n",
            "Epoch 852/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0536 - accuracy: 0.9816 - val_loss: 1.7138 - val_accuracy: 0.8731\n",
            "Epoch 853/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 1.7070 - val_accuracy: 0.8725\n",
            "Epoch 854/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0357 - accuracy: 0.9877 - val_loss: 1.8176 - val_accuracy: 0.8711\n",
            "Epoch 855/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9879 - val_loss: 1.6944 - val_accuracy: 0.8755\n",
            "Epoch 856/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0366 - accuracy: 0.9870 - val_loss: 1.8158 - val_accuracy: 0.8636\n",
            "Epoch 857/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0451 - accuracy: 0.9825 - val_loss: 1.6057 - val_accuracy: 0.8730\n",
            "Epoch 858/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0393 - accuracy: 0.9869 - val_loss: 1.7608 - val_accuracy: 0.8717\n",
            "Epoch 859/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0386 - accuracy: 0.9862 - val_loss: 1.7774 - val_accuracy: 0.8717\n",
            "Epoch 860/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9862 - val_loss: 1.7823 - val_accuracy: 0.8752\n",
            "Epoch 861/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9873 - val_loss: 1.7902 - val_accuracy: 0.8694\n",
            "Epoch 862/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0444 - accuracy: 0.9838 - val_loss: 1.8576 - val_accuracy: 0.8714\n",
            "Epoch 863/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0598 - accuracy: 0.9809 - val_loss: 1.7057 - val_accuracy: 0.8683\n",
            "Epoch 864/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0457 - accuracy: 0.9853 - val_loss: 1.8271 - val_accuracy: 0.8691\n",
            "Epoch 865/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 1.6591 - val_accuracy: 0.8739\n",
            "Epoch 866/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9883 - val_loss: 1.6856 - val_accuracy: 0.8734\n",
            "Epoch 867/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0383 - accuracy: 0.9848 - val_loss: 1.6307 - val_accuracy: 0.8727\n",
            "Epoch 868/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9866 - val_loss: 1.8213 - val_accuracy: 0.8686\n",
            "Epoch 869/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0359 - accuracy: 0.9859 - val_loss: 1.7304 - val_accuracy: 0.8733\n",
            "Epoch 870/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 1.7342 - val_accuracy: 0.8730\n",
            "Epoch 871/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0466 - accuracy: 0.9842 - val_loss: 1.6230 - val_accuracy: 0.8717\n",
            "Epoch 872/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9859 - val_loss: 1.7582 - val_accuracy: 0.8737\n",
            "Epoch 873/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0607 - accuracy: 0.9792 - val_loss: 1.8086 - val_accuracy: 0.8675\n",
            "Epoch 874/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0522 - accuracy: 0.9808 - val_loss: 1.7087 - val_accuracy: 0.8684\n",
            "Epoch 875/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9830 - val_loss: 1.7021 - val_accuracy: 0.8755\n",
            "Epoch 876/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9865 - val_loss: 1.7205 - val_accuracy: 0.8719\n",
            "Epoch 877/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9872 - val_loss: 1.7094 - val_accuracy: 0.8731\n",
            "Epoch 878/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0286 - accuracy: 0.9901 - val_loss: 1.8767 - val_accuracy: 0.8678\n",
            "Epoch 879/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0381 - accuracy: 0.9865 - val_loss: 1.6847 - val_accuracy: 0.8748\n",
            "Epoch 880/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 1.6891 - val_accuracy: 0.8695\n",
            "Epoch 881/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0410 - accuracy: 0.9842 - val_loss: 1.7920 - val_accuracy: 0.8719\n",
            "Epoch 882/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 1.6641 - val_accuracy: 0.8763\n",
            "Epoch 883/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0347 - accuracy: 0.9884 - val_loss: 1.8026 - val_accuracy: 0.8758\n",
            "Epoch 884/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0302 - accuracy: 0.9879 - val_loss: 1.7863 - val_accuracy: 0.8725\n",
            "Epoch 885/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0660 - accuracy: 0.9815 - val_loss: 1.8456 - val_accuracy: 0.8673\n",
            "Epoch 886/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0825 - accuracy: 0.9736 - val_loss: 1.7594 - val_accuracy: 0.8667\n",
            "Epoch 887/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 1.7690 - val_accuracy: 0.8670\n",
            "Epoch 888/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0285 - accuracy: 0.9893 - val_loss: 1.6770 - val_accuracy: 0.8719\n",
            "Epoch 889/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0315 - accuracy: 0.9890 - val_loss: 1.8078 - val_accuracy: 0.8734\n",
            "Epoch 890/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0400 - accuracy: 0.9858 - val_loss: 1.6590 - val_accuracy: 0.8739\n",
            "Epoch 891/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0354 - accuracy: 0.9873 - val_loss: 1.6729 - val_accuracy: 0.8750\n",
            "Epoch 892/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9887 - val_loss: 1.7496 - val_accuracy: 0.8689\n",
            "Epoch 893/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - accuracy: 0.9896 - val_loss: 1.7391 - val_accuracy: 0.8722\n",
            "Epoch 894/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 1.6464 - val_accuracy: 0.8744\n",
            "Epoch 895/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0268 - accuracy: 0.9887 - val_loss: 1.6932 - val_accuracy: 0.8731\n",
            "Epoch 896/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 1.8386 - val_accuracy: 0.8730\n",
            "Epoch 897/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0504 - accuracy: 0.9837 - val_loss: 1.8025 - val_accuracy: 0.8719\n",
            "Epoch 898/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0409 - accuracy: 0.9859 - val_loss: 1.7601 - val_accuracy: 0.8742\n",
            "Epoch 899/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0355 - accuracy: 0.9862 - val_loss: 1.7131 - val_accuracy: 0.8775\n",
            "Epoch 900/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0352 - accuracy: 0.9875 - val_loss: 1.8410 - val_accuracy: 0.8700\n",
            "Epoch 901/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9872 - val_loss: 1.8959 - val_accuracy: 0.8691\n",
            "Epoch 902/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0233 - accuracy: 0.9911 - val_loss: 1.7223 - val_accuracy: 0.8761\n",
            "Epoch 903/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0286 - accuracy: 0.9898 - val_loss: 1.8473 - val_accuracy: 0.8730\n",
            "Epoch 904/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0351 - accuracy: 0.9865 - val_loss: 1.7624 - val_accuracy: 0.8648\n",
            "Epoch 905/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0582 - accuracy: 0.9805 - val_loss: 1.9045 - val_accuracy: 0.8705\n",
            "Epoch 906/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 1.8653 - val_accuracy: 0.8703\n",
            "Epoch 907/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - accuracy: 0.9896 - val_loss: 1.6820 - val_accuracy: 0.8717\n",
            "Epoch 908/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 1.6949 - val_accuracy: 0.8737\n",
            "Epoch 909/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 1.7504 - val_accuracy: 0.8752\n",
            "Epoch 910/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0267 - accuracy: 0.9900 - val_loss: 1.6933 - val_accuracy: 0.8702\n",
            "Epoch 911/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9855 - val_loss: 1.7485 - val_accuracy: 0.8706\n",
            "Epoch 912/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0391 - accuracy: 0.9866 - val_loss: 1.8556 - val_accuracy: 0.8694\n",
            "Epoch 913/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0563 - accuracy: 0.9821 - val_loss: 1.7508 - val_accuracy: 0.8683\n",
            "Epoch 914/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0459 - accuracy: 0.9855 - val_loss: 1.8658 - val_accuracy: 0.8727\n",
            "Epoch 915/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0498 - accuracy: 0.9840 - val_loss: 1.8625 - val_accuracy: 0.8686\n",
            "Epoch 916/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0616 - accuracy: 0.9809 - val_loss: 1.9087 - val_accuracy: 0.8700\n",
            "Epoch 917/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0435 - accuracy: 0.9850 - val_loss: 1.7985 - val_accuracy: 0.8684\n",
            "Epoch 918/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0358 - accuracy: 0.9861 - val_loss: 1.6700 - val_accuracy: 0.8741\n",
            "Epoch 919/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0333 - accuracy: 0.9870 - val_loss: 1.7871 - val_accuracy: 0.8722\n",
            "Epoch 920/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0391 - accuracy: 0.9877 - val_loss: 1.8275 - val_accuracy: 0.8722\n",
            "Epoch 921/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9896 - val_loss: 1.7307 - val_accuracy: 0.8772\n",
            "Epoch 922/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 1.7824 - val_accuracy: 0.8745\n",
            "Epoch 923/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0257 - accuracy: 0.9902 - val_loss: 1.7428 - val_accuracy: 0.8752\n",
            "Epoch 924/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0294 - accuracy: 0.9891 - val_loss: 1.8066 - val_accuracy: 0.8761\n",
            "Epoch 925/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0458 - accuracy: 0.9846 - val_loss: 1.8825 - val_accuracy: 0.8725\n",
            "Epoch 926/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0413 - accuracy: 0.9869 - val_loss: 1.7924 - val_accuracy: 0.8733\n",
            "Epoch 927/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9878 - val_loss: 1.6983 - val_accuracy: 0.8742\n",
            "Epoch 928/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0279 - accuracy: 0.9891 - val_loss: 1.7004 - val_accuracy: 0.8781\n",
            "Epoch 929/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 1.9341 - val_accuracy: 0.8736\n",
            "Epoch 930/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0517 - accuracy: 0.9834 - val_loss: 1.7794 - val_accuracy: 0.8764\n",
            "Epoch 931/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9875 - val_loss: 1.7875 - val_accuracy: 0.8744\n",
            "Epoch 932/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 1.6836 - val_accuracy: 0.8712\n",
            "Epoch 933/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 1.7561 - val_accuracy: 0.8736\n",
            "Epoch 934/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9878 - val_loss: 1.8028 - val_accuracy: 0.8723\n",
            "Epoch 935/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0390 - accuracy: 0.9868 - val_loss: 1.7971 - val_accuracy: 0.8698\n",
            "Epoch 936/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0335 - accuracy: 0.9888 - val_loss: 1.7838 - val_accuracy: 0.8692\n",
            "Epoch 937/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 1.8431 - val_accuracy: 0.8731\n",
            "Epoch 938/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0428 - accuracy: 0.9854 - val_loss: 1.7650 - val_accuracy: 0.8716\n",
            "Epoch 939/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9878 - val_loss: 1.7836 - val_accuracy: 0.8719\n",
            "Epoch 940/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 1.7444 - val_accuracy: 0.8739\n",
            "Epoch 941/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0263 - accuracy: 0.9904 - val_loss: 1.7066 - val_accuracy: 0.8741\n",
            "Epoch 942/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0246 - accuracy: 0.9905 - val_loss: 1.8059 - val_accuracy: 0.8725\n",
            "Epoch 943/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 1.8170 - val_accuracy: 0.8706\n",
            "Epoch 944/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0232 - accuracy: 0.9908 - val_loss: 1.7754 - val_accuracy: 0.8761\n",
            "Epoch 945/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0293 - accuracy: 0.9887 - val_loss: 1.8528 - val_accuracy: 0.8706\n",
            "Epoch 946/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0289 - accuracy: 0.9898 - val_loss: 1.6874 - val_accuracy: 0.8800\n",
            "Epoch 947/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9897 - val_loss: 1.7449 - val_accuracy: 0.8737\n",
            "Epoch 948/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0471 - accuracy: 0.9848 - val_loss: 1.9520 - val_accuracy: 0.8712\n",
            "Epoch 949/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0404 - accuracy: 0.9859 - val_loss: 1.8290 - val_accuracy: 0.8717\n",
            "Epoch 950/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0329 - accuracy: 0.9878 - val_loss: 1.8454 - val_accuracy: 0.8691\n",
            "Epoch 951/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0439 - accuracy: 0.9845 - val_loss: 2.0225 - val_accuracy: 0.8691\n",
            "Epoch 952/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0570 - accuracy: 0.9811 - val_loss: 1.7320 - val_accuracy: 0.8769\n",
            "Epoch 953/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 1.8115 - val_accuracy: 0.8694\n",
            "Epoch 954/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0340 - accuracy: 0.9875 - val_loss: 1.7579 - val_accuracy: 0.8698\n",
            "Epoch 955/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0397 - accuracy: 0.9866 - val_loss: 1.7775 - val_accuracy: 0.8739\n",
            "Epoch 956/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9866 - val_loss: 1.7798 - val_accuracy: 0.8706\n",
            "Epoch 957/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0475 - accuracy: 0.9838 - val_loss: 1.8776 - val_accuracy: 0.8727\n",
            "Epoch 958/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 1.8386 - val_accuracy: 0.8664\n",
            "Epoch 959/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 1.8394 - val_accuracy: 0.8734\n",
            "Epoch 960/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0501 - accuracy: 0.9834 - val_loss: 1.6652 - val_accuracy: 0.8739\n",
            "Epoch 961/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9870 - val_loss: 1.7100 - val_accuracy: 0.8742\n",
            "Epoch 962/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 1.9002 - val_accuracy: 0.8716\n",
            "Epoch 963/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0302 - accuracy: 0.9891 - val_loss: 1.8717 - val_accuracy: 0.8730\n",
            "Epoch 964/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9876 - val_loss: 1.7756 - val_accuracy: 0.8691\n",
            "Epoch 965/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0288 - accuracy: 0.9891 - val_loss: 1.7959 - val_accuracy: 0.8753\n",
            "Epoch 966/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9869 - val_loss: 1.8138 - val_accuracy: 0.8708\n",
            "Epoch 967/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9869 - val_loss: 1.7983 - val_accuracy: 0.8722\n",
            "Epoch 968/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - accuracy: 0.9898 - val_loss: 1.8405 - val_accuracy: 0.8730\n",
            "Epoch 969/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9878 - val_loss: 1.8949 - val_accuracy: 0.8669\n",
            "Epoch 970/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0605 - accuracy: 0.9819 - val_loss: 1.8409 - val_accuracy: 0.8675\n",
            "Epoch 971/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0486 - accuracy: 0.9832 - val_loss: 1.7918 - val_accuracy: 0.8694\n",
            "Epoch 972/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0415 - accuracy: 0.9848 - val_loss: 1.8148 - val_accuracy: 0.8739\n",
            "Epoch 973/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0459 - accuracy: 0.9847 - val_loss: 1.7641 - val_accuracy: 0.8731\n",
            "Epoch 974/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0278 - accuracy: 0.9888 - val_loss: 1.7029 - val_accuracy: 0.8753\n",
            "Epoch 975/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0305 - accuracy: 0.9886 - val_loss: 1.7769 - val_accuracy: 0.8725\n",
            "Epoch 976/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0294 - accuracy: 0.9886 - val_loss: 1.8341 - val_accuracy: 0.8750\n",
            "Epoch 977/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0436 - accuracy: 0.9855 - val_loss: 1.7542 - val_accuracy: 0.8736\n",
            "Epoch 978/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0472 - accuracy: 0.9852 - val_loss: 1.8115 - val_accuracy: 0.8728\n",
            "Epoch 979/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0462 - accuracy: 0.9834 - val_loss: 1.6537 - val_accuracy: 0.8733\n",
            "Epoch 980/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0286 - accuracy: 0.9898 - val_loss: 1.7159 - val_accuracy: 0.8728\n",
            "Epoch 981/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0389 - accuracy: 0.9872 - val_loss: 1.8903 - val_accuracy: 0.8745\n",
            "Epoch 982/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0354 - accuracy: 0.9877 - val_loss: 1.7072 - val_accuracy: 0.8684\n",
            "Epoch 983/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0270 - accuracy: 0.9892 - val_loss: 1.7830 - val_accuracy: 0.8763\n",
            "Epoch 984/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9855 - val_loss: 1.8006 - val_accuracy: 0.8675\n",
            "Epoch 985/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 1.8011 - val_accuracy: 0.8722\n",
            "Epoch 986/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0442 - accuracy: 0.9859 - val_loss: 1.9080 - val_accuracy: 0.8709\n",
            "Epoch 987/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9883 - val_loss: 1.8077 - val_accuracy: 0.8722\n",
            "Epoch 988/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 1.8006 - val_accuracy: 0.8698\n",
            "Epoch 989/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0517 - accuracy: 0.9823 - val_loss: 1.8154 - val_accuracy: 0.8720\n",
            "Epoch 990/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0480 - accuracy: 0.9841 - val_loss: 1.8972 - val_accuracy: 0.8720\n",
            "Epoch 991/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0378 - accuracy: 0.9862 - val_loss: 1.8654 - val_accuracy: 0.8728\n",
            "Epoch 992/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 1.7809 - val_accuracy: 0.8722\n",
            "Epoch 993/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0236 - accuracy: 0.9912 - val_loss: 1.7615 - val_accuracy: 0.8745\n",
            "Epoch 994/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0400 - accuracy: 0.9854 - val_loss: 1.8066 - val_accuracy: 0.8717\n",
            "Epoch 995/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0301 - accuracy: 0.9891 - val_loss: 1.8090 - val_accuracy: 0.8686\n",
            "Epoch 996/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0257 - accuracy: 0.9909 - val_loss: 1.8037 - val_accuracy: 0.8695\n",
            "Epoch 997/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0347 - accuracy: 0.9875 - val_loss: 1.8138 - val_accuracy: 0.8728\n",
            "Epoch 998/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9881 - val_loss: 1.8589 - val_accuracy: 0.8720\n",
            "Epoch 999/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0480 - accuracy: 0.9859 - val_loss: 1.8308 - val_accuracy: 0.8734\n",
            "Epoch 1000/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0417 - accuracy: 0.9862 - val_loss: 1.7999 - val_accuracy: 0.8723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WTy2ZlsrBto",
        "outputId": "38aed080-4728-476a-ce3d-71cf388f49c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model_lr_loss,model_lr_acc=model.evaluate(test_dataset,steps=50)\n",
        "print(\"Accuracy with Initial learning rate of 0.01 is \", model_lr_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 0s 8ms/step - loss: 1.7999 - accuracy: 0.8723\n",
            "Accuracy with Initial learning rate of 0.01 is  0.8723437786102295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkWkyohZuHLY",
        "outputId": "7b6ff407-2c9a-4a0f-c752-ae2dc95956d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "NO_EPOCHS=250\n",
        "history_lr_250epoch=model.fit(train_dataset,epochs=NO_EPOCHS,steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,validation_data=test_dataset,batch_size=BATCH_SIZE,verbose = 1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0610 - accuracy: 0.9812 - val_loss: 1.7831 - val_accuracy: 0.8745\n",
            "Epoch 2/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 1.7730 - val_accuracy: 0.8747\n",
            "Epoch 3/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 1.7845 - val_accuracy: 0.8720\n",
            "Epoch 4/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0288 - accuracy: 0.9894 - val_loss: 1.8600 - val_accuracy: 0.8675\n",
            "Epoch 5/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0439 - accuracy: 0.9860 - val_loss: 1.7392 - val_accuracy: 0.8766\n",
            "Epoch 6/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0436 - accuracy: 0.9849 - val_loss: 1.7993 - val_accuracy: 0.8759\n",
            "Epoch 7/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0378 - accuracy: 0.9866 - val_loss: 1.8754 - val_accuracy: 0.8694\n",
            "Epoch 8/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 1.8102 - val_accuracy: 0.8680\n",
            "Epoch 9/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9880 - val_loss: 1.8779 - val_accuracy: 0.8722\n",
            "Epoch 10/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0430 - accuracy: 0.9859 - val_loss: 1.7292 - val_accuracy: 0.8769\n",
            "Epoch 11/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0221 - accuracy: 0.9917 - val_loss: 1.7807 - val_accuracy: 0.8758\n",
            "Epoch 12/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0260 - accuracy: 0.9909 - val_loss: 1.8559 - val_accuracy: 0.8739\n",
            "Epoch 13/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 1.9500 - val_accuracy: 0.8727\n",
            "Epoch 14/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0293 - accuracy: 0.9884 - val_loss: 1.7929 - val_accuracy: 0.8737\n",
            "Epoch 15/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0256 - accuracy: 0.9908 - val_loss: 1.8387 - val_accuracy: 0.8712\n",
            "Epoch 16/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0254 - accuracy: 0.9895 - val_loss: 1.7784 - val_accuracy: 0.8745\n",
            "Epoch 17/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - accuracy: 0.9891 - val_loss: 1.8774 - val_accuracy: 0.8686\n",
            "Epoch 18/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 1.9160 - val_accuracy: 0.8656\n",
            "Epoch 19/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0452 - accuracy: 0.9840 - val_loss: 1.7541 - val_accuracy: 0.8698\n",
            "Epoch 20/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0332 - accuracy: 0.9877 - val_loss: 1.8492 - val_accuracy: 0.8736\n",
            "Epoch 21/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0275 - accuracy: 0.9902 - val_loss: 1.8700 - val_accuracy: 0.8742\n",
            "Epoch 22/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0326 - accuracy: 0.9880 - val_loss: 1.7868 - val_accuracy: 0.8692\n",
            "Epoch 23/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9848 - val_loss: 1.9411 - val_accuracy: 0.8672\n",
            "Epoch 24/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0594 - accuracy: 0.9815 - val_loss: 1.7085 - val_accuracy: 0.8758\n",
            "Epoch 25/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9874 - val_loss: 1.8046 - val_accuracy: 0.8734\n",
            "Epoch 26/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0246 - accuracy: 0.9907 - val_loss: 1.8938 - val_accuracy: 0.8694\n",
            "Epoch 27/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0254 - accuracy: 0.9908 - val_loss: 1.7851 - val_accuracy: 0.8767\n",
            "Epoch 28/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0285 - accuracy: 0.9902 - val_loss: 1.8036 - val_accuracy: 0.8709\n",
            "Epoch 29/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0432 - accuracy: 0.9848 - val_loss: 1.8553 - val_accuracy: 0.8709\n",
            "Epoch 30/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0460 - accuracy: 0.9834 - val_loss: 1.7609 - val_accuracy: 0.8737\n",
            "Epoch 31/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0488 - accuracy: 0.9857 - val_loss: 1.7820 - val_accuracy: 0.8711\n",
            "Epoch 32/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9858 - val_loss: 1.8890 - val_accuracy: 0.8698\n",
            "Epoch 33/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 1.8293 - val_accuracy: 0.8683\n",
            "Epoch 34/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0300 - accuracy: 0.9898 - val_loss: 1.8532 - val_accuracy: 0.8678\n",
            "Epoch 35/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0360 - accuracy: 0.9868 - val_loss: 1.8153 - val_accuracy: 0.8734\n",
            "Epoch 36/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0259 - accuracy: 0.9899 - val_loss: 1.8891 - val_accuracy: 0.8725\n",
            "Epoch 37/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0269 - accuracy: 0.9891 - val_loss: 1.8617 - val_accuracy: 0.8759\n",
            "Epoch 38/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0260 - accuracy: 0.9903 - val_loss: 1.7935 - val_accuracy: 0.8763\n",
            "Epoch 39/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0213 - accuracy: 0.9923 - val_loss: 1.8481 - val_accuracy: 0.8766\n",
            "Epoch 40/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 2.0417 - val_accuracy: 0.8691\n",
            "Epoch 41/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 1.8665 - val_accuracy: 0.8720\n",
            "Epoch 42/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0411 - accuracy: 0.9862 - val_loss: 1.9392 - val_accuracy: 0.8766\n",
            "Epoch 43/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 1.8896 - val_accuracy: 0.8714\n",
            "Epoch 44/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 1.8571 - val_accuracy: 0.8742\n",
            "Epoch 45/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0357 - accuracy: 0.9882 - val_loss: 1.9773 - val_accuracy: 0.8666\n",
            "Epoch 46/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0360 - accuracy: 0.9866 - val_loss: 1.7952 - val_accuracy: 0.8745\n",
            "Epoch 47/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9870 - val_loss: 1.8651 - val_accuracy: 0.8728\n",
            "Epoch 48/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0379 - accuracy: 0.9859 - val_loss: 1.9401 - val_accuracy: 0.8695\n",
            "Epoch 49/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0296 - accuracy: 0.9898 - val_loss: 1.9118 - val_accuracy: 0.8700\n",
            "Epoch 50/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9838 - val_loss: 1.8371 - val_accuracy: 0.8708\n",
            "Epoch 51/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0529 - accuracy: 0.9832 - val_loss: 1.9345 - val_accuracy: 0.8702\n",
            "Epoch 52/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0424 - accuracy: 0.9856 - val_loss: 1.7752 - val_accuracy: 0.8777\n",
            "Epoch 53/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0336 - accuracy: 0.9881 - val_loss: 1.9189 - val_accuracy: 0.8733\n",
            "Epoch 54/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 1.8742 - val_accuracy: 0.8684\n",
            "Epoch 55/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - accuracy: 0.9899 - val_loss: 1.7810 - val_accuracy: 0.8748\n",
            "Epoch 56/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0482 - accuracy: 0.9839 - val_loss: 1.9766 - val_accuracy: 0.8700\n",
            "Epoch 57/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0461 - accuracy: 0.9841 - val_loss: 1.8091 - val_accuracy: 0.8700\n",
            "Epoch 58/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9891 - val_loss: 1.7296 - val_accuracy: 0.8731\n",
            "Epoch 59/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0461 - accuracy: 0.9857 - val_loss: 2.1249 - val_accuracy: 0.8623\n",
            "Epoch 60/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0751 - accuracy: 0.9780 - val_loss: 1.8271 - val_accuracy: 0.8677\n",
            "Epoch 61/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0348 - accuracy: 0.9880 - val_loss: 1.8656 - val_accuracy: 0.8697\n",
            "Epoch 62/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9880 - val_loss: 1.8649 - val_accuracy: 0.8684\n",
            "Epoch 63/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 1.9589 - val_accuracy: 0.8720\n",
            "Epoch 64/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0300 - accuracy: 0.9889 - val_loss: 1.8301 - val_accuracy: 0.8763\n",
            "Epoch 65/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0340 - accuracy: 0.9881 - val_loss: 1.8139 - val_accuracy: 0.8720\n",
            "Epoch 66/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0242 - accuracy: 0.9914 - val_loss: 1.8048 - val_accuracy: 0.8745\n",
            "Epoch 67/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 1.8969 - val_accuracy: 0.8755\n",
            "Epoch 68/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 1.9212 - val_accuracy: 0.8736\n",
            "Epoch 69/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9892 - val_loss: 1.8642 - val_accuracy: 0.8773\n",
            "Epoch 70/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - accuracy: 0.9894 - val_loss: 1.9510 - val_accuracy: 0.8737\n",
            "Epoch 71/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0414 - accuracy: 0.9858 - val_loss: 1.8764 - val_accuracy: 0.8664\n",
            "Epoch 72/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0533 - accuracy: 0.9839 - val_loss: 1.8541 - val_accuracy: 0.8731\n",
            "Epoch 73/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0374 - accuracy: 0.9877 - val_loss: 1.9254 - val_accuracy: 0.8711\n",
            "Epoch 74/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0227 - accuracy: 0.9913 - val_loss: 1.8392 - val_accuracy: 0.8745\n",
            "Epoch 75/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0215 - accuracy: 0.9915 - val_loss: 1.8449 - val_accuracy: 0.8722\n",
            "Epoch 76/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 1.8380 - val_accuracy: 0.8716\n",
            "Epoch 77/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0270 - accuracy: 0.9899 - val_loss: 1.8358 - val_accuracy: 0.8739\n",
            "Epoch 78/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0279 - accuracy: 0.9898 - val_loss: 1.9237 - val_accuracy: 0.8720\n",
            "Epoch 79/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0404 - accuracy: 0.9861 - val_loss: 1.8916 - val_accuracy: 0.8705\n",
            "Epoch 80/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0405 - accuracy: 0.9859 - val_loss: 1.8997 - val_accuracy: 0.8706\n",
            "Epoch 81/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9881 - val_loss: 1.8921 - val_accuracy: 0.8703\n",
            "Epoch 82/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0257 - accuracy: 0.9905 - val_loss: 2.0136 - val_accuracy: 0.8689\n",
            "Epoch 83/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0305 - accuracy: 0.9894 - val_loss: 1.8674 - val_accuracy: 0.8712\n",
            "Epoch 84/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 1.9618 - val_accuracy: 0.8712\n",
            "Epoch 85/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0259 - accuracy: 0.9899 - val_loss: 1.8723 - val_accuracy: 0.8708\n",
            "Epoch 86/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0465 - accuracy: 0.9854 - val_loss: 1.9488 - val_accuracy: 0.8694\n",
            "Epoch 87/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 2.0930 - val_accuracy: 0.8686\n",
            "Epoch 88/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0492 - accuracy: 0.9831 - val_loss: 1.8670 - val_accuracy: 0.8686\n",
            "Epoch 89/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0509 - accuracy: 0.9842 - val_loss: 1.9235 - val_accuracy: 0.8717\n",
            "Epoch 90/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9873 - val_loss: 1.9332 - val_accuracy: 0.8697\n",
            "Epoch 91/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0365 - accuracy: 0.9867 - val_loss: 1.8319 - val_accuracy: 0.8764\n",
            "Epoch 92/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0273 - accuracy: 0.9896 - val_loss: 1.9088 - val_accuracy: 0.8742\n",
            "Epoch 93/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 1.9686 - val_accuracy: 0.8753\n",
            "Epoch 94/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 1.9652 - val_accuracy: 0.8656\n",
            "Epoch 95/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 1.9763 - val_accuracy: 0.8706\n",
            "Epoch 96/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0274 - accuracy: 0.9906 - val_loss: 2.0088 - val_accuracy: 0.8686\n",
            "Epoch 97/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0262 - accuracy: 0.9899 - val_loss: 1.8571 - val_accuracy: 0.8703\n",
            "Epoch 98/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9883 - val_loss: 1.9117 - val_accuracy: 0.8781\n",
            "Epoch 99/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0264 - accuracy: 0.9902 - val_loss: 1.7618 - val_accuracy: 0.8786\n",
            "Epoch 100/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0218 - accuracy: 0.9912 - val_loss: 1.8407 - val_accuracy: 0.8755\n",
            "Epoch 101/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 2.0201 - val_accuracy: 0.8736\n",
            "Epoch 102/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0303 - accuracy: 0.9889 - val_loss: 1.9372 - val_accuracy: 0.8750\n",
            "Epoch 103/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0672 - accuracy: 0.9797 - val_loss: 1.9769 - val_accuracy: 0.8703\n",
            "Epoch 104/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0541 - accuracy: 0.9841 - val_loss: 1.9897 - val_accuracy: 0.8736\n",
            "Epoch 105/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0436 - accuracy: 0.9860 - val_loss: 1.8783 - val_accuracy: 0.8759\n",
            "Epoch 106/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0296 - accuracy: 0.9891 - val_loss: 1.9196 - val_accuracy: 0.8705\n",
            "Epoch 107/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0336 - accuracy: 0.9870 - val_loss: 2.0106 - val_accuracy: 0.8705\n",
            "Epoch 108/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0352 - accuracy: 0.9881 - val_loss: 1.8926 - val_accuracy: 0.8755\n",
            "Epoch 109/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0451 - accuracy: 0.9859 - val_loss: 1.9361 - val_accuracy: 0.8702\n",
            "Epoch 110/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9885 - val_loss: 1.9255 - val_accuracy: 0.8686\n",
            "Epoch 111/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0416 - accuracy: 0.9862 - val_loss: 1.7762 - val_accuracy: 0.8748\n",
            "Epoch 112/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0311 - accuracy: 0.9892 - val_loss: 1.9219 - val_accuracy: 0.8792\n",
            "Epoch 113/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 1.8642 - val_accuracy: 0.8711\n",
            "Epoch 114/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0474 - accuracy: 0.9841 - val_loss: 1.9328 - val_accuracy: 0.8747\n",
            "Epoch 115/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 1.9368 - val_accuracy: 0.8761\n",
            "Epoch 116/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0364 - accuracy: 0.9882 - val_loss: 1.8482 - val_accuracy: 0.8745\n",
            "Epoch 117/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0295 - accuracy: 0.9900 - val_loss: 1.8635 - val_accuracy: 0.8720\n",
            "Epoch 118/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9891 - val_loss: 1.9755 - val_accuracy: 0.8723\n",
            "Epoch 119/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0302 - accuracy: 0.9892 - val_loss: 1.8471 - val_accuracy: 0.8761\n",
            "Epoch 120/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9872 - val_loss: 2.0515 - val_accuracy: 0.8727\n",
            "Epoch 121/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 1.8772 - val_accuracy: 0.8728\n",
            "Epoch 122/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0295 - accuracy: 0.9890 - val_loss: 2.0367 - val_accuracy: 0.8697\n",
            "Epoch 123/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 1.9491 - val_accuracy: 0.8737\n",
            "Epoch 124/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9878 - val_loss: 2.0109 - val_accuracy: 0.8725\n",
            "Epoch 125/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0455 - accuracy: 0.9861 - val_loss: 1.8419 - val_accuracy: 0.8734\n",
            "Epoch 126/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9870 - val_loss: 2.0607 - val_accuracy: 0.8684\n",
            "Epoch 127/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0305 - accuracy: 0.9881 - val_loss: 1.8129 - val_accuracy: 0.8691\n",
            "Epoch 128/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 1.9066 - val_accuracy: 0.8722\n",
            "Epoch 129/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 2.1044 - val_accuracy: 0.8683\n",
            "Epoch 130/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 1.9236 - val_accuracy: 0.8695\n",
            "Epoch 131/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0380 - accuracy: 0.9882 - val_loss: 1.9601 - val_accuracy: 0.8734\n",
            "Epoch 132/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0376 - accuracy: 0.9864 - val_loss: 2.0150 - val_accuracy: 0.8741\n",
            "Epoch 133/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0466 - accuracy: 0.9862 - val_loss: 1.8822 - val_accuracy: 0.8697\n",
            "Epoch 134/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 1.8925 - val_accuracy: 0.8744\n",
            "Epoch 135/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 1.9357 - val_accuracy: 0.8669\n",
            "Epoch 136/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0512 - accuracy: 0.9847 - val_loss: 1.9994 - val_accuracy: 0.8612\n",
            "Epoch 137/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0520 - accuracy: 0.9826 - val_loss: 1.9790 - val_accuracy: 0.8648\n",
            "Epoch 138/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0413 - accuracy: 0.9858 - val_loss: 2.1143 - val_accuracy: 0.8672\n",
            "Epoch 139/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0255 - accuracy: 0.9902 - val_loss: 1.9476 - val_accuracy: 0.8723\n",
            "Epoch 140/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 1.9450 - val_accuracy: 0.8697\n",
            "Epoch 141/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9885 - val_loss: 1.9229 - val_accuracy: 0.8716\n",
            "Epoch 142/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9879 - val_loss: 1.8893 - val_accuracy: 0.8756\n",
            "Epoch 143/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 1.9504 - val_accuracy: 0.8700\n",
            "Epoch 144/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0229 - accuracy: 0.9905 - val_loss: 1.9835 - val_accuracy: 0.8712\n",
            "Epoch 145/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0258 - accuracy: 0.9897 - val_loss: 1.8074 - val_accuracy: 0.8769\n",
            "Epoch 146/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0237 - accuracy: 0.9903 - val_loss: 1.9936 - val_accuracy: 0.8697\n",
            "Epoch 147/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0241 - accuracy: 0.9906 - val_loss: 1.8818 - val_accuracy: 0.8763\n",
            "Epoch 148/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0174 - accuracy: 0.9929 - val_loss: 1.9830 - val_accuracy: 0.8658\n",
            "Epoch 149/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0359 - accuracy: 0.9876 - val_loss: 1.9665 - val_accuracy: 0.8731\n",
            "Epoch 150/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 1.9225 - val_accuracy: 0.8712\n",
            "Epoch 151/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0263 - accuracy: 0.9906 - val_loss: 1.9707 - val_accuracy: 0.8716\n",
            "Epoch 152/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 1.9702 - val_accuracy: 0.8698\n",
            "Epoch 153/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 1.9301 - val_accuracy: 0.8759\n",
            "Epoch 154/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9879 - val_loss: 1.8635 - val_accuracy: 0.8759\n",
            "Epoch 155/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0345 - accuracy: 0.9872 - val_loss: 1.9192 - val_accuracy: 0.8725\n",
            "Epoch 156/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0380 - accuracy: 0.9868 - val_loss: 1.8963 - val_accuracy: 0.8672\n",
            "Epoch 157/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0296 - accuracy: 0.9890 - val_loss: 2.0899 - val_accuracy: 0.8683\n",
            "Epoch 158/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 2.0169 - val_accuracy: 0.8725\n",
            "Epoch 159/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0380 - accuracy: 0.9877 - val_loss: 2.0177 - val_accuracy: 0.8730\n",
            "Epoch 160/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0383 - accuracy: 0.9865 - val_loss: 1.9852 - val_accuracy: 0.8675\n",
            "Epoch 161/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0435 - accuracy: 0.9854 - val_loss: 1.9401 - val_accuracy: 0.8720\n",
            "Epoch 162/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 1.9436 - val_accuracy: 0.8717\n",
            "Epoch 163/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 1.9591 - val_accuracy: 0.8747\n",
            "Epoch 164/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0255 - accuracy: 0.9903 - val_loss: 1.9862 - val_accuracy: 0.8722\n",
            "Epoch 165/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0602 - accuracy: 0.9799 - val_loss: 1.9112 - val_accuracy: 0.8722\n",
            "Epoch 166/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 1.9010 - val_accuracy: 0.8731\n",
            "Epoch 167/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0311 - accuracy: 0.9885 - val_loss: 1.9609 - val_accuracy: 0.8708\n",
            "Epoch 168/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 1.8504 - val_accuracy: 0.8733\n",
            "Epoch 169/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0353 - accuracy: 0.9883 - val_loss: 1.8271 - val_accuracy: 0.8750\n",
            "Epoch 170/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 1.9866 - val_accuracy: 0.8781\n",
            "Epoch 171/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 2.0603 - val_accuracy: 0.8709\n",
            "Epoch 172/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0486 - accuracy: 0.9854 - val_loss: 1.9094 - val_accuracy: 0.8716\n",
            "Epoch 173/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0413 - accuracy: 0.9864 - val_loss: 2.0579 - val_accuracy: 0.8698\n",
            "Epoch 174/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0584 - accuracy: 0.9802 - val_loss: 1.9632 - val_accuracy: 0.8700\n",
            "Epoch 175/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0480 - accuracy: 0.9861 - val_loss: 1.8937 - val_accuracy: 0.8756\n",
            "Epoch 176/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0231 - accuracy: 0.9913 - val_loss: 1.9956 - val_accuracy: 0.8708\n",
            "Epoch 177/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0296 - accuracy: 0.9901 - val_loss: 1.8249 - val_accuracy: 0.8723\n",
            "Epoch 178/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0393 - accuracy: 0.9865 - val_loss: 1.8820 - val_accuracy: 0.8747\n",
            "Epoch 179/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0270 - accuracy: 0.9901 - val_loss: 1.9247 - val_accuracy: 0.8716\n",
            "Epoch 180/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 2.0180 - val_accuracy: 0.8673\n",
            "Epoch 181/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9890 - val_loss: 1.9479 - val_accuracy: 0.8730\n",
            "Epoch 182/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0441 - accuracy: 0.9852 - val_loss: 1.9733 - val_accuracy: 0.8722\n",
            "Epoch 183/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0256 - accuracy: 0.9905 - val_loss: 1.8807 - val_accuracy: 0.8736\n",
            "Epoch 184/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0260 - accuracy: 0.9918 - val_loss: 1.9741 - val_accuracy: 0.8731\n",
            "Epoch 185/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 1.9885 - val_accuracy: 0.8669\n",
            "Epoch 186/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0212 - accuracy: 0.9923 - val_loss: 1.9706 - val_accuracy: 0.8712\n",
            "Epoch 187/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0335 - accuracy: 0.9891 - val_loss: 2.0716 - val_accuracy: 0.8714\n",
            "Epoch 188/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0251 - accuracy: 0.9903 - val_loss: 1.8626 - val_accuracy: 0.8734\n",
            "Epoch 189/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9893 - val_loss: 1.9691 - val_accuracy: 0.8745\n",
            "Epoch 190/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0509 - accuracy: 0.9851 - val_loss: 2.1447 - val_accuracy: 0.8669\n",
            "Epoch 191/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0776 - accuracy: 0.9770 - val_loss: 1.8811 - val_accuracy: 0.8728\n",
            "Epoch 192/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0422 - accuracy: 0.9872 - val_loss: 1.9315 - val_accuracy: 0.8719\n",
            "Epoch 193/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9885 - val_loss: 2.0196 - val_accuracy: 0.8714\n",
            "Epoch 194/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0285 - accuracy: 0.9886 - val_loss: 1.9116 - val_accuracy: 0.8702\n",
            "Epoch 195/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0254 - accuracy: 0.9910 - val_loss: 2.0066 - val_accuracy: 0.8769\n",
            "Epoch 196/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0243 - accuracy: 0.9912 - val_loss: 1.9327 - val_accuracy: 0.8748\n",
            "Epoch 197/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 1.9319 - val_accuracy: 0.8694\n",
            "Epoch 198/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 1.9902 - val_accuracy: 0.8709\n",
            "Epoch 199/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0226 - accuracy: 0.9919 - val_loss: 1.9793 - val_accuracy: 0.8705\n",
            "Epoch 200/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0446 - accuracy: 0.9877 - val_loss: 1.9726 - val_accuracy: 0.8741\n",
            "Epoch 201/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0475 - accuracy: 0.9844 - val_loss: 1.9885 - val_accuracy: 0.8766\n",
            "Epoch 202/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 1.8673 - val_accuracy: 0.8737\n",
            "Epoch 203/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0318 - accuracy: 0.9901 - val_loss: 1.8421 - val_accuracy: 0.8741\n",
            "Epoch 204/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 1.9919 - val_accuracy: 0.8673\n",
            "Epoch 205/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0274 - accuracy: 0.9893 - val_loss: 1.9211 - val_accuracy: 0.8725\n",
            "Epoch 206/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 1.9845 - val_accuracy: 0.8684\n",
            "Epoch 207/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 1.9056 - val_accuracy: 0.8712\n",
            "Epoch 208/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 1.8886 - val_accuracy: 0.8744\n",
            "Epoch 209/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9870 - val_loss: 1.9745 - val_accuracy: 0.8792\n",
            "Epoch 210/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0366 - accuracy: 0.9867 - val_loss: 2.0349 - val_accuracy: 0.8691\n",
            "Epoch 211/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0373 - accuracy: 0.9870 - val_loss: 2.0421 - val_accuracy: 0.8695\n",
            "Epoch 212/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9880 - val_loss: 1.9415 - val_accuracy: 0.8752\n",
            "Epoch 213/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0288 - accuracy: 0.9896 - val_loss: 2.1282 - val_accuracy: 0.8697\n",
            "Epoch 214/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0263 - accuracy: 0.9904 - val_loss: 1.8778 - val_accuracy: 0.8791\n",
            "Epoch 215/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0218 - accuracy: 0.9917 - val_loss: 2.0258 - val_accuracy: 0.8698\n",
            "Epoch 216/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0351 - accuracy: 0.9875 - val_loss: 1.9277 - val_accuracy: 0.8694\n",
            "Epoch 217/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0528 - accuracy: 0.9831 - val_loss: 1.8713 - val_accuracy: 0.8798\n",
            "Epoch 218/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 1.9927 - val_accuracy: 0.8708\n",
            "Epoch 219/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0187 - accuracy: 0.9925 - val_loss: 1.9545 - val_accuracy: 0.8711\n",
            "Epoch 220/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0348 - accuracy: 0.9881 - val_loss: 1.9461 - val_accuracy: 0.8691\n",
            "Epoch 221/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0298 - accuracy: 0.9890 - val_loss: 2.0760 - val_accuracy: 0.8728\n",
            "Epoch 222/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 1.8941 - val_accuracy: 0.8711\n",
            "Epoch 223/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 1.9678 - val_accuracy: 0.8734\n",
            "Epoch 224/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0332 - accuracy: 0.9885 - val_loss: 2.0173 - val_accuracy: 0.8725\n",
            "Epoch 225/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 1.9331 - val_accuracy: 0.8716\n",
            "Epoch 226/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 1.9768 - val_accuracy: 0.8733\n",
            "Epoch 227/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 2.0512 - val_accuracy: 0.8727\n",
            "Epoch 228/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - accuracy: 0.9898 - val_loss: 1.8813 - val_accuracy: 0.8728\n",
            "Epoch 229/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 1.9772 - val_accuracy: 0.8695\n",
            "Epoch 230/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0797 - accuracy: 0.9797 - val_loss: 1.9077 - val_accuracy: 0.8653\n",
            "Epoch 231/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9786 - val_loss: 2.1088 - val_accuracy: 0.8666\n",
            "Epoch 232/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0609 - accuracy: 0.9830 - val_loss: 2.1114 - val_accuracy: 0.8687\n",
            "Epoch 233/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 1.9970 - val_accuracy: 0.8722\n",
            "Epoch 234/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0442 - accuracy: 0.9860 - val_loss: 1.8822 - val_accuracy: 0.8741\n",
            "Epoch 235/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0291 - accuracy: 0.9893 - val_loss: 1.9795 - val_accuracy: 0.8736\n",
            "Epoch 236/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - accuracy: 0.9904 - val_loss: 1.9254 - val_accuracy: 0.8731\n",
            "Epoch 237/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 1.9485 - val_accuracy: 0.8756\n",
            "Epoch 238/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0209 - accuracy: 0.9919 - val_loss: 2.0317 - val_accuracy: 0.8712\n",
            "Epoch 239/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 1.9432 - val_accuracy: 0.8695\n",
            "Epoch 240/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0227 - accuracy: 0.9916 - val_loss: 1.9985 - val_accuracy: 0.8714\n",
            "Epoch 241/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0295 - accuracy: 0.9891 - val_loss: 1.9855 - val_accuracy: 0.8723\n",
            "Epoch 242/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 2.0625 - val_accuracy: 0.8747\n",
            "Epoch 243/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0461 - accuracy: 0.9842 - val_loss: 2.1461 - val_accuracy: 0.8662\n",
            "Epoch 244/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 1.8836 - val_accuracy: 0.8741\n",
            "Epoch 245/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 1.9853 - val_accuracy: 0.8739\n",
            "Epoch 246/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0507 - accuracy: 0.9845 - val_loss: 1.9763 - val_accuracy: 0.8703\n",
            "Epoch 247/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 1.9840 - val_accuracy: 0.8722\n",
            "Epoch 248/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0289 - accuracy: 0.9895 - val_loss: 1.9585 - val_accuracy: 0.8767\n",
            "Epoch 249/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0263 - accuracy: 0.9910 - val_loss: 2.0884 - val_accuracy: 0.8716\n",
            "Epoch 250/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0222 - accuracy: 0.9919 - val_loss: 1.8951 - val_accuracy: 0.8712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHd_ZSq_uVzk",
        "outputId": "43186c1e-6703-4936-81a7-3e6e7b0549fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "lr_epoch_loss,lr_epoch_acc=model.evaluate(test_dataset,steps=50)\n",
        "print(\"Accuracy with initial Learning rate 0.01 and 250 epochs is \",lr_epoch_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 0s 8ms/step - loss: 1.8951 - accuracy: 0.8712\n",
            "Accuracy with initial Learning rate 0.01 and 250 epochs is  0.8712499737739563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2mNRr-rUm9v"
      },
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "reg_model = keras.Sequential()\n",
        "reg_model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "reg_model.add(keras.layers.Dense(32, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),activation='relu'))\n",
        "reg_model.add(keras.layers.Dense(128,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\n",
        "reg_model.add(keras.layers.Dense(10,activation='softmax'))\n",
        "reg_model.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACvamQeLVeej",
        "outputId": "c94e0f1a-76f6-47e8-b693-01970f44a478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "NO_EPOCHS=250\n",
        "history_reg_model=reg_model.fit(train_dataset,epochs=NO_EPOCHS,steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,validation_data=test_dataset,batch_size=BATCH_SIZE,verbose = 1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 2.7008 - accuracy: 0.1015 - val_loss: 2.3942 - val_accuracy: 0.1005\n",
            "Epoch 2/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3412 - accuracy: 0.1023 - val_loss: 2.3133 - val_accuracy: 0.0984\n",
            "Epoch 3/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3068 - accuracy: 0.0979 - val_loss: 2.3035 - val_accuracy: 0.1005\n",
            "Epoch 4/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3031 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 5/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 6/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 7/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 8/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 9/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0967 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 10/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
            "Epoch 11/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1030\n",
            "Epoch 12/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.1041\n",
            "Epoch 13/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0986 - val_loss: 2.3028 - val_accuracy: 0.1016\n",
            "Epoch 14/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3028 - val_accuracy: 0.0975\n",
            "Epoch 15/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3029 - accuracy: 0.0966 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 16/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 17/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 18/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0954 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 19/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 20/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 21/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1034 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 22/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0955 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 23/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 24/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0970 - val_loss: 2.3026 - val_accuracy: 0.0975\n",
            "Epoch 25/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
            "Epoch 26/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 27/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1016\n",
            "Epoch 28/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1020 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 29/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 30/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1014 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 31/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1007 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 32/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0956 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 33/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.1006 - val_loss: 2.3026 - val_accuracy: 0.0975\n",
            "Epoch 34/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0941 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 35/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1025 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 36/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 37/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1016\n",
            "Epoch 38/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0966 - val_loss: 2.3026 - val_accuracy: 0.1003\n",
            "Epoch 39/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0938 - val_loss: 2.3026 - val_accuracy: 0.1030\n",
            "Epoch 40/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 41/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0961 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 42/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 43/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 44/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 45/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 46/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0956 - val_loss: 2.3028 - val_accuracy: 0.1030\n",
            "Epoch 47/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.1003 - val_loss: 2.3028 - val_accuracy: 0.1030\n",
            "Epoch 48/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 49/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 50/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 51/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 52/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3027 - val_accuracy: 0.1003\n",
            "Epoch 53/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0953 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 54/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.1023 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 55/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3029 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 56/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3026 - accuracy: 0.1025 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 57/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1030\n",
            "Epoch 58/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 59/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 60/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0959 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 61/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3028 - val_accuracy: 0.1030\n",
            "Epoch 62/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3026 - val_accuracy: 0.1030\n",
            "Epoch 63/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 64/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 65/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.1009 - val_loss: 2.3029 - val_accuracy: 0.1003\n",
            "Epoch 66/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 67/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 68/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 69/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0972 - val_loss: 2.3030 - val_accuracy: 0.0984\n",
            "Epoch 70/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 71/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 72/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 73/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 74/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0962 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 75/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3028 - val_accuracy: 0.0983\n",
            "Epoch 76/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 77/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 78/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 79/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 80/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.0980\n",
            "Epoch 81/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 82/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1011 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 83/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 84/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.0979 - val_loss: 2.3028 - val_accuracy: 0.1016\n",
            "Epoch 85/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 86/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 87/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 88/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
            "Epoch 89/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3029 - val_accuracy: 0.0975\n",
            "Epoch 90/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 91/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 92/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 93/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 94/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 95/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0937 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 96/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.1051 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 97/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0954 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 98/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0959 - val_loss: 2.3028 - val_accuracy: 0.0975\n",
            "Epoch 99/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0992 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 100/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 101/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0998 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 102/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0953 - val_loss: 2.3026 - val_accuracy: 0.1016\n",
            "Epoch 103/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3026 - accuracy: 0.1025 - val_loss: 2.3028 - val_accuracy: 0.0975\n",
            "Epoch 104/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0936 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 105/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 106/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 107/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3028 - val_accuracy: 0.1016\n",
            "Epoch 108/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.1018 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 109/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 110/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1029 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 111/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0952 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 112/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1023 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 113/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.1025 - val_loss: 2.3030 - val_accuracy: 0.0980\n",
            "Epoch 114/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
            "Epoch 115/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0999 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 116/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 117/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3025 - accuracy: 0.0972 - val_loss: 2.3026 - val_accuracy: 0.0975\n",
            "Epoch 118/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1041\n",
            "Epoch 119/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 120/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 121/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1002 - val_loss: 2.3031 - val_accuracy: 0.1030\n",
            "Epoch 122/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0983\n",
            "Epoch 123/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 124/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 125/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1017 - val_loss: 2.3029 - val_accuracy: 0.0984\n",
            "Epoch 126/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0955 - val_loss: 2.3028 - val_accuracy: 0.1016\n",
            "Epoch 127/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 128/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 129/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1024 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 130/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1016\n",
            "Epoch 131/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1027 - val_loss: 2.3028 - val_accuracy: 0.0975\n",
            "Epoch 132/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1041\n",
            "Epoch 133/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1025 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 134/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 135/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3028 - val_accuracy: 0.1030\n",
            "Epoch 136/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3029 - accuracy: 0.1022 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 137/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0974 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 138/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1019 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 139/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0925 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 140/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1013 - val_loss: 2.3028 - val_accuracy: 0.1016\n",
            "Epoch 141/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.1024 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 142/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0963 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 143/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1043 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 144/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0962 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
            "Epoch 145/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1015 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 146/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1041\n",
            "Epoch 147/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 148/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 149/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0963 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
            "Epoch 150/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0959 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
            "Epoch 151/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 152/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1037 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 153/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0952 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 154/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1020 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 155/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1003\n",
            "Epoch 156/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 157/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1015 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 158/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1016\n",
            "Epoch 159/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.0975\n",
            "Epoch 160/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
            "Epoch 161/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 162/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0955 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 163/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 164/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 165/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 166/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1035 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 167/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0947 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 168/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0955 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 169/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 170/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1030\n",
            "Epoch 171/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 172/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0941 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 173/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.0986 - val_loss: 2.3028 - val_accuracy: 0.0975\n",
            "Epoch 174/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 175/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1073 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 176/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 177/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0953 - val_loss: 2.3028 - val_accuracy: 0.1030\n",
            "Epoch 178/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3031 - val_accuracy: 0.0983\n",
            "Epoch 179/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 180/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3026 - accuracy: 0.1032 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 181/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 182/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3027 - val_accuracy: 0.1003\n",
            "Epoch 183/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0959 - val_loss: 2.3027 - val_accuracy: 0.0983\n",
            "Epoch 184/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0945 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 185/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1016 - val_loss: 2.3026 - val_accuracy: 0.0984\n",
            "Epoch 186/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0960 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 187/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 188/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 189/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1019 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 190/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3028 - val_accuracy: 0.1005\n",
            "Epoch 191/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
            "Epoch 192/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1011 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 193/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 194/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1027 - val_loss: 2.3029 - val_accuracy: 0.0984\n",
            "Epoch 195/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 196/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3027 - val_accuracy: 0.1003\n",
            "Epoch 197/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0987 - val_loss: 2.3029 - val_accuracy: 0.0980\n",
            "Epoch 198/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0979 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 199/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.1011 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 200/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0957 - val_loss: 2.3028 - val_accuracy: 0.1016\n",
            "Epoch 201/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3026 - accuracy: 0.1035 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 202/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 203/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 204/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 205/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.0973 - val_loss: 2.3028 - val_accuracy: 0.1030\n",
            "Epoch 206/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.0983\n",
            "Epoch 207/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 208/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1037 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 209/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0971 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 210/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3028 - val_accuracy: 0.1003\n",
            "Epoch 211/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0965 - val_loss: 2.3027 - val_accuracy: 0.0983\n",
            "Epoch 212/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0946 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 213/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 214/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0954 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 215/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3026 - accuracy: 0.1022 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 216/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3029 - accuracy: 0.0975 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 217/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1022 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 218/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3029 - val_accuracy: 0.1003\n",
            "Epoch 219/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1016\n",
            "Epoch 220/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3029 - val_accuracy: 0.0975\n",
            "Epoch 221/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3029 - accuracy: 0.0950 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 222/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 223/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 224/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3030 - val_accuracy: 0.1030\n",
            "Epoch 225/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0969 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 226/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0934 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 227/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 228/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0950 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 229/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1013 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 230/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0993 - val_loss: 2.3030 - val_accuracy: 0.0980\n",
            "Epoch 231/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3030 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 232/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1013 - val_loss: 2.3027 - val_accuracy: 0.1041\n",
            "Epoch 233/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0967 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 234/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3028 - val_accuracy: 0.0975\n",
            "Epoch 235/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3029 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1041\n",
            "Epoch 236/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1045 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 237/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 238/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.0995 - val_loss: 2.3029 - val_accuracy: 0.0984\n",
            "Epoch 239/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0961 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
            "Epoch 240/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 241/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.1005\n",
            "Epoch 242/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 243/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 244/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 245/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.1010 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 246/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1033 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 247/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.1016\n",
            "Epoch 248/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1021 - val_loss: 2.3027 - val_accuracy: 0.0975\n",
            "Epoch 249/250\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 2.3028 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 250/250\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 2.3028 - accuracy: 0.1041 - val_loss: 2.3029 - val_accuracy: 0.0984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj-ril2PWIJu",
        "outputId": "693b6a1b-24ac-4abe-9dcb-c01f14c29443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "reg_epoch_loss,reg_epoch_acc=model.evaluate(test_dataset,steps=50)\n",
        "print(\"Accuracy with l2 regularization is \",reg_epoch_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 0s 8ms/step - loss: 1.8951 - accuracy: 0.8712\n",
            "Accuracy with l2 regularization is  0.8712499737739563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1LRIBrEgu92"
      },
      "source": [
        "\n",
        "|Dropout (rate)   | Batch Normalisation (Y/N)  | Optimiser  | Learning Rate  | Number of Epochs   |     Regularization |  Test Accuracy |\n",
        "|---|---|---|---|---|---|---|\n",
        "|   0.5|   |   |   |   |    |   87.7|\n",
        "|   |   Y  |   |   |   |     |84.0 |\n",
        "|   |   |   | 0.01(with decay)  |   |    |87.2  |\n",
        "|   |   |   |   0.01(with decay)    | 250   |     |  87.1  |\n",
        "|   |   |   |       |  250  |    l2    | 87.1   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLjJA98Qgxg5"
      },
      "source": [
        "\n",
        "Answer the following questions:\n",
        "\n",
        "1. Which configuration achieved the best test accuracy?\n",
        "2. Which setting had the most impact and which one had the least impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8ndkVJuWyxn"
      },
      "source": [
        "1. The best configuration was achieved by the addition of a Dropout layer.\n",
        "2. Considering a layer with l2 regularization has the least impact on the dataset as the results are almost the same as it was in our first model.\n",
        "Having batch-normalization has the most impact even though the impact has been negative in this scenario as the accuracy has dropped from 87 to 84."
      ]
    }
  ]
}